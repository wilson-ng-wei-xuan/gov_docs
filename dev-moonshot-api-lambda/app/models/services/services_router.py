import base64
import json, os
from typing import Optional

from fastapi import APIRouter, Security, HTTPException, Request
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
from pydantic import BaseModel, AnyHttpUrl
from fastapi.responses import RedirectResponse, JSONResponse
import httpx
from starlette.datastructures import MutableHeaders

from app import config
from app.models.services.services_model import UsageLogModel
from app.models.apikey.apikey_router import api_key_auth
from app.config import dynamodb, TABLE_MOONSHOT_LLM
import logging

from app.config import boto_config, OPENAI_API_SECRET
from app.utils.secret_manager_util import get_json_secret_as_dict

openai_secret = get_json_secret_as_dict(
    OPENAI_API_SECRET,
    endpoint_url=os.getenv("SECRETS_MGR_ENDPOINT_URL"),
    boto_config=boto_config,
)

router = APIRouter()
security_http_bearer = HTTPBearer()

model_usage_log = UsageLogModel(dynamodb, TABLE_MOONSHOT_LLM)

class UsageLogType(BaseModel):
    usage: dict
    response: str

    class Config:
        schema_extra = {
            "example": {
                "usage": {'input1': 'Some notes', 
                          'input2': 'Some more notes',
                          'settings':{'tone':'neutral'}},
                "response": "Response generated by the LLM"
            }
        }


@router.post("/log_usage")
async def log_usage(payload:UsageLogType, credentials: HTTPAuthorizationCredentials = Security(security_http_bearer)):
    '''
    Logs usage of the LLM by agents & external applications.
    Requires valid API key (not JWT)
    '''

    owner = api_key_auth(credentials.credentials)
    email = owner.get('email')
    agency = owner.get('agency')
    project = owner.get('project')

    usage = payload.usage
    response = payload.response

    response = model_usage_log.put_usage_log(project, usage, response, email, agency)

    if response:
        return "Usage logged successfully"
    else:
        return "Error logging usage"

@router.post("/openai/{path:path}")
async def openai_completion(request: Request, path: str):
    '''
    Proxies the API call to Azure OpenAI endpoint
    1. Generate an API key with a unique project name (Using Apikey API above)
    2. Use openai library as shown below: 
        - openai.api_type = 'azure'
        - openai.api_base = 'https://moonshot-api.data.tech.gov.sg/services/openai/'
        - openai.api_version = '2023-03-15-preview'
        - openai.api_key = <APIKEY generated from step 1>
    3. For intranet access, use the following endpoint instead:
        - openai.api_base = 'https://moonshot-intra.data.tech.gov.sg/services/openai/'
    '''

    # Verify that the API key is valid
    api_key = request.headers.get('api-key')
    if not api_key:
        raise HTTPException(status_code=401, detail="Missing API key")
    
    owner = api_key_auth(api_key)
    email = owner.get('email')
    agency = owner.get('agency')
    project = owner.get('project')

    # Swap in actual Azure API key
    # TODO: replace with external resource API key
    # azure_endpoint = 'https://launchpad-davinci.openai.azure.com/'
    azure_endpoint = 'https://moonshot-gpt-external.openai.azure.com/'
    azure_api_key = openai_secret.get("OPENAI_API_KEY_AZURE_EXTERNAL")

    url = f"{azure_endpoint}{path}?{request.url.query}"
    print(f"{url=}")

    headers = {'api-key': azure_api_key}

    # track prompts
    request_body = await request.body()
    json_body = json.loads(request_body)

    if json_body.get('prompt'):
        prompt = json_body.get('prompt')
    elif json_body.get('messages'):
        prompt = json_body.get('messages')[-1].get('content')
    else:
        prompt = ""
    
    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers, data=request_body, timeout=60.0)

        response_json = response.json()
        print(f"{response_json=}")

    # Log usage
    usage_dict = {
        'prompt': prompt,
        'model': response_json.get('model'),
        'object': response_json.get('object'),
        'usage': response_json.get('usage')
    }
    
    choices = response_json.get('choices')[0]
    if choices.get('text'):
        response_text = choices.get('text')
    elif choices.get('message'):
        response_text = choices.get('message').get('content')
    else:
        response_text = ""

    model_usage_log.put_usage_log(project, usage_dict, response_text, email, agency)

    return JSONResponse(content=response_json, status_code=response.status_code)

@router.get("/openai/test/{passphrase}")
async def openai_test(passphrase: str):
    '''
    Test endpoint for Azure OpenAI
    '''
    if passphrase != 'beer':
        raise HTTPException(status_code=401, detail="Invalid passphrase")

    azure_endpoint = 'https://moonshot-gpt-external.openai.azure.com/'
    path='openai/deployments/gpt-35-turbo/chat/completions'
    query='api-version=2023-03-15-preview'
    url = f"{azure_endpoint}{path}?{query}"
    print(f"{url=}")

    azure_api_key = openai_secret.get("OPENAI_API_KEY_AZURE_EXTERNAL")
    headers = {'api-key': azure_api_key}

    request_body ={'messages':[{'role':'user','content':'say this is a test'}]}

    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers, data=json.dumps(request_body), timeout=60.0)
    response_json = response.json()
    return response_json