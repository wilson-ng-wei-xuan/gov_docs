{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP5H-M8E-Bcd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773601385,
          "user_tz": -480,
          "elapsed": 2562,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8a0dd288-c71d-4364-9f5c-bffd8cad60ac"
      },
      "id": "iP5H-M8E-Bcd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (1.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.12.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install axolotl[ring-flash-attn]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8S5-DlS6pEk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773716451,
          "user_tz": -480,
          "elapsed": 115067,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c21fe221-70b2-4c48-eb66-cdfd77991a87"
      },
      "id": "y8S5-DlS6pEk",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting axolotl[ring-flash-attn]\n",
            "  Downloading axolotl-0.8.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.1/275.1 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes==0.45.4 (from axolotl[ring-flash-attn])\n",
            "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting triton>=3.0.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting liger-kernel==0.5.6 (from axolotl[ring-flash-attn])\n",
            "  Downloading liger_kernel-0.5.6-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting packaging==23.2 (from axolotl[ring-flash-attn])\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting peft==0.15.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers==4.51.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting tokenizers>=0.21.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting accelerate==1.6.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting datasets==3.5.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting trl==0.16.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hf_xet==1.0.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading hf_xet-1.0.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Collecting optimum==1.16.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting hf_transfer (from axolotl[ring-flash-attn])\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.2.0)\n",
            "Collecting gradio==5.23.3 (from axolotl[ring-flash-attn])\n",
            "  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting modal==0.70.5 (from axolotl[ring-flash-attn])\n",
            "  Downloading modal-0.70.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pydantic==2.10.6 (from axolotl[ring-flash-attn])\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting addict (from axolotl[ring-flash-attn])\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fire (from axolotl[ring-flash-attn])\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2.32.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.19.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.8.0)\n",
            "Collecting colorama (from axolotl[ring-flash-attn])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.60.0)\n",
            "Requirement already satisfied: numpy<=2.0.1,>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (1.26.4)\n",
            "Collecting evaluate==0.4.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (1.13.1)\n",
            "Collecting scikit-learn==1.4.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py==12.560.30 (from axolotl[ring-flash-attn])\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting art (from axolotl[ring-flash-attn])\n",
            "  Downloading art-6.5-py3-none-any.whl.metadata (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2.17.1)\n",
            "Collecting python-dotenv==1.0.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting s3fs>=2024.5.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading s3fs-2025.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: gcsfs>=2024.5.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2024.10.0)\n",
            "Collecting adlfs>=2024.5.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading adlfs-2024.12.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ocifs==1.3.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading ocifs-1.3.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting zstandard==0.22.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (1.7.28)\n",
            "Collecting lm_eval==0.4.7 (from axolotl[ring-flash-attn])\n",
            "  Downloading lm_eval-0.4.7-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect==1.0.9 (from axolotl[ring-flash-attn])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting immutabledict==4.2.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting antlr4-python3-runtime==4.13.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Collecting torchao==0.9.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "Collecting schedulefree==1.4.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading schedulefree-1.4.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting axolotl-contribs-lgpl==0.0.6 (from axolotl[ring-flash-attn])\n",
            "  Downloading axolotl_contribs_lgpl-0.0.6.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting axolotl-contribs-mit==0.0.3 (from axolotl[ring-flash-attn])\n",
            "  Downloading axolotl_contribs_mit-0.0.3.tar.gz (5.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2.5.1+cu121)\n",
            "Collecting xformers>=0.0.28.post3 (from axolotl[ring-flash-attn])\n",
            "  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting flash-attn==2.7.4.post1 (from axolotl[ring-flash-attn])\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ring-flash-attn>=0.1.4 (from axolotl[ring-flash-attn])\n",
            "  Downloading ring_flash_attn-0.1.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting yunchang==0.6.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading yunchang-0.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==1.6.0->axolotl[ring-flash-attn]) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.6.0->axolotl[ring-flash-attn]) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.6.0->axolotl[ring-flash-attn]) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (4.67.1)\n",
            "Collecting xxhash (from datasets==3.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0->axolotl[ring-flash-attn]) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (3.11.11)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl[ring-flash-attn])\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (0.28.1)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate==1.6.0->axolotl[ring-flash-attn])\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.1.5)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.10.13)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (11.1.0)\n",
            "Collecting pydub (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect==1.0.9->axolotl[ring-flash-attn]) (1.17.0)\n",
            "Collecting jsonlines (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.7->axolotl[ring-flash-attn]) (2.10.2)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlitedict (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting word2number (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.7->axolotl[ring-flash-attn]) (10.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (2024.12.14)\n",
            "Requirement already satisfied: click>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (8.1.8)\n",
            "Collecting grpclib==0.4.7 (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading grpclib-0.4.7.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf!=4.24.0,<6.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (4.25.5)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (13.9.4)\n",
            "Collecting synchronicity~=0.9.8 (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading synchronicity-0.9.11-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (0.10.2)\n",
            "Collecting types-certifi (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading types_certifi-2021.10.8.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting types-toml (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading types_toml-0.10.8.20240310-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting watchfiles (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading watchfiles-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting oci>=2.43.1 (from ocifs==1.3.2->axolotl[ring-flash-attn])\n",
            "  Downloading oci-2.150.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting coloredlogs (from optimum==1.16.2->axolotl[ring-flash-attn])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.16.2->axolotl[ring-flash-attn]) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.10.6->axolotl[ring-flash-attn]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.10.6->axolotl[ring-flash-attn]) (2.27.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl[ring-flash-attn]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl[ring-flash-attn]) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->axolotl[ring-flash-attn]) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0->axolotl[ring-flash-attn]) (2024.11.6)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.8.0->gradio==5.23.3->axolotl[ring-flash-attn]) (14.1)\n",
            "Collecting h2<5,>=3.1.0 (from grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: multidict in /usr/local/lib/python3.10/dist-packages (from grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn]) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.16.2->axolotl[ring-flash-attn]) (1.3.0)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-datalake-store<0.1,>=0.0.53 (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting azure-identity (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.17.0 (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[ring-flash-attn]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[ring-flash-attn]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[ring-flash-attn]) (2.3.0)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading aiobotocore-2.21.1-py3-none-any.whl.metadata (24 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs>=2024.5.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading s3fs-2025.3.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading s3fs-2024.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton>=3.0.0->axolotl[ring-flash-attn]) (69.5.1)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers>=0.0.28.post3 (from axolotl[ring-flash-attn])\n",
            "  Downloading xformers-0.0.29.post2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "  Downloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl[ring-flash-attn]) (2.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->axolotl[ring-flash-attn]) (0.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (3.1.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (1.3.4)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.37.2,>=1.37.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading botocore-1.37.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn]) (2.8.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn]) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (1.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (1.18.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio==5.23.3->axolotl[ring-flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio==5.23.3->axolotl[ring-flash-attn]) (1.2.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (1.17.1)\n",
            "Collecting msal<2,>=1.16.0 (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading msal-1.32.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob>=12.17.0->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (43.0.3)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.17.0->adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl[ring-flash-attn]) (4.0.12)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (4.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==5.23.3->axolotl[ring-flash-attn]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.23.3->axolotl[ring-flash-attn]) (0.14.0)\n",
            "Requirement already satisfied: pyOpenSSL<25.0.0,>=17.5.0 in /usr/local/lib/python3.10/dist-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl[ring-flash-attn]) (24.2.1)\n",
            "Requirement already satisfied: pytz>=2016.10 in /usr/local/lib/python3.10/dist-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl[ring-flash-attn]) (2024.2)\n",
            "Collecting circuitbreaker<3.0.0,>=1.3.1 (from oci>=2.43.1->ocifs==1.3.2->axolotl[ring-flash-attn])\n",
            "  Downloading circuitbreaker-2.1.3-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.5.0->axolotl[ring-flash-attn]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modal==0.70.5->axolotl[ring-flash-attn]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modal==0.70.5->axolotl[ring-flash-attn]) (2.18.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.7->axolotl[ring-flash-attn]) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[ring-flash-attn]) (0.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[ring-flash-attn]) (5.3.0)\n",
            "Collecting sigtools>=4.0.1 (from synchronicity~=0.9.8->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading sigtools-4.0.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==5.23.3->axolotl[ring-flash-attn]) (1.5.4)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl[ring-flash-attn])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.6.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl[ring-flash-attn]) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.25.0)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3.1.0->grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3.1.0->grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->modal==0.70.5->axolotl[ring-flash-attn]) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn]) (5.2.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (2.10.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (3.2.2)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.23.3-py3-none-any.whl (46.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.0.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading liger_kernel-0.5.6-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.7-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modal-0.70.5-py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.4/509.4 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ocifs-1.3.2-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Downloading peft-0.15.1-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading schedulefree-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m147.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.0-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yunchang-0.6.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adlfs-2024.12.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ring_flash_attn-0.1.4-py3-none-any.whl (24 kB)\n",
            "Downloading s3fs-2024.10.0-py3-none-any.whl (29 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading art-6.5-py3-none-any.whl (610 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.4/610.4 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m142.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiobotocore-2.21.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.1/207.1 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_datalake_store-0.0.53-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oci-2.150.1-py3-none-any.whl (29.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m150.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading synchronicity-0.9.11-py3-none-any.whl (36 kB)\n",
            "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading types_certifi-2021.10.8.3-py3-none-any.whl (2.1 kB)\n",
            "Downloading types_toml-0.10.8.20240310-py3-none-any.whl (4.8 kB)\n",
            "Downloading watchfiles-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.37.1-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m146.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading circuitbreaker-2.1.3-py3-none-any.whl (7.7 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading msal-1.32.0-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading sigtools-4.0.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: axolotl-contribs-lgpl, axolotl-contribs-mit, flash-attn, langdetect, grpclib, axolotl, fire, rouge-score, sqlitedict, word2number\n",
            "  Building wheel for axolotl-contribs-lgpl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl-contribs-lgpl: filename=axolotl_contribs_lgpl-0.0.6-py3-none-any.whl size=10897 sha256=0fb7a49376a9757285288378bb0b6801fff5e052767edb077c52b734db858a57\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/0a/5b/0c4db6ff7b7b11979dc2d274706f66cd079198fb0f15dea37f\n",
            "  Building wheel for axolotl-contribs-mit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl-contribs-mit: filename=axolotl_contribs_mit-0.0.3-py3-none-any.whl size=6005 sha256=7e0314c5e286e1c3f5fc90eb4078ff3f80eb5cf5c0d0026d4a7b2bc17c638dab\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/8e/3b/84cb3147cfe6cb5853c2667823368039db4a2b9b2eeb6a0eaf\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187797312 sha256=b267f80a08e516292cdd748056a2178a45b8abedf7fca123292eb17c21c8c87c\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/ce/d5/08ea07bfc16ba218dc65a3a7ef9b6a270530bcbd2cea2ee1ca\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=3c2f73e0c4039be79866ae2ccc377210336843ec7653defa2b93370c543135f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.7-py3-none-any.whl size=76261 sha256=6c78abddb2a6bdf47f361504b70589738968727342ed73d2982a710b39fa3be8\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/c0/1c/3d807409d0c67efeab2949832ba409205b1b6fe03f739ae4c1\n",
            "  Building wheel for axolotl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl: filename=axolotl-0.8.1-py3-none-any.whl size=350645 sha256=6458143a4f08deebaad683524d1412af8318d5cf0f9f42a6d03b3cf46ce1cda2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/48/e9/741d24d3a8d57db536ce44ff0b6d229a0dfc2b9d8285aa8985\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=32907bdf5c0f7240bfa6cf6095c1cc95a1185ee749428e5f68429e176e77fc9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=868c0ab43aa13567d2bf478c042da9ea7877e61c38482795aa34f4f8c61bb5c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=21faf8db6bf1b319faaedd2f02a53c3e5185a41d285d7f005596fe58a2d1825d\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=0c9abeaf0d9a65266f689fd7c93b920999feaeed8a311bcc8c31664e149b2729\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built axolotl-contribs-lgpl axolotl-contribs-mit flash-attn langdetect grpclib axolotl fire rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, types-certifi, torchao, sqlitedict, pydub, nvidia-ml-py, circuitbreaker, antlr4-python3-runtime, addict, zstandard, yunchang, xxhash, uvicorn, types-toml, triton, tomlkit, tcolorpy, sigtools, semantic-version, ruff, ring-flash-attn, python-multipart, python-dotenv, pybind11, portalocker, pathvalidate, packaging, mbstrdecoder, langdetect, jsonlines, jmespath, isodate, immutabledict, hyperframe, humanfriendly, hpack, hf_xet, hf_transfer, groovy, fire, ffmpy, dill, colorama, art, aioitertools, aiofiles, watchfiles, typepy, tqdm-multiprocess, synchronicity, starlette, scikit-learn, sacrebleu, rouge-score, responses, pydantic, multiprocess, huggingface-hub, h2, coloredlogs, botocore, azure-core, xformers, tokenizers, schedulefree, safehttpx, liger-kernel, grpclib, gradio-client, flash-attn, fastapi, bitsandbytes, azure-storage-blob, axolotl-contribs-mit, accelerate, transformers, oci, msal, modal, gradio, DataProperty, aiobotocore, tabledata, s3fs, peft, ocifs, msal-extensions, datasets, azure-datalake-store, trl, pytablewriter, optimum, evaluate, azure-identity, axolotl-contribs-lgpl, lm_eval, adlfs, axolotl\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: immutabledict\n",
            "    Found existing installation: immutabledict 4.2.1\n",
            "    Uninstalling immutabledict-4.2.1:\n",
            "      Successfully uninstalled immutabledict-4.2.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.0\n",
            "    Uninstalling scikit-learn-1.6.0:\n",
            "      Successfully uninstalled scikit-learn-1.6.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.4\n",
            "    Uninstalling pydantic-2.10.4:\n",
            "      Successfully uninstalled pydantic-2.10.4\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.27.1\n",
            "    Uninstalling huggingface-hub-0.27.1:\n",
            "      Successfully uninstalled huggingface-hub-0.27.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "Successfully installed DataProperty-1.1.0 accelerate-1.6.0 addict-2.4.0 adlfs-2024.12.0 aiobotocore-2.21.1 aiofiles-23.2.1 aioitertools-0.12.0 antlr4-python3-runtime-4.13.2 art-6.5 axolotl-0.8.1 axolotl-contribs-lgpl-0.0.6 axolotl-contribs-mit-0.0.3 azure-core-1.33.0 azure-datalake-store-0.0.53 azure-identity-1.21.0 azure-storage-blob-12.25.1 bitsandbytes-0.45.4 botocore-1.37.1 circuitbreaker-2.1.3 colorama-0.4.6 coloredlogs-15.0.1 datasets-3.5.0 dill-0.3.8 evaluate-0.4.1 fastapi-0.115.12 ffmpy-0.5.0 fire-0.7.0 flash-attn-2.7.4.post1 gradio-5.23.3 gradio-client-1.8.0 groovy-0.1.2 grpclib-0.4.7 h2-4.2.0 hf_transfer-0.1.9 hf_xet-1.0.0 hpack-4.1.0 huggingface-hub-0.30.2 humanfriendly-10.0 hyperframe-6.1.0 immutabledict-4.2.0 isodate-0.7.2 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 liger-kernel-0.5.6 lm_eval-0.4.7 mbstrdecoder-1.1.4 modal-0.70.5 msal-1.32.0 msal-extensions-1.3.1 multiprocess-0.70.16 nvidia-ml-py-12.560.30 oci-2.150.1 ocifs-1.3.2 optimum-1.16.2 packaging-23.2 pathvalidate-3.2.3 peft-0.15.1 portalocker-3.1.1 pybind11-2.13.6 pydantic-2.10.6 pydub-0.25.1 pytablewriter-1.2.1 python-dotenv-1.0.1 python-multipart-0.0.20 responses-0.18.0 ring-flash-attn-0.1.4 rouge-score-0.1.2 ruff-0.11.5 s3fs-2024.10.0 sacrebleu-2.5.1 safehttpx-0.1.6 schedulefree-1.4.1 scikit-learn-1.4.2 semantic-version-2.10.0 sigtools-4.0.1 sqlitedict-2.1.0 starlette-0.46.2 synchronicity-0.9.11 tabledata-1.3.4 tcolorpy-0.1.7 tokenizers-0.21.1 tomlkit-0.13.2 torchao-0.9.0 tqdm-multiprocess-0.0.11 transformers-4.51.0 triton-3.3.0 trl-0.16.1 typepy-1.3.4 types-certifi-2021.10.8.3 types-toml-0.10.8.20240310 uvicorn-0.34.1 watchfiles-1.0.5 word2number-1.1 xformers-0.0.29.post1 xxhash-3.5.0 yunchang-0.6.0 zstandard-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4vha5X5Hgt6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773719294,
          "user_tz": -480,
          "elapsed": 2847,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "95ec0712-2129-4aba-963d-3afb4729db7f"
      },
      "id": "z4vha5X5Hgt6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.51.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  transformers datasets peft accelerate bitsandbytes wandb deepspeed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STQoDdHuQLF7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773735322,
          "user_tz": -480,
          "elapsed": 16030,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "11726b59-7d9c-4ffd-b201-34a9f5ae4d89"
      },
      "id": "STQoDdHuQLF7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.51.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.4)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.16.5.tar.gz (1.5 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (69.5.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from deepspeed) (0.8.0)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.1.0)\n",
            "Collecting ninja (from deepspeed)\n",
            "  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from deepspeed) (12.560.30)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.16.5-py3-none-any.whl size=1580581 sha256=3f278b3b0e2251a7fbb7108bfbf1999fe517864eda9b154a488dda987e3ace08\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/fa/e7/98efc76db11fac734a4fae8c19dd08cc24257107e132e674f6\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: hjson, ninja, deepspeed\n",
            "Successfully installed deepspeed-0.16.5 hjson-3.1.0 ninja-1.11.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "TCbx9PsYEzdX"
      },
      "id": "TCbx9PsYEzdX"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.cloud import storage\n",
        "import os\n",
        "\n",
        "def save_json(data, filename):\n",
        "    # Get the directory from the filename\n",
        "    directory = os.path.dirname(filename)\n",
        "\n",
        "    # Check if the directory exists, if not, create it\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    # Save the data to the file\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def list_files_in_bucket(bucket_name, prefix=\"\"):\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "\n",
        "    # Print the list of file names in the bucket\n",
        "    print(\"Files in the bucket:\")\n",
        "    for blob in blobs:\n",
        "        print(blob.name)\n",
        "\n",
        "def load_json_from_gcs(bucket_name, file_name):\n",
        "    from google.cloud import storage\n",
        "    import json\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    if not file_name.endswith('.jsonl'):  # Ensure it's a JSONL file\n",
        "        raise ValueError(f\"The specified file '{file_name}' is not a JSONL file.\")\n",
        "\n",
        "    concatenated_data = []  # To accumulate JSON objects\n",
        "    try:\n",
        "        # Download and decode the file content\n",
        "        content = blob.download_as_string().decode('utf-8')\n",
        "        # Split content by lines and load each line as a separate JSON object\n",
        "        for line in content.splitlines():\n",
        "            if line.strip():  # Only parse non-empty lines\n",
        "                json_obj = json.loads(line)\n",
        "                concatenated_data.append(json_obj)  # Add JSON object to the list\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON in {file_name}: {e}\")\n",
        "\n",
        "    # Return the JSON as a string for output\n",
        "    return json.dumps(concatenated_data, indent=4)  # Prettify the JSON output\n",
        "\n",
        "def load_csv_from_gcs(bucket_name, file_name):\n",
        "    from google.cloud import storage\n",
        "    import pandas as pd\n",
        "    from io import StringIO  # Corrected import for StringIO\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    if not file_name.endswith('.csv'):  # Ensure it's a CSV file\n",
        "        raise ValueError(f\"The specified file '{file_name}' is not a CSV file.\")\n",
        "\n",
        "    try:\n",
        "        # Download CSV content and load it into a pandas DataFrame\n",
        "        content = blob.download_as_string().decode('utf-8')\n",
        "        data = pd.read_csv(StringIO(content))  # Use StringIO to parse the CSV content\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CSV file '{file_name}': {e}\")\n",
        "        return None\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def save_csv_to_gcs(bucket_name, file_name, dataframe):\n",
        "    from google.cloud import storage\n",
        "    import pandas as pd\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    if not file_name.endswith('.csv'):\n",
        "        raise ValueError(f\"The specified file '{file_name}' is not a CSV file.\")\n",
        "\n",
        "    try:\n",
        "        # Convert the DataFrame to CSV and upload it to GCS\n",
        "        csv_content = dataframe.to_csv(index=False)  # Convert DataFrame to CSV string\n",
        "        blob.upload_from_string(csv_content, content_type='text/csv')\n",
        "        print(f\"File '{file_name}' successfully saved to bucket '{bucket_name}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving CSV file '{file_name}': {e}\")"
      ],
      "metadata": {
        "id": "sec6ZoL57RQL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773736081,
          "user_tz": -480,
          "elapsed": 762,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "sec6ZoL57RQL",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_sample(df, col1, col2, frac=0.5, random_state=None):\n",
        "    total_samples = int(len(df) * frac)\n",
        "    grouped = df.groupby([col1, col2])\n",
        "    n_groups = len(grouped)\n",
        "    samples_per_group = total_samples // n_groups\n",
        "\n",
        "    sampled_df = (\n",
        "        grouped\n",
        "        .apply(lambda x: x.sample(n=min(samples_per_group, len(x)), random_state=random_state))\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    return sampled_df"
      ],
      "metadata": {
        "id": "N9I2rQKSTINa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773736081,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "N9I2rQKSTINa",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_train.csv\")\n",
        "augmented_full_df = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/augmented_mistral_train.csv\")\n",
        "test_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_test.csv\").rename({'key_point': 'stance', 'person_id': 'user'}, axis=1)\n",
        "vali_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_val.csv\")\n",
        "vali_data['prompt'] = vali_data[['prompt', 'label']].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n",
        "\n",
        "train_data.tail()"
      ],
      "metadata": {
        "id": "m0bDj8Vm-Jaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773780640,
          "user_tz": -480,
          "elapsed": 44561,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1c4445bb-bad6-451c-8ed0-2146af2cf2b6"
      },
      "id": "m0bDj8Vm-Jaj",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-8847c0ea2598>:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  vali_data['prompt'] = vali_data[['prompt', 'label']].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      group                                  user  \\\n",
              "2435      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2436      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2437      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2438      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2439      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "\n",
              "                                                 stance topic_group  \\\n",
              "2435  Contributor shared varying perspectives on whe...     rideout   \n",
              "2436  Contributor had differing opinions on whether ...     rideout   \n",
              "2437  Contributor expressed different views on the t...     rideout   \n",
              "2438  Contributor shared differing opinions on wheth...     rideout   \n",
              "2439  Contributor shared differing views on the inde...     rideout   \n",
              "\n",
              "     human_label  agreement                             group_user  label  \\\n",
              "2435  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2436  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2437  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2438  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2439  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "\n",
              "                                       pid  chat_group_id  contributor  \\\n",
              "2435  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2436  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2437  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2438  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2439  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "\n",
              "                                                  topic  \\\n",
              "2435  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2436  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2437  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2438  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2439  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "\n",
              "                                         content_concat  \\\n",
              "2435  Contributor255: https://www.channelnewsasia.co...   \n",
              "2436  Contributor255: https://www.channelnewsasia.co...   \n",
              "2437  Contributor255: https://www.channelnewsasia.co...   \n",
              "2438  Contributor255: https://www.channelnewsasia.co...   \n",
              "2439  Contributor255: https://www.channelnewsasia.co...   \n",
              "\n",
              "                                                 prompt  \n",
              "2435  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2436  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2437  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2438  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2439  <s>[INST]Determine whether Contributor16 holds...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd422ec4-122b-4907-88c8-0280a4c92107\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>user</th>\n",
              "      <th>stance</th>\n",
              "      <th>topic_group</th>\n",
              "      <th>human_label</th>\n",
              "      <th>agreement</th>\n",
              "      <th>group_user</th>\n",
              "      <th>label</th>\n",
              "      <th>pid</th>\n",
              "      <th>chat_group_id</th>\n",
              "      <th>contributor</th>\n",
              "      <th>topic</th>\n",
              "      <th>content_concat</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2435</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor shared varying perspectives on whe...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2436</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor had differing opinions on whether ...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2437</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor expressed different views on the t...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2438</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor shared differing opinions on wheth...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2439</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor shared differing views on the inde...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd422ec4-122b-4907-88c8-0280a4c92107')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd422ec4-122b-4907-88c8-0280a4c92107 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd422ec4-122b-4907-88c8-0280a4c92107');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1dec737-b8c1-40f0-b16b-50ca210e85bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1dec737-b8c1-40f0-b16b-50ca210e85bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1dec737-b8c1-40f0-b16b-50ca210e85bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"dd88a7a7-de66-4503-bfee-dfc0e74f578f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Contributor had differing opinions on whether the process for renting out the Ridout Road properties was fair.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rideout\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no opinion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agreement\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"unanimous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group_user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"6dd88a7a7-de66-4503-bfee-dfc0e74f578f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pid\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"dd88a7a7-de66-4503-bfee-dfc0e74f578f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chat_group_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contributor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 16,\n        \"max\": 16,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\ud83d\\udce2 *Topic* \\ud83d\\udce2\\n\\nIn Parliament today (3 July), Senior Minister Teo Chee Hean delivered a Ministerial Statement on the findings from his review of the rental of the 26 Ridout Road and 31 Ridout Road properties by Minister K Shanmugam and Minister Vivian Balakrishnan, respectively. \\n\\nThis Parliament discussion comes after PM Lee directed for the Corrupt Practices Investigation Bureau (CPIB) and SM Teo to conduct reviews on the situation. Both CPIB and SM Teo\\u2019s reports were published on 28 June 2023. \\n\\n\\ud83d\\udcac *What are your views on the findings from SM Teo\\u2019s review into the rental of the Ridout Road bungalows?*\\n\\nIn SM Teo\\u2019s Ministerial Statement, he noted that:\\n\\n1\\ufe0f\\u20e3 *No evidence of corruption or criminal wrongdoing in the rental of the Ridout Road properties.*\\n\\nSM Teo said that CPIB had found no evidence of corruption or criminal wrongdoing in the rental of Ridout Road properties by the two ministers. Neither were corrupt intent or any inducements uncovered.\\n\\n2\\ufe0f\\u20e3 *Both Ministers and the public officers, as well as private sector intermediaries involved,\\u00a0had conducted themselves properly in the two rental transactions.*\\n\\nSM Teo said that Ministers, public officers and private sector intermediaries were aware of their duty to declare and avoid any conflict of interest and took appropriate steps to prevent any potential or actual conflict of interest from arising. \\n\\nNonetheless, SM Teo announced that the Public Service Division (PSD) will work with relevant ministries and statutory boards such as HDB, JTC, NEA and SLA to introduce a standard declaration requirement for selected groups of officers who have access to, or are involved in, leasing and valuation matters.\\u00a0PM will also review declarations required for property transactions for Ministers and PAP MPs. \\n\\n3\\ufe0f\\u20e3 *Both rental transactions had kept to Singapore Land Authority's (SLA) prevailing guidelines.*\\n\\nSM Teo said that the rental of the two properties did not deviate from prevailing SLA guidelines for renting out black-and-white bungalows for residential purposes. He added that both properties were within the maximum allowable tenancy of 3+3+3 years for residential properties rented out by SLA or SLA\\u2019s managing agents at any one time. \\n\\n\\ud83d\\udd14 *The Parliament discussion on Ridout Road is still ongoing. Watch the discussion live here:* https://www.youtube.com/watch?v=xn7sGrmdpTw \\ud83d\\udd14\\n\\n\\ud83d\\udc49\\ud83c\\udffc  *ST live summary on the Parliament discussion* https://www.straitstimes.com/ridout-road-bungalow-rentals-parliament-live-blog\\n\\n\\ud83d\\udc49\\ud83c\\udffc *Findings from CPIB and SM Teo's reviews*\\nhttps://www.pmo.gov.sg/Newsroom/Rental-of-State-Properties-at-Ridout-Road-by-Min-Shanmugam-and-Min-Vivian-Balakrishnan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_concat\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Contributor255: https://www.channelnewsasia.com/singapore/ridout-road-properties-officers-privileged-information-declaration-renting-government-sm-teo-3602056?cid=internal_sharetool_iphone_03072023_cnaThis directly address Point 2 for me that there are gaps and as such , the integrity is left in a question mark here for the 2 ministers instead of it being iron clad there was none .\\nContributor813: For a second point, why should the ministers not have bought their own private properties elsewhere to stay in, if the primary motive for minister Shanmugum was to monetize his home.\\nContributor255: https://www.channelnewsasia.com/singapore/ridout-road-sla-rent-black-white-bungalow-longer-lease-en-bloc-3602066?cid=internal_sharetool_iphone_03072023_cna\\nContributor813: I can accept minister balakrishnan saying that he wished to house multiple generations all in a home. Even if this is a privileged choice he can make there is nothing inherent to disagree about.\\nContributor255: The question for his long leases is whether this is knee jerk to the questions asked about the value of the refurbishment or SLA can show this was in the works a few years ago and still in planning stages\\nContributor389: Partly the way SLA handle the initial response to the allegation was rather poorly done imho\\nContributor57: did he shed a tear when he said this?\\nContributor813: I think the word privileged came out of his mouth. At any rate his home is much more aligned with the rest of the SLA properties being rented out. minister Shanmugum has all those arrangements which have a lot of attention being drawn to it.So the credible prospects can read all the contents of the list, and indeed all the managing agents possess such a list and publicize it. Do they publicize this in lockstep with SLA\\u2019s decisions to not list or to list? Otherwise it sounds like the strategy to not allow supply to cannibalize demand would be highly ineffective and any marketing in this manner would not work.If the Managing agents do manage themselves without direction from SLA, and publicize the properties so as to \\u201cmaximize the rental and occupancy\\u201d, does SLA defer to the managing agents who are \\u201cthe professionals\\u201d, as ostensibly stated by Minister Tong, or does SLA hold an independent marketing strategy and decide this themselves?\\nContributor16: the toxicities here , impressive !\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<s>[INST]Determine whether Contributor16 holds the same view as this statement: 'Contributor had differing opinions on whether the process for renting out the Ridout Road properties was fair.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 16 and other contributors: \\n Contributor255: https://www.channelnewsasia.com/singapore/ridout-road-properties-officers-privileged-information-declaration-renting-government-sm-teo-3602056?cid=internal_sharetool_iphone_03072023_cnaThis directly address Point 2 for me that there are gaps and as such , the integrity is left in a question mark here for the 2 ministers instead of it being iron clad there was none .\\nContributor813: For a second point, why should the ministers not have bought their own private properties elsewhere to stay in, if the primary motive for minister Shanmugum was to monetize his home.\\nContributor255: https://www.channelnewsasia.com/singapore/ridout-road-sla-rent-black-white-bungalow-longer-lease-en-bloc-3602066?cid=internal_sharetool_iphone_03072023_cna\\nContributor813: I can accept minister balakrishnan saying that he wished to house multiple generations all in a home. Even if this is a privileged choice he can make there is nothing inherent to disagree about.\\nContributor255: The question for his long leases is whether this is knee jerk to the questions asked about the value of the refurbishment or SLA can show this was in the works a few years ago and still in planning stages\\nContributor389: Partly the way SLA handle the initial response to the allegation was rather poorly done imho\\nContributor57: did he shed a tear when he said this?\\nContributor813: I think the word privileged came out of his mouth. At any rate his home is much more aligned with the rest of the SLA properties being rented out. minister Shanmugum has all those arrangements which have a lot of attention being drawn to it.So the credible prospects can read all the contents of the list, and indeed all the managing agents possess such a list and publicize it. Do they publicize this in lockstep with SLA\\u2019s decisions to not list or to list? Otherwise it sounds like the strategy to not allow supply to cannibalize demand would be highly ineffective and any marketing in this manner would not work.If the Managing agents do manage themselves without direction from SLA, and publicize the properties so as to \\u201cmaximize the rental and occupancy\\u201d, does SLA defer to the managing agents who are \\u201cthe professionals\\u201d, as ostensibly stated by Minister Tong, or does SLA hold an independent marketing strategy and decide this themselves?\\nContributor16: the toxicities here , impressive ! [/INST]0</s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_full_df_sampled = stratified_sample(augmented_full_df, 'stance', 'human_label', frac=0.3, random_state=42)\n",
        "augmented_full_df_sampled.shape"
      ],
      "metadata": {
        "id": "Ms43bpv7KshX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773889554,
          "user_tz": -480,
          "elapsed": 8425,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1ce55c47-9e4e-4a8a-d55f-28aec1986b36"
      },
      "id": "Ms43bpv7KshX",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-89bc82edf383>:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(n=min(samples_per_group, len(x)), random_state=random_state))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9082, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stratified_test = test_data.copy().sample(frac=0.1)[[ 'stance', 'prompt', 'label']].reset_index(drop=True)\n",
        "stratified_test[\"prompt\"] = stratified_test[[\"prompt\", \"label\"]].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n",
        "print(stratified_test.prompt.loc[0][-20:])\n",
        "print(stratified_test.shape)\n",
        "list(stratified_test.prompt.values)[0][-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "lpG_kNEpAMLn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773889554,
          "user_tz": -480,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2f795495-1ff7-4c43-9a19-183fb1762c1e"
      },
      "id": "lpG_kNEpAMLn",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "selves. [/INST]1</s>\n",
            "(135, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e12aee7e73d4>:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  stratified_test[\"prompt\"] = stratified_test[[\"prompt\", \"label\"]].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.concat([\n",
        "    train_data[['chat_group_id', 'label', 'stance', 'prompt', 'human_label', 'topic_group', 'agreement', 'user', 'group_user', 'topic']],\n",
        "    #augmented_full_df[['chat_group_id',  'stance', 'content', 'class', 'context', 'human_label']].rename({'class': 'label'}, axis=1)\n",
        "    augmented_full_df_sampled[[  'stance', 'prompt', 'label', 'human_label']],\n",
        "    stratified_test\n",
        "    ]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "#df = train_data[['chat_group_id', 'label', 'stance', 'prompt', 'human_label', 'topic_group', 'agreement', 'user', 'group_user', 'topic']].loc[:100]\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "3Fnp9nEo-NLc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773890452,
          "user_tz": -480,
          "elapsed": 900,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b89348a9-546e-4f31-9674-349e95f8d92b"
      },
      "id": "3Fnp9nEo-NLc",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   chat_group_id  label                                             stance  \\\n",
              "0            1.0      0  Contributor shared different perspectives on p...   \n",
              "1            1.0      0  Contributor expressed differing levels of trus...   \n",
              "\n",
              "                                              prompt human_label  \\\n",
              "0  <s>[INST]Determine whether Contributor429 hold...  no opinion   \n",
              "1  <s>[INST]Determine whether Contributor429 hold...    disagree   \n",
              "\n",
              "    topic_group  agreement                                  user  \\\n",
              "0  national_day  unanimous  04195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "1  national_day   majority  04195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "\n",
              "                              group_user  \\\n",
              "0  104195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "1  104195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "\n",
              "                                               topic  \n",
              "0  *📢 Topic 📢*\\nIn his National Day Message, Prim...  \n",
              "1  *📢 Topic 📢*\\nIn his National Day Message, Prim...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65d59816-7c01-496a-b73b-0246daa7b914\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chat_group_id</th>\n",
              "      <th>label</th>\n",
              "      <th>stance</th>\n",
              "      <th>prompt</th>\n",
              "      <th>human_label</th>\n",
              "      <th>topic_group</th>\n",
              "      <th>agreement</th>\n",
              "      <th>user</th>\n",
              "      <th>group_user</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contributor shared different perspectives on p...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor429 hold...</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>national_day</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>04195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>104195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>*📢 Topic 📢*\\nIn his National Day Message, Prim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contributor expressed differing levels of trus...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor429 hold...</td>\n",
              "      <td>disagree</td>\n",
              "      <td>national_day</td>\n",
              "      <td>majority</td>\n",
              "      <td>04195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>104195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>*📢 Topic 📢*\\nIn his National Day Message, Prim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65d59816-7c01-496a-b73b-0246daa7b914')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65d59816-7c01-496a-b73b-0246daa7b914 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65d59816-7c01-496a-b73b-0246daa7b914');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40ddc586-11b3-4ddc-82b7-bac17b2206ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40ddc586-11b3-4ddc-82b7-bac17b2206ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40ddc586-11b3-4ddc-82b7-bac17b2206ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11657,\n  \"fields\": [\n    {\n      \"column\": \"chat_group_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9309924156889844,\n        \"min\": 1.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          7.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stance\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2662,\n        \"samples\": [\n          \"Contributors highlighted the necessity of enhancing the Progressive Wage Model to ensure that low-wage workers receive a living wage, thereby promoting both economic sustainability and social equity in Singapore.\",\n          \"Contributors advocated for the expansion of affordable public housing options as a vital measure to enhance the quality of life for lower and middle-income families in Singapore.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11657,\n        \"samples\": [\n          \"<s>[INST]Determine whether Contributor761 holds the same view as this statement: 'Contributors emphasized the necessity of integrating mental health education into school curricula to better equip students with coping mechanisms for the pressures of academic life.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 761 and other contributors: \\n Contributor331: Its interesting to consider how an integrated approach to education, combining both STEM and the humanities, could foster critical thinking skills necessary for navigating an increasingly complex world.\\nContributor771: But leh, maybe focusing more on STEM can also prepare students for the jobs of the future, and they can always pick up humanities later, right?\\nContributor838: But hor, maybe not so bad lah, if STEM more focused, can encourage students to be more innovative in their own ways too, right?\\nContributor774: STEM provides essential skills that complement the humanities and arts, much like how a well-rounded meal combines diverse nutrients for overall health.\\nContributor933: While balancing education is crucial, the integration of STEM with real-world applications can enhance critical thinking skills that benefit all areas of study, including the humanities and arts.\\nContributor430: While its true that STEM is highlighted, as Albert Einstein said, Imagination is more important than knowledge. Perhaps fostering creativity alongside STEM could enrich education further.\\nContributor23: While I strongly agree on the importance of coding and digital literacy, I feel we must also emphasize critical thinking skills. Without the ability to analyze and evaluate information, students might find themselves lost in the digital age, just following trends without understanding the implications. A balanced approach can ensure they not only know how to code but can also make informed decisions about the technology they use.\\nContributor823: While coding is useful, can we afford to ignore creative arts that foster innovation and emotional intelligence?\\nContributor338: While investing in coding is valuable, as Einstein said, Education is not the learning of facts, but the training of the mind to think, suggesting we shouldnt lose sight of fostering broader intellectual skills.\\nContributor807: Its great to focus on coding, but what about fostering creativity through arts and sports? Those skills also play a crucial role in holistic development, just like critical thinking.\\nContributor409: While coding may open doors, I often find that the ability to navigate real-life situations, like handling finances or communication, often leads to a more fulfilling life beyond just a job.\\nContributor880: Dont forget that emotional intelligence is equally crucial for success in any job market!\\nContributor37: While coding and digital literacy are undeniably crucial, I wonder how we can ensure that students learn to navigate real-world challenges effectively without overshadowing practical life skills.\\nContributor529: While coding is certainly a valuable skill, I think we also need to consider the impact of creativity and the arts on a students overall development.\\nContributor635: I wonder how skills like teamwork and emotional intelligence, which seem less emphasized, could play a crucial role in today\\u2019s workplace dynamics.\\nContributor348: Aiyoh, but if we stress too much on coding, then what about the softer skills ah? Like how to communicate and work with people?\\nContributor316: Its interesting to think that while coding and digital skills are vital, my own childhood lessons in teamwork and empathy have proven just as crucial in navigating both personal and professional landscapes.\\nContributor188: What about integrating more real-world projects in schools, allowing students to apply coding and digital skills to solve local community issues?\\nContributor772: While coding and digital literacy are important, what about fostering creativity and emotional intelligence in students?But hor, maybe focus on how to teach students to adapt to changes in technology also quite important leh, not just coding itself, you know?\\nContributor409: But if we focus solely on coding, we risk neglecting the development of creativity and interpersonal skills that are just as crucial in todays diverse workplace.\\nContributor520: What about integrating financial literacy and interpersonal skills alongside coding to ensure well-rounded graduates capable of thriving in various aspects of life?\\nContributor338: Focusing solely on coding might overlook the importance of creativity and emotional intelligence in students development.\\nContributor815: While I agree that digital literacy is crucial, Im also concerned that an overemphasis on tech skills might overshadow the importance of interpersonal skills, which are equally vital in navigating todays complex work environments.\\nContributor770: While digital skills are crucial, its also worth considering how traditional subjects can foster creativity and emotional intelligence, which are equally valuable in the evolving job landscape.\\nContributor93: While coding is important, Id argue that fostering creativity through the arts and humanities might actually fuel innovation more than just digital skills alone.\\nContributor348: But hor, we also must consider if the focus on coding takes away time from other subjects that teach creativity and sports, leh.\\nContributor356: While coding is undeniably crucial, I sometimes wonder if we risk overshadowing hands-on experiences like cooking or budgeting, which are equally vital for real-world preparedness.\\nContributor93: Balance is indeed crucial, but as Albert Einstein said, Education is not the learning of facts, but the training of the mind to think. Perhaps we should prioritize critical thinking over coding.\\nContributor520: It might also be worth considering how integrating experiential learning and real-world applications into the curriculum could enhance both digital literacy and life skills simultaneously.\\nContributor871: It might also be worth considering how integrating outdoor education and experiential learning experiences could enhance overall student engagement and personal development alongside coding and digital literacy.While coding and digital literacy are indeed crucial, its also interesting to consider how integrating creative subjects might foster innovation alongside those skills.\\nContributor506: Eh, I totally agree lah, mental health education in schools super important. But hor, I think we also need to focus on making sure teachers are trained properly to help students, you know? Must have proper support system in place, not just teach syllabus and go home.Yah, like that also got coaching, not just talk about mental health, must have real-life situations that students can relate to. Then they can learn how to handle stress from exams and peer pressure better, not just theory then forget one.If we just teach coping mechanisms but don\\u2019t have follow-up support, like counseling or peer support groups, then I feel its kinda pointless. Must be holistic approach lah, otherwise students still feel alone when they struggle.And hor, I think maybe also need to include parents in this education. Like have workshops for them to understand mental health better and how to support their kids. Sometimes parents pressure them too much without realizing it.In Singapore, we stress so much on academic results, but must remember mental health also plays a big role in achieving those results. Integration of mental health into the curriculum should not be just a checkbox, but something significantly impactful.Speaking from experience, if we teach mental health, must also create a culture in school where its okay to talk about feelings and struggles. Cannot have students fearing to voice out, otherwise they will just bottle it up, which is very unhealthy lah.\\nContributor663: I wonder if practical workshops on stress management outside of traditional classes could also engage students in a different way, showing them real-life applications.\\nContributor761: Sometimes, its worth considering whether mental health education should also include topics on resilience and adaptability in the face of failure, rather than just coping strategies.\\n\\n\\nContributor995: The focus should really be on enhancing academic support rather than mental health education.\\nContributor893: I feel like while mental health education is essential, it could also be beneficial to incorporate practical life skills like time management and financial literacy, which could alleviate some of the stress students face in academics.\\nContributor756: While mental health education is crucial, perhaps we should also consider the role of family support in developing these coping mechanisms, as seen in programs that incorporate parental involvement, which have shown positive outcomes in student resilience.\\nContributor132: While integrating mental health education in schools is crucial, I wonder if we also need to consider the role of parents in reinforcing these lessons at home, much like how my own parents stressed the importance of emotional resilience amidst academic challenges.\\nContributor761: What if we also included practical workshops alongside the theory? [/INST]1</s>\",\n          \"<s>[INST]Determine whether Contributor684 holds the same view as this statement: 'Contributors expressed concerns over rising healthcare costs, highlighting that the affordability of medical services is increasingly out of reach for many Singaporeans, especially the elderly and low-income families.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 684 and other contributors: \\n Contributor509: While some may be concerned about foreign labor policies, its important to recognize how these policies can drive innovation and create more competitive markets, ultimately benefiting local workers through enhanced job opportunities in emerging industries.\\nContributor818: Its like when youre baking a cake and you realize youve added too much of one ingredient; sometimes tightening things up can make it harder for the cake to rise, just like tighter policies can limit job growth for locals.Its worth considering that while foreign labor policies might impact local employment, they can also drive innovation and productivity, benefiting the economy as a whole.\\nContributor125: While I understand those concerns, Ive seen that in some industries, foreign labor can also help fill skill gaps that local workers might not want to pursue, much like how I took on different roles in my career to adapt to changing job demands.\\nContributor199: While concerns about foreign labor policies are valid, one must also consider how the integration of skilled foreign workers can drive innovation and elevate the competitive edge of local industries, potentially leading to more diverse job opportunities in the long term.\\nContributor818: Sometimes the best way to predict the future is to create it, and perhaps its worth exploring how we can innovate our industries to both uplift local workers and adapt to a changing economy.\\nContributor899: While its essential to consider local employment, one might also reflect on how industries such as construction and hospitality depend heavily on foreign labor to meet demands and sustain growth.\\nContributor732: I think its important to acknowledge that the government has made considerable efforts to communicate policies to the public, especially through public consultations and various outreach programs. Many citizens might not be aware of all the channels available for them to provide feedback and engage with policy-making processes., In addition, transparency does not mean that every single detail should be disclosed to the public; it\\u2019s about finding a balance between essential information and operational confidentiality. The government often has to make tough decisions, and sometimes that requires a level of discretion that might not always feel transparent., Moreover, I believe that the communication style of the government might not resonate with everyone. The government provides information through various platforms, yet some citizens still choose not to engage or to seek out that information. It\\u2019s crucial for us, as citizens, to take the initiative to understand the policies affecting us rather than solely relying on the government to provide this information.\\nContributor760: Its essential to recognize that the government often provides ample platforms for public engagement, like town hall meetings and feedback surveys, where citizens can express their views and ask questions about policy formation.\\nContributor935: \\u6216\\u8bb8\\u6709\\u4e9b\\u653f\\u7b56\\u662f\\u4e3a\\u4e86\\u66f4\\u5feb\\u5730\\u5e94\\u5bf9\\u53d8\\u5316\\u800c\\u505a\\u51fa\\u7684\\uff0c\\u4f46\\u4e5f\\u5e0c\\u671b\\u80fd\\u6709\\u66f4\\u591a\\u7684\\u4fe1\\u606f\\u5206\\u4eab\\u3002\\nContributor827: Its interesting to think about how in my personal life, sometimes the decisions made by my family or friends arent shared in detail, yet we trust each other to make choices that we believe are for the best.\\nContributor725: But I wonder if the same frustration isnt something we also face in our own workplaces, where decisions are made without clear communication, leaving us speculating about the reasoning behind those choices.\\nContributor543: Its important to consider that while transparency is crucial, there are also complexities in policymaking that may not be easily communicated to the public without oversimplifying the issues at hand.\\nContributor964: Perhaps the focus should also be on how we can actively engage with our government to enhance that transparency ourselves.\\nContributor12: The governments efforts to engage with the community through various channels really show their commitment to transparency.\\nContributor602: Perhaps there are aspects of government decision-making that benefit from a level of confidentiality, ensuring that strategies and discussions can unfold without external pressure.\\nContributor964: \\u6216\\u8bb8\\u9664\\u4e86\\u900f\\u660e\\u5ea6\\uff0c\\u6211\\u4eec\\u4e5f\\u5e94\\u8be5\\u5173\\u6ce8\\u516c\\u4f17\\u5728\\u653f\\u7b56\\u5f62\\u6210\\u8fc7\\u7a0b\\u4e2d\\u7684\\u53c2\\u4e0e\\u5ea6\\uff0c\\u4ece\\u800c\\u66f4\\u597d\\u5730\\u5efa\\u7acb\\u4fe1\\u4efb\\u3002\\nContributor529: I completely agree that we need enhanced mental health services, but we must also focus on accessibility. For instance, while there are more therapists available now, how many of them can be easily reached by those living in less accessible areas of Singapore?\\nContributor557: Absolutely, but we should also consider integrating mental health education into school curriculums to build resilience from a young age, like how character and citizenship education has evolved.\\nContributor949: While its crucial to enhance mental health services, we should also consider how fostering community connections can play a significant role in preventing mental health issues from arising in the first place.\\nContributor924: It\\u2019s interesting to consider how integrating mental health education into schools could provide preventative support rather than just reactive measures later in life.\\nContributor347: Maybe people just need to adapt better to changes instead of relying on external support.\\nContributor805: While its important to acknowledge mental health, perhaps focusing on strengthening community ties and fostering resilience could be a more proactive approach rather than solely relying on enhanced services.\\nContributor949: Perhaps we should also consider how the greatest weapon against stress is our ability to choose one thought over another. Investing not just in services, but in our mindset, could be pivotal in navigating our mental health landscape.\\nContributor637: While addressing mental health is crucial, we should also consider the role of physical health and fitness in enhancing overall well-being, as both aspects are interconnected.\\nContributor557: Perhaps we should also consider integrating mental health education into our school curriculum to foster resilience from a young age.\\nContributor586: Have we considered the role of community initiatives in supporting mental health alongside professional services?\\nContributor924: Its interesting to consider that while enhancing mental health services is crucial, we also need to focus on integrating mental well-being into everyday community interactions and fostering environments that promote open conversations about mental health.\\nContributor545: \\u6211\\u4eec\\u53ef\\u80fd\\u9700\\u8981\\u66f4\\u591a\\u7684\\u5173\\u6ce8\\u5728\\u9884\\u9632\\u548c\\u6559\\u80b2\\u4e0a\\uff0c\\u800c\\u4e0d\\u662f\\u4ec5\\u4ec5\\u589e\\u5f3a\\u670d\\u52a1\\uff0c\\u6bd5\\u7adf\\u5fc3\\u7406\\u5065\\u5eb7\\u7684\\u7ef4\\u62a4\\u4e5f\\u53ef\\u4ee5\\u901a\\u8fc7\\u65e5\\u5e38\\u751f\\u6d3b\\u4e2d\\u7684\\u5c0f\\u6539\\u53d8\\u6765\\u5b9e\\u73b0\\u3002\\nContributor949: While I see the importance of enhancing mental health services, I believe we also need to focus on community engagement initiatives that foster real connections, as personal experiences have shown me that supportive friendships can significantly alleviate mental strain.\\nContributor810: I think the focus should also be on preventive healthcare measures to reduce long-term costs. It\\u2019s about keeping people healthy in the first place., I believe that while medical costs are rising, we could also look at enhancing community health programs that provide services at lower costs for the elderly.Its worth considering how investing in preventive care could alleviate some of the financial burdens in the long run.\\nContributor507: What if we explored alternative healthcare delivery models that could alleviate some of these costs for the elderly and low-income families?\\nContributor460: Isnt it worth considering that advancements in medical technology and treatments can often lead to better outcomes, which might justify some of the costs?\\nContributor507: Health is wealth, and as Benjamin Franklin once said, An ounce of prevention is worth a pound of cure; perhaps we should consider investing more in preventive healthcare to mitigate costs in the long run.\\nContributor684: Its like how some people choose to go to hawker centres for more affordable meals, but as costs rise, they might have to adjust their budgets or frequency of eating out.\\n\\n\\nContributor810: While its essential to address rising costs, we must also remember that an ounce of prevention is worth a pound of cure, and focusing on preventive healthcare could alleviate some financial burdens down the line.\\nContributor962: Its essential to explore innovative healthcare models that could ease the burden on families while ensuring quality care.\\nContributor723: Having access to quality healthcare can really be a great equalizer; as they say, An ounce of prevention is worth a pound of cure.\\nContributor684: Have we considered how leveraging technology and telemedicine could potentially alleviate some of these rising costs in healthcare services? [/INST]0</s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"disagree\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"national_day\",\n          \"budget\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agreement\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"majority\",\n          \"unanimous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 229,\n        \"samples\": [\n          \"cb58a6f8-2604-4b8d-a0d9-b9718cc134af\",\n          \"5419fb94-a5af-46ee-b019-ee1e52cc006e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group_user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 234,\n        \"samples\": [\n          \"45419fb94-a5af-46ee-b019-ee1e52cc006e\",\n          \"20c58c1ab-6e81-406a-9609-21b23cad0f62\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\\u5927\\u5bb6\\u597d\\uff0c\\u6b22\\u8fce\\u56de\\u6765\\uff01 \\u4eca\\u5929\\u8ba8\\u8bba\\u7684\\u8bdd\\u9898\\u662f\\uff1a\\n\\n*\\u56fd\\u5e86\\u732e\\u8bcd*\\n\\n\\u653f\\u5e9c\\u5c06\\u8c03\\u6574\\u7ec4\\u5c4b\\u653f\\u7b56\\uff0c\\u786e\\u4fdd\\u653f\\u7b56\\u516c\\u5e73\\u548c\\u5305\\u5bb9\\uff0c\\u540c\\u65f6\\u5b8c\\u5584\\u516c\\u79ef\\u91d1\\u5236\\u5ea6\\uff0c\\u786e\\u4fdd\\u5e74\\u957f\\u4f1a\\u5458\\u6709\\u8db3\\u591f\\u516c\\u79ef\\u91d1\\u517b\\u8001\\u3002\\u674e\\u663e\\u9f99\\u603b\\u7406\\u4f1a\\u5728\\u56fd\\u5e86\\u7fa4\\u4f17\\u5927\\u4f1a\\u4e0a\\u8bf4\\u660e\\u653f\\u5e9c\\u7684\\u8ba1\\u5212\\u3002\\n\\n\\u8fc7\\u53bb\\u4e00\\u5e74\\uff0c\\u4f4f\\u623f\\u4f9b\\u5e94\\u548c\\u4ef7\\u683c\\u8d70\\u52bf\\u53d7\\u5230\\u65b0\\u52a0\\u5761\\u4eba\\u9ad8\\u5ea6\\u5173\\u6ce8\\u3002\\u674e\\u603b\\u7406\\u5728\\u661f\\u671f\\u4e8c\\uff088\\u67088\\u65e5\\uff09\\u53d1\\u8868\\u7684\\u56fd\\u5e86\\u732e\\u8bcd\\u4e2d\\uff0c\\u91cd\\u70b9\\u8c08\\u5230\\u4f4f\\u623f\\u8bfe\\u9898\\u3002\\u4ed6\\u91cd\\u7533\\uff0c\\u5373\\u4f7f\\u5927\\u73af\\u5883\\u4e0d\\u65ad\\u53d8\\u5316\\uff0c\\u653f\\u5e9c\\u4ecd\\u5fc5\\u987b\\u786e\\u4fdd\\u5404\\u4e2a\\u6536\\u5165\\u9636\\u5c42\\u7684\\u56fd\\u4eba\\uff0c\\u90fd\\u80fd\\u4e70\\u5f97\\u5230\\u548c\\u4e70\\u5f97\\u8d77\\u653f\\u5e9c\\u7ec4\\u5c4b\\u3002\\n\\n\\ud83d\\udcac *\\u60a8\\u5bf9\\u674e\\u603b\\u7406\\u7684\\u56fd\\u5e86\\u732e\\u8bcd\\u6709\\u4ec0\\u4e48\\u60f3\\u6cd5\\uff1f \\u653f\\u5e9c\\u8fd8\\u80fd\\u591f\\u901a\\u8fc7\\u54ea\\u4e9b\\u65b9\\u6cd5\\u6276\\u6301\\u8001\\u9f84\\u5316\\u7684\\u4eba\\u53e3\\uff0c\\u4ee5\\u53ca\\u786e\\u4fdd\\u516c\\u5171\\u4f4f\\u5c4b\\u653f\\u7b56\\u80fd\\u53cd\\u6620\\u6c11\\u95f4\\u7684\\u73b0\\u5b9e\\u60c5\\u51b5\\u548c\\u4eba\\u4eec\\u7684\\u671f\\u671b\\uff1f*\\n\\n\\ud83d\\udccc *\\u516c\\u5171\\u7ec4\\u5c4b*\\n\\u56fd\\u5bb6\\u53d1\\u5c55\\u90e8\\u957f\\u674e\\u667a\\u965e\\u53bb\\u5e74\\u5e95\\u63a5\\u53d7\\u5a92\\u4f53\\u8bbf\\u95ee\\u65f6\\u66fe\\u900f\\u9732\\uff0c\\u5f53\\u5c40\\u6b63\\u5728\\u63a2\\u8ba8\\u6709\\u5173\\u516c\\u5171\\u4f4f\\u5c4b\\u653f\\u7b56\\u7684\\u6570\\u9879\\u6539\\u9769\\uff0c\\u5305\\u62ec\\u6210\\u719f\\u548c\\u975e\\u6210\\u719f\\u5e02\\u9547\\u7684\\u5206\\u7c7b\\uff0c\\u800c\\u6311\\u6218\\u5728\\u4e8e\\u786e\\u4fdd\\u5206\\u7c7b\\u80fd\\u53cd\\u6620\\u6c11\\u95f4\\u7684\\u73b0\\u5b9e\\u60c5\\u51b5\\u548c\\u4eba\\u4eec\\u7684\\u671f\\u671b\\u3002\\u4ed6\\u5f53\\u65f6\\u8bf4\\uff0c\\u4e00\\u4e2a\\u53ef\\u80fd\\u7684\\u5206\\u7c7b\\u65b9\\u5f0f\\uff0c\\u662f\\u6839\\u636e\\u6bcf\\u4e2a\\u9879\\u76ee\\u7684\\u6761\\u4ef6\\u8fdb\\u884c\\u5206\\u7c7b\\uff0c\\u4f46\\u8fd9\\u6709\\u5f85\\u7814\\u7a76\\u3002\\n\\n\\ud83d\\udccc *\\u6276\\u6301\\u8001\\u9f84\\u5316\\u4eba\\u53e3*\\n\\u56fd\\u5e86\\u732e\\u8bcd\\u4e2d\\u805a\\u7126\\u7684\\u53e6\\u4e00\\u4e2a\\u8bfe\\u9898\\u662f\\u517b\\u8001\\u8bfe\\u9898\\u3002\\u674e\\u603b\\u7406\\u8bf4\\uff0c\\u653f\\u5e9c\\u9010\\u6b65\\u6539\\u5584\\u516c\\u79ef\\u91d1\\u5236\\u5ea6\\uff0c\\u786e\\u4fdd\\u65b0\\u52a0\\u5761\\u4eba\\u5728\\u5c31\\u4e1a\\u65f6\\u671f\\u6709\\u8db3\\u591f\\u7684\\u50a8\\u84c4\\uff0c\\u53e6\\u4e00\\u65b9\\u9762\\u4e5f\\u901a\\u8fc7\\u5c31\\u4e1a\\u5956\\u52b1\\u8ba1\\u5212\\u548c\\u6e10\\u8fdb\\u5f0f\\u85aa\\u91d1\\u6a21\\u5f0f\\u7b49\\u63aa\\u65bd\\uff0c\\u4e3a\\u4f4e\\u6536\\u5165\\u5458\\u5de5\\u63d0\\u4f9b\\u63f4\\u52a9\\u3002\\n\\n\\u674e\\u603b\\u7406\\u4e5f\\u8bf4\\uff0c\\u653f\\u5e9c\\u6b63\\u91c7\\u53d6\\u63aa\\u65bd\\uff0c\\u6253\\u9020\\u66f4\\u4eb2\\u4e50\\u9f84\\u7ec4\\u5c4b\\u548c\\u793e\\u533a\\uff0c\\u5305\\u62ec\\u5174\\u5efa\\u66f4\\u591a\\u4f11\\u606f\\u7ad9\\u3001\\u89c4\\u5212\\u66f4\\u591a\\u884c\\u4eba\\u4e13\\u7528\\u533a\\uff0c\\u4ee5\\u53ca\\u5b8c\\u5584\\u90bb\\u91cc\\u793e\\u533a\\u7a7a\\u95f4\\u7684\\u8bbe\\u8ba1\\uff0c\\u548c\\u5f00\\u8bbe\\u66f4\\u591a\\u6d3b\\u8dc3\\u4e50\\u9f84\\u4e2d\\u5fc3\\u3002\\n\\n\\ud83d\\udccc *\\u653f\\u5e9c\\u786e\\u4fdd\\u6211\\u56fd\\u5236\\u5ea6\\u7ef4\\u6301\\u5ec9\\u6d01\\u7684\\u51b3\\u5fc3*\\n\\u674e\\u603b\\u7406\\u8bf4\\uff0c\\u8fd1\\u671f\\u53d1\\u751f\\u7684\\u95ee\\u9898\\u65f6\\u4e0d\\u65f6\\u4f1a\\u51fa\\u73b0\\u3002\\u4ed6\\u5f3a\\u8c03\\uff0c\\u5f53\\u4e8b\\u4ef6\\u53d1\\u751f\\u65f6\\uff0c\\u653f\\u5e9c\\u4e00\\u76f4\\u90fd\\u4ee5\\u59a5\\u5f53\\u3001\\u516c\\u5f00\\u7684\\u65b9\\u5f0f\\u5904\\u7406\\uff0c\\u5728\\u8fd1\\u51e0\\u6b21\\u4e8b\\u4ef6\\u4e0a\\u4e5f\\u4e0d\\u4f8b\\u5916\\u3002\\n\\n\\u674e\\u603b\\u7406\\u8bf4\\uff0c\\u53ea\\u6709\\u81f4\\u529b\\u7ef4\\u6301\\u9ad8\\u6807\\u51c6\\uff0c\\u624d\\u80fd\\u7ef4\\u62a4\\u65b0\\u52a0\\u5761\\u4eba\\u5bf9\\u653f\\u5e9c\\u548c\\u56fd\\u5bb6\\u4f53\\u5236\\u7684\\u4fe1\\u5fc3\\uff0c\\u52a0\\u5f3a\\u6c11\\u4f17\\u5bf9\\u653f\\u5e9c\\u7684\\u4fe1\\u4efb\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u674e\\u603b\\u7406\\u56fd\\u5e86\\u732e\\u8bcd\\uff1a\\u8c03\\u6574\\u7ec4\\u5c4b\\u4e0e\\u516c\\u79ef\\u91d1\\u653f\\u7b56\\u786e\\u4fdd\\u516c\\u5e73\\u5305\\u5bb9\\u3011\\uff1a https://www.zaobao.com.sg/news/singapore/story20230809-1421915\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u674e\\u603b\\u7406\\uff1a\\u653f\\u5e9c\\u51b3\\u5fc3\\u786e\\u4fdd\\u6211\\u56fd\\u5236\\u5ea6\\u7ef4\\u6301\\u5ec9\\u6d01\\u6b63\\u76f4\\u6709\\u8bda\\u4fe1\\u3011\\uff1a https://www.zaobao.com.sg/news/singapore/story20230809-1421917\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u603b\\u7406\\u56fd\\u5e86\\u732e\\u8bcd - \\u4eba\\u6c11\\u548c\\u653f\\u5e9c\\u7d27\\u5bc6\\u5408\\u4f5c\\u662f\\u65b0\\u52a0\\u5761\\u4f18\\u52bf \\u5e94\\u597d\\u597d\\u5b88\\u62a4\\u3011\\nhttps://www.zaobao.com.sg/realtime/singapore/story20230808-1421820\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u89c2\\u770b\\uff1a\\u7531\\u526f\\u603b\\u7406\\u9ec4\\u5faa\\u8d22\\u5ba3\\u8bfb\\u7684\\u56fd\\u5e86\\u732e\\u8bcd\\u3011\\uff1ahttps://www.pmo.gov.sg/Newsroom/National-Day-Message-2023-Chinese \\u200e<This message was edited>\",\n          \"\\u5927\\u5bb6\\u597d\\uff0c\\u6b22\\u8fce\\u56de\\u6765! \\u6211\\u4eec\\u5c06\\u5f00\\u653e\\u7fa4\\u804a\\u8fdb\\u884c\\u8ba8\\u8bba\\u81f3\\u508d\\u665a7\\u70b9\\u3002\\u4eca\\u5929\\u7684\\u8ba8\\u8bba\\u8bfe\\u9898\\u662f\\uff1a\\n\\n\\ud83d\\udcac2023 \\u5e74\\u9884\\u7b97\\u6848\\u4e2d\\u7684\\u54ea\\u4e9b\\u63aa\\u65bd\\u5f15\\u8d77\\u60a8\\u7684\\u5171\\u9e23\\uff1f\\n\\n\\ud83d\\udccc \\u7f13\\u901a\\u80c0\\uff1a\\u66f4\\u591a\\u8865\\u52a9\\u6e21\\u96be\\u5173\\n- \\u5f3a\\u5316\\u6c38\\u4e45\\u6027\\u6d88\\u8d39\\u7a0e\\u8865\\u52a9\\u5238\\uff08GSTV\\uff09\\u8ba1\\u5212\\uff0c\\u4ee5\\u7ee7\\u7eed\\u5e2e\\u52a9\\u7b26\\u5408\\u8d44\\u683c\\u7684\\u5bb6\\u5ead\\uff0c\\u5e94\\u4ed8\\u6d88\\u8d39\\u7a0e\\u3002\\n- \\u5728\\u5b9a\\u5fc3\\u4e0e\\u63f4\\u52a9\\u914d\\u5957\\uff08Assurance Package\\uff09\\u4e0b\\uff0c \\u7b26\\u5408\\u8d44\\u683c\\u7684\\u65b0\\u52a0\\u5761\\u4eba\\u63a5\\u4e0b\\u6765\\u53ef\\u83b7\\u5f97\\u7684\\u73b0\\u91d1\\u8865\\u52a9\\u5c06\\u589e\\u52a0\\u4ecb\\u4e8e300\\u5143\\u5230650\\u5143\\u3002\\u6b64\\u5916\\uff0c\\u653f\\u5e9c\\u660e\\u5e74\\u63d0\\u4f9b\\u7684\\u793e\\u533a\\u53d1\\u5c55\\u7406\\u4e8b\\u4f1a\\u90bb\\u91cc\\u8d2d\\u7269\\u5238\\u5c06\\u589e\\u52a0100\\u5143\\n- \\u6bcf\\u540d\\u7b26\\u5408\\u8d44\\u683c\\u7684\\u65b0\\u52a0\\u5761\\u4eba\\uff0c\\u5c06\\u53ef\\u83b7\\u5f97\\u4ecb\\u4e8e200\\u5143\\u5230400\\u5143\\u7684\\u751f\\u6d3b\\u8d39\\u7279\\u522b\\u8865\\u52a9 (Cost-of-Living Special Payment\\uff09\\u3002\\u7b26\\u5408\\u8d44\\u683c\\u768455\\u5c81\\u53ca\\u4ee5\\u4e0a\\u56fd\\u4eba\\uff0c\\u5219\\u53ef\\u989d\\u5916\\u83b7\\u5f97200\\u5143\\u5230300\\u5143\\u7684\\u6d25\\u8d34\\u3002\\n\\n\\ud83d\\udccc \\u5174\\u7ecf\\u6d4e\\uff1a\\u52a9\\u4f01\\u4e1a\\u521b\\u65b0\\u817e\\u98de \\uff0c\\u8ba9\\u5458\\u5de5\\u518d\\u57f9\\u8bad\\u529b\\u4e89\\u4e0a\\u6e38\\n- \\u57282023\\u5e74\\u7684\\u8d22\\u653f\\u9884\\u7b97\\u6848\\u4e2d\\uff0c\\u653f\\u5e9c\\u4e3a\\u5168\\u56fd\\u751f\\u4ea7\\u529b\\u57fa\\u91d1\\u6ce8\\u5165\\u8d44\\u91d1\\uff0c\\u4e5f\\u65b0\\u63a8\\u51fa\\u4f01\\u4e1a\\u521b\\u65b0\\u8ba1\\u5212\\uff0c\\u4ee5\\u534f\\u52a9\\u672c\\u5730\\u4f01\\u4e1a\\u53d6\\u5f97\\u8d44\\u91d1\\uff0c\\u5c55\\u5f00\\u66f4\\u591a\\u521b\\u65b0\\u6d3b\\u52a8\\u3002\\u9664\\u4e86\\u79ef\\u6781\\u9f13\\u52b1\\u4f01\\u4e1a\\u521b\\u65b0\\u4ee5\\u5916\\uff0c\\u653f\\u5e9c\\u4e5f\\u901a\\u8fc7\\u4e24\\u9879\\u62e8\\u6b3e\\u534f\\u52a9\\u672c\\u5730\\u4f01\\u4e1a\\u6269\\u5927\\u89c4\\u6a21\\uff0c\\u6253\\u9020\\u56fd\\u9645\\u7ade\\u4e89\\u529b\\u3002\\n- \\u4e3a\\u786e\\u4fdd\\u5458\\u5de5\\u7684\\u6280\\u80fd\\u66f4\\u8d34\\u8fd1\\u5e02\\u573a\\u7684\\u5b9e\\u9645\\u9700\\u6c42\\uff0c\\u653f\\u5e9c\\u5c06\\u6210\\u7acb\\u5c31\\u4e1a\\u4e0e\\u57f9\\u8bad\\u534f\\u8c03\\u5904\\uff0c\\u901a\\u8fc7\\u57f9\\u8bad\\u4e0e\\u884c\\u4e1a\\u7684\\u914d\\u5bf9\\uff0c\\u4e3a\\u4f01\\u4e1a\\u5458\\u5de5\\u5e26\\u6765\\u66f4\\u597d\\u7684\\u85aa\\u8d44\\u6536\\u5165\\u548c\\u5c31\\u4e1a\\u524d\\u666f\\u3002\\n- \\u4e3a\\u4f4e\\u85aa\\u5de5\\u53cb\\uff0c\\u5e74\\u957f\\u8005\\uff0c\\u6b8b\\u75be\\u4eba\\u58eb\\u4e0e\\u524d\\u56da\\u72af\\u63d0\\u4f9b\\u5c31\\u4e1a\\u5e2e\\u52a9\\n\\n\\ud83d\\udccc \\u52a0\\u5f3a\\u793e\\u4f1a\\u5951\\u7ea6\\n- \\u5e2e\\u52a9\\u56fd\\u4eba\\u8fbe\\u6210\\u8d2d\\u5c4b\\u7406\\u60f3\\uff1a \\u4e3a40\\u5c81\\u53ca\\u4ee5\\u4e0b\\u5e74\\u8f7b\\u592b\\u5987\\u53ca\\u6709\\u5b69\\u5b50\\u7684\\u9996\\u8d2d\\u5bb6\\u5ead\\u63d0\\u4f9b\\u7533\\u8d2d\\u9996\\u4e2a\\u9884\\u8d2d\\u7ec4\\u5c4b\\u7684\\u989d\\u5916\\u62bd\\u7b7e\\u673a\\u4f1a\\u3002\\u5728\\u516c\\u79ef\\u91d1\\u8d2d\\u5c4b\\u6d25\\u8d34\\u4e0b\\uff0c\\u9996\\u6b21\\u8d2d\\u5c4b\\u5bb6\\u5ead\\u4e70\\u8f6c\\u552e\\u7ec4\\u5c4b\\uff0c\\u516c\\u79ef\\u91d1\\u8d2d\\u5c4b\\u6d25\\u8d34\\u589e\\u52a0\\u591a\\u8fbe3\\u4e07\\u5143\\u3002\\n- \\u9f13\\u52b1\\u56fd\\u4eba\\u751f\\u80b2\\uff1a \\u63d0\\u9ad8\\u5a74\\u513f\\u82b1\\u7ea2\\u53ca\\u513f\\u7ae5\\u57f9\\u80b2\\u6237\\u5934\\u586b\\u8865\\uff0c\\u63d0\\u4f9b\\u80b2\\u513f\\u8865\\u8d34\\u5e76\\u589e\\u52a0\\u966a\\u4ea7\\u5047\\u548c\\u80b2\\u5a74\\u5047\\n- \\u5e2e\\u52a9\\u4f4e\\u85aa\\u5bb6\\u5ead\\uff1a\\u901a\\u8fc7\\u793e\\u533a\\u8054\\u7cfb\\u7ad9\\uff08ComLink)\\uff0c\\u8fdb\\u4e00\\u6b65\\u878d\\u5408\\u653f\\u5e9c\\u4e3a\\u8f83\\u4f4e\\u6536\\u5165\\u5bb6\\u5ead\\u6240\\u63a8\\u51fa\\u7684\\u4e0d\\u540c\\u8ba1\\u5212\\u7684\\u76f8\\u540c\\u529f\\u80fd\\uff0c\\u586b\\u8865\\u5173\\u6000\\u57fa\\u91d1\\uff08ComCare Endowment Fund\\uff09\\u4e0e\\u6269\\u5927\\u5e7c\\u513f\\u57f9\\u80b2\\u8f85\\u52a9\\u8ba1\\u5212\\uff08KidSTART\\uff09\\n-\\u5e2e\\u52a9\\u5e74\\u957f\\u8005\\uff1a\\u4e3a\\u8001\\u4eba\\u62a4\\u7406\\u57fa\\u91d1\\uff08ElderCare Fund\\uff09\\u586b\\u88655\\u4ebf\\u5143\\uff0c\\u4fdd\\u5065\\u57fa\\u91d1\\uff08MediFund\\uff09\\u586b\\u886515\\u4ebf\\u5143\\n-\\u5e2e\\u52a9\\u5e73\\u53f0\\u5458\\u5de5\\uff1a \\u5f3a\\u5316\\u4f4e\\u85aa\\u5e73\\u53f0\\u4eba\\u5458\\u7684\\u9000\\u4f11\\u4fdd\\u969c\\uff0c\\u63a8\\u51fa\\u516c\\u79ef\\u91d1\\u8fc7\\u6e21\\u63f4\\u52a9\\u8ba1\\u5212\\uff0c\\u4ee5\\u51cf\\u8f7b\\u4ed6\\u4eec\\u65e5\\u540e\\u7f34\\u7eb3\\u516c\\u79ef\\u91d1\\u7684\\u8d1f\\u62c5\\n\\n\\u76f8\\u5173\\u62a5\\u9053\\uff1a\\n\\ud83d\\udc49\\ud83c\\udffb \\u4e00\\u6587\\u638c\\u63e12023\\u5e74\\u8d22\\u653f\\u9884\\u7b97\\u6848\\u8981\\u70b9\\nhttps://www.zaobao.com.sg/news/singapore/story20230214-1363163\\n\\n\\ud83d\\udc49\\ud83c\\udffb\\u3010\\u61d2\\u4eba\\u5305\\u3011\\u4f60\\u9700\\u8981\\u77e5\\u9053\\u7684\\u4e5d\\u9879\\u8d22\\u653f\\u9884\\u7b97\\u6848\\u5ba3\\u5e03\\nhttps://www.8world.com/singapore/budget2023-things-you-need-to-know-2054706\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def mistral_to_chat(entry):\n",
        "    entry = entry.strip()\n",
        "\n",
        "    # Check if entry starts with <s>[INST] and ends with </s>\n",
        "    if not entry.startswith(\"<s>[INST]\") or not entry.endswith(\"</s>\"):\n",
        "        print(\"Skipped (bad format):\", entry)\n",
        "        return None\n",
        "\n",
        "    messages = []\n",
        "    while True:\n",
        "        # Look for the next [INST] ... [/INST] ... </s> block\n",
        "        inst_start = entry.find(\"[INST]\")\n",
        "        inst_end = entry.find(\"[/INST]\")\n",
        "        s_end = entry.find(\"</s>\", inst_end)\n",
        "\n",
        "        if inst_start == -1 or inst_end == -1 or s_end == -1:\n",
        "            break\n",
        "\n",
        "        instruction = entry[inst_start + len(\"[INST]\"):inst_end].strip()\n",
        "        output = entry[inst_end + len(\"[/INST]\"):s_end].strip()\n",
        "\n",
        "        if instruction:\n",
        "            messages.append({\"role\": \"user\", \"content\": instruction})\n",
        "        if output:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": output})\n",
        "\n",
        "        # Move to the next segment\n",
        "        entry = entry[s_end + len(\"</s>\"):].strip()\n",
        "\n",
        "    if not messages:\n",
        "        return None\n",
        "\n",
        "    return {\"messages\": messages}\n",
        "\n",
        "\n",
        "def convert_list_to_jsonl(entries, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "        for entry in entries:\n",
        "            chat_format = mistral_to_chat(entry)\n",
        "            if chat_format:\n",
        "                json.dump(chat_format, outfile, ensure_ascii=False)\n",
        "                outfile.write(\"\\n\")\n",
        "train_prompts = list(df.prompt.values)\n",
        "\n",
        "convert_list_to_jsonl(train_prompts, \"train_data.jsonl\")\n"
      ],
      "metadata": {
        "id": "G4KZdSEfGK6N",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773891670,
          "user_tz": -480,
          "elapsed": 1221,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "G4KZdSEfGK6N",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "df.prompt.str.len().describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "RuZ97KwCg5WJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773894922,
          "user_tz": -480,
          "elapsed": 71,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6ebf3f10-8445-4ad5-a084-2666867b9914"
      },
      "id": "RuZ97KwCg5WJ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    11657.000000\n",
              "mean      7604.036802\n",
              "std       3066.212165\n",
              "min        518.000000\n",
              "25%       8081.000000\n",
              "50%       8515.000000\n",
              "75%       8787.000000\n",
              "max      19208.000000\n",
              "Name: prompt, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11657.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7604.036802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3066.212165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>518.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8081.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8515.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8787.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>19208.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning"
      ],
      "metadata": {
        "id": "WZSdZnrxEw3p"
      },
      "id": "WZSdZnrxEw3p"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/config.yml\n",
        "# File: /content/config.yml\n",
        "\n",
        "base_model: unsloth/Meta-Llama-3.1-8B-Instruct\n",
        "\n",
        "datasets:\n",
        "  - path: /content/train_data.jsonl\n",
        "    ds_type: json\n",
        "    type: chat_template\n",
        "    chat_template: tokenizer_default\n",
        "    field_messages: messages\n",
        "    message_property_mappings:\n",
        "      role: role\n",
        "      content: content\n",
        "    roles:\n",
        "      user: [\"user\"]\n",
        "      assistant: [\"assistant\"]\n",
        "    drop_system_message: true\n",
        "    roles_to_train: [\"assistant\"]\n",
        "    system_prompt: \"You are a helpful AI assistant for classifying stance.\"\n",
        "    data_files:\n",
        "      - /content/train_data.jsonl\n",
        "\n",
        "# test_datasets:\n",
        "#   - path: /content/val_data.jsonl\n",
        "#     ds_type: json\n",
        "#     type:\n",
        "#       type: chat_template\n",
        "#       chat_template: tokenizer_default\n",
        "#     data_files:\n",
        "#       - /content/val_data.jsonl\n",
        "#     split: train\n",
        "\n",
        "dataset_processes: 1\n",
        "\n",
        "# Output\n",
        "output_dir: /content/llama-output\n",
        "\n",
        "# LoRA config (if you still want to use LoRA)\n",
        "adapter: lora\n",
        "lora_r: 8\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.1\n",
        "lora_target_modules:\n",
        "  - q_proj\n",
        "  - k_proj\n",
        "  #- v_proj\n",
        "  #- o_proj\n",
        "  #- gate_proj\n",
        "  #- up_proj\n",
        "  #- down_proj\n",
        "lora_modules_to_save:\n",
        "  - embed_tokens\n",
        "  - lm_head\n",
        "\n",
        "# Format\n",
        "model_type: AutoModelForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "sequence_len: 8192\n",
        "pad_to_sequence_len: true\n",
        "load_in_8bit: true\n",
        "#load_in_4bit: true\n",
        "\n",
        "flash_attention: true\n",
        "sequence_parallel_degree: 2\n",
        "\n",
        "# Training\n",
        "num_epochs: 2\n",
        "micro_batch_size: 1\n",
        "gradient_accumulation_steps: 4\n",
        "\n",
        "# Optimization\n",
        "learning_rate: 2e-5\n",
        "lr_scheduler_type: cosine\n",
        "#weight_decay: 0.001\n",
        "\n",
        "#Validation\n",
        "# evaluation_strategy: steps\n",
        "# #early_stopping_patience: 3\n",
        "# do_causal_lm_eval: false\n",
        "# eval_causal_lm_metrics:\n",
        "#   - sacrebleu\n",
        "#   - ter\n",
        "#   - perplexity\n",
        "# eval_sample_packing: false\n",
        "# eval_max_new_tokens: 9\n",
        "# eval_batch_size: 1\n",
        "# eval_steps: 1000\n",
        "# logging_steps: 1000\n",
        "\n",
        "save_steps: 200\n",
        "\n",
        "# Precision\n",
        "bf16: true\n",
        "\n",
        "# Trainer\n",
        "trainer: AxolotlTrainer\n",
        "\n",
        "# DeepSpeed\n",
        "#deepspeed: /content/ds_config_zero3.json\n",
        "\n",
        "# Wandb\n",
        "wandb_mode: online\n",
        "wandb_project: reach-fine-tuning\n",
        "wandb_name: llama-v0\n",
        "wandb_run_id: llama-v0\n",
        "wandb_log_model: end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptuqu3Z4tdTH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773897292,
          "user_tz": -480,
          "elapsed": 79,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "bee53a83-6763-4e3c-e1f3-ff2216167bf4"
      },
      "id": "ptuqu3Z4tdTH",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/config.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ds_config_zero3.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"train_micro_batch_size_per_gpu\": 1,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 3,\n",
        "    \"offload_optimizer\": {\n",
        "      \"device\": \"cpu\"\n",
        "    },\n",
        "    \"offload_param\": {\n",
        "      \"device\": \"cpu\"\n",
        "    },\n",
        "    \"overlap_comm\": true,\n",
        "    \"contiguous_gradients\": true\n",
        "  },\n",
        "  \"bf16\": {\n",
        "    \"enabled\": true\n",
        "  },\n",
        "  \"steps_per_print\": 100,\n",
        "  \"wall_clock_breakdown\": false\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OqO_cSQ_82t",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773900597,
          "user_tz": -480,
          "elapsed": 62,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0487bc54-6127-4033-f717-0b67b05bce36"
      },
      "id": "6OqO_cSQ_82t",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ds_config_zero3.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a tensor and move it to GPU\n",
        "x = torch.randn(1, 1, device='cuda')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Ensure a GPU is installed and configured.\")\n",
        "\n",
        "# Check the available and total memory on the GPU\n",
        "allocated_memory = torch.cuda.memory_allocated()  # Memory currently in use\n",
        "reserved_memory = torch.cuda.memory_reserved()  # Memory reserved by the allocator\n",
        "free_memory = torch.cuda.memory_reserved() - torch.cuda.memory_allocated()  # Free memory\n",
        "\n",
        "print(f\"Allocated Memory: {allocated_memory / 1024 ** 2:.2f} MB\")\n",
        "print(f\"Reserved Memory: {reserved_memory / 1024 ** 2:.2f} MB\")\n",
        "print(f\"Free Memory: {free_memory / 1024 ** 2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qnuH39rY_zZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744771531097,
          "user_tz": -480,
          "elapsed": 2334,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3b16b7d0-e8ac-4bcd-f05a-bd73a22eadee"
      },
      "id": "8qnuH39rY_zZ",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available! Using GPU: NVIDIA A100-SXM4-40GB\n",
            "Allocated Memory: 0.00 MB\n",
            "Reserved Memory: 2.00 MB\n",
            "Free Memory: 2.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Now, import PyTorch\n",
        "import torch\n",
        "\n",
        "# You can now use PyTorch as usual\n",
        "print(torch.cuda.is_available())  # Check if CUDA is available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PS3xk-u6vBq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744771532765,
          "user_tz": -480,
          "elapsed": 60,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "73fe0e45-9017-4685-d2bd-6d2a1088915f"
      },
      "id": "9PS3xk-u6vBq",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "97edfae13e4e4ab6a59d93da1117a132",
            "4af4af1188b0485caf2429f0249915bf",
            "46ee28c3417c47f89eb0d81717721283",
            "5effacae387d4b0f8e287253abc4c268",
            "de234ac3773648228345b53d38f3a482",
            "04759e0465a74e6186d5479b5f8e0d92",
            "700d4e33d31642339289c0191c249f89",
            "90b347f2cec14298941e422da566c10d",
            "1db8a3ce335c487bb327d6e30446b458",
            "c18b18b38f20441798d4266a65c8ae31",
            "fea3973ab9594290a4a7591381c52d31",
            "c4687bc61fc74eaebe532899be0dbb21",
            "27e5951be00c4e6cbf19843a2b668129",
            "aca943421d5a478291243732f5bbf02d",
            "b3aec4709c964ee6b82b86b811560c31",
            "422284ad8bc04344965af0ed7cc0ac99",
            "85faeaa0175f4dea8dd0771e778bdfe9",
            "a50e3e1b560d443eafe254ddcae68ae4",
            "1d52165a12e4452bb370e156e4068561",
            "20e92f98648148bab111f934672d5083"
          ]
        },
        "id": "HBiY8TDlHmOf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773906477,
          "user_tz": -480,
          "elapsed": 235,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "51a0ad83-5e9b-4a27-b036-1cdd6e6b91da"
      },
      "id": "HBiY8TDlHmOf",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97edfae13e4e4ab6a59d93da1117a132"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "Qa1X_FXEneAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744773928813,
          "user_tz": -480,
          "elapsed": 6997,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "40f6f1d8-ca49-4b7a-cf6b-05f47c132389"
      },
      "id": "Qa1X_FXEneAl",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi nvlink --status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMALLhm6HZEq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744513637153,
          "user_tz": -480,
          "elapsed": 136,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "063c32d0-3851-4eb3-a152-4dabdf3aed6e"
      },
      "id": "EMALLhm6HZEq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-a82dd269-9d2e-6d13-818f-001427bc2793)\n",
            "\t Link 0: 25 GB/s\n",
            "\t Link 1: 25 GB/s\n",
            "\t Link 2: 25 GB/s\n",
            "\t Link 3: 25 GB/s\n",
            "\t Link 4: 25 GB/s\n",
            "\t Link 5: 25 GB/s\n",
            "\t Link 6: 25 GB/s\n",
            "\t Link 7: 25 GB/s\n",
            "\t Link 8: 25 GB/s\n",
            "\t Link 9: 25 GB/s\n",
            "\t Link 10: 25 GB/s\n",
            "\t Link 11: 25 GB/s\n",
            "GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-d14257b2-2da5-0825-6052-9757a3ba708b)\n",
            "\t Link 0: 25 GB/s\n",
            "\t Link 1: 25 GB/s\n",
            "\t Link 2: 25 GB/s\n",
            "\t Link 3: 25 GB/s\n",
            "\t Link 4: 25 GB/s\n",
            "\t Link 5: 25 GB/s\n",
            "\t Link 6: 25 GB/s\n",
            "\t Link 7: 25 GB/s\n",
            "\t Link 8: 25 GB/s\n",
            "\t Link 9: 25 GB/s\n",
            "\t Link 10: 25 GB/s\n",
            "\t Link 11: 25 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export NCCL_P2P_LEVEL=NVL"
      ],
      "metadata": {
        "id": "BzoRw4W4HfYv"
      },
      "id": "BzoRw4W4HfYv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/mistral-output*\n",
        "!rm -rf /content/wandb*\n",
        "!rm -rf /content/last_run_prepared*"
      ],
      "metadata": {
        "id": "3jBXfsASO1Tz"
      },
      "id": "3jBXfsASO1Tz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists('/content/train_data.jsonl'))  # Should return True\n",
        "print(os.path.exists('/content/val_data.jsonl'))    # Should return True\n",
        "print(os.path.exists('/content/ds_config_zero3.json'))\n",
        "print(os.path.exists('/content/config.yml'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_3Loz3MIMs6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744713916227,
          "user_tz": -480,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0ca521a9-bef0-4c0c-c9b3-19c1045895e8"
      },
      "id": "B_3Loz3MIMs6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train /content/config.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buX2T5j6uBOY",
        "outputId": "07ce3a8d-1fda-4d10-f803-090b4713656b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744774254676,
          "user_tz": -480,
          "elapsed": 321630,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "buX2T5j6uBOY",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:accelerate.commands.launch:The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `4`\n",
            "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
            "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-04-16 03:25:49.847729: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-16 03:25:49.847726: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-16 03:25:49.847729: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-16 03:25:49.847740: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-16 03:25:50.326776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-16 03:25:50.326785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-16 03:25:50.326785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-16 03:25:50.326793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-16 03:25:50.487673: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-16 03:25:50.487684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-16 03:25:50.487686: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-16 03:25:50.487696: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-16 03:25:50.536743: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-16 03:25:50.536750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-16 03:25:50.536753: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-16 03:25:50.536763: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-16 03:25:50.876279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-16 03:25:50.876279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-16 03:25:50.876283: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-16 03:25:50.876287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-16 03:25:55.359011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-04-16 03:25:55.359011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-04-16 03:25:55.359226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-04-16 03:25:55.359263: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2025-04-16 03:26:00,391] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-16 03:26:00,391] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-16 03:26:00,391] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-16 03:26:00,392] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-16 03:26:00,481] [INFO] [root.spawn:38] [PID:2528] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmppia3sw88/test.c -o /tmp/tmppia3sw88/test.o\n",
            "[2025-04-16 03:26:00,481] [INFO] [root.spawn:38] [PID:2530] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpbifybgra/test.c -o /tmp/tmpbifybgra/test.o\n",
            "[2025-04-16 03:26:00,481] [INFO] [root.spawn:38] [PID:2527] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpeacis77x/test.c -o /tmp/tmpeacis77x/test.o\n",
            "[2025-04-16 03:26:00,481] [INFO] [root.spawn:38] [PID:2529] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpn2ynyqf6/test.c -o /tmp/tmpn2ynyqf6/test.o\n",
            "[2025-04-16 03:26:00,499] [INFO] [root.spawn:38] [PID:2527] x86_64-linux-gnu-gcc /tmp/tmpeacis77x/test.o -laio -o /tmp/tmpeacis77x/a.out\n",
            "[2025-04-16 03:26:00,499] [INFO] [root.spawn:38] [PID:2528] x86_64-linux-gnu-gcc /tmp/tmppia3sw88/test.o -laio -o /tmp/tmppia3sw88/a.out\n",
            "[2025-04-16 03:26:00,499] [INFO] [root.spawn:38] [PID:2529] x86_64-linux-gnu-gcc /tmp/tmpn2ynyqf6/test.o -laio -o /tmp/tmpn2ynyqf6/a.out\n",
            "[2025-04-16 03:26:00,499] [INFO] [root.spawn:38] [PID:2530] x86_64-linux-gnu-gcc /tmp/tmpbifybgra/test.o -laio -o /tmp/tmpbifybgra/a.out\n",
            "[2025-04-16 03:26:01,113] [INFO] [root.spawn:38] [PID:2527] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp_g8q9rzl/test.c -o /tmp/tmp_g8q9rzl/test.o\n",
            "[2025-04-16 03:26:01,114] [INFO] [root.spawn:38] [PID:2528] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpqsao1wgg/test.c -o /tmp/tmpqsao1wgg/test.o\n",
            "[2025-04-16 03:26:01,115] [INFO] [root.spawn:38] [PID:2529] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpgoo2rucl/test.c -o /tmp/tmpgoo2rucl/test.o\n",
            "[2025-04-16 03:26:01,116] [INFO] [root.spawn:38] [PID:2530] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp6_bit_bk/test.c -o /tmp/tmp6_bit_bk/test.o\n",
            "[2025-04-16 03:26:01,131] [INFO] [root.spawn:38] [PID:2527] x86_64-linux-gnu-gcc /tmp/tmp_g8q9rzl/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp_g8q9rzl/a.out\n",
            "[2025-04-16 03:26:01,131] [INFO] [root.spawn:38] [PID:2528] x86_64-linux-gnu-gcc /tmp/tmpqsao1wgg/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpqsao1wgg/a.out\n",
            "[2025-04-16 03:26:01,132] [INFO] [root.spawn:38] [PID:2529] x86_64-linux-gnu-gcc /tmp/tmpgoo2rucl/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpgoo2rucl/a.out\n",
            "[2025-04-16 03:26:01,134] [INFO] [root.spawn:38] [PID:2530] x86_64-linux-gnu-gcc /tmp/tmp6_bit_bk/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp6_bit_bk/a.out\n",
            "[2025-04-16 03:26:01,181] [INFO] [root.spawn:38] [PID:2528] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpmobckbqu/test.c -o /tmp/tmpmobckbqu/test.o\n",
            "[2025-04-16 03:26:01,181] [INFO] [root.spawn:38] [PID:2527] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmph5o2zxgv/test.c -o /tmp/tmph5o2zxgv/test.o\n",
            "[2025-04-16 03:26:01,182] [INFO] [root.spawn:38] [PID:2529] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpxss8fvxx/test.c -o /tmp/tmpxss8fvxx/test.o\n",
            "[2025-04-16 03:26:01,184] [INFO] [root.spawn:38] [PID:2530] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmppm83exu8/test.c -o /tmp/tmppm83exu8/test.o\n",
            "[2025-04-16 03:26:01,199] [INFO] [root.spawn:38] [PID:2527] x86_64-linux-gnu-gcc /tmp/tmph5o2zxgv/test.o -laio -o /tmp/tmph5o2zxgv/a.out\n",
            "[2025-04-16 03:26:01,199] [INFO] [root.spawn:38] [PID:2528] x86_64-linux-gnu-gcc /tmp/tmpmobckbqu/test.o -laio -o /tmp/tmpmobckbqu/a.out\n",
            "[2025-04-16 03:26:01,199] [INFO] [root.spawn:38] [PID:2529] x86_64-linux-gnu-gcc /tmp/tmpxss8fvxx/test.o -laio -o /tmp/tmpxss8fvxx/a.out\n",
            "[2025-04-16 03:26:01,202] [INFO] [root.spawn:38] [PID:2530] x86_64-linux-gnu-gcc /tmp/tmppm83exu8/test.o -laio -o /tmp/tmppm83exu8/a.out\n",
            "[2025-04-16 03:26:02,869] [INFO] [datasets.<module>:54] [PID:2529] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-16 03:26:02,870] [INFO] [datasets.<module>:54] [PID:2530] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-16 03:26:02,871] [INFO] [datasets.<module>:66] [PID:2530] Polars version 1.9.0 available.\n",
            "[2025-04-16 03:26:02,871] [INFO] [datasets.<module>:66] [PID:2529] Polars version 1.9.0 available.\n",
            "[2025-04-16 03:26:02,871] [INFO] [datasets.<module>:54] [PID:2528] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-16 03:26:02,872] [INFO] [datasets.<module>:66] [PID:2528] Polars version 1.9.0 available.\n",
            "[2025-04-16 03:26:02,872] [INFO] [datasets.<module>:77] [PID:2530] Duckdb version 1.1.3 available.\n",
            "[2025-04-16 03:26:02,872] [INFO] [datasets.<module>:77] [PID:2529] Duckdb version 1.1.3 available.\n",
            "[2025-04-16 03:26:02,873] [INFO] [datasets.<module>:77] [PID:2528] Duckdb version 1.1.3 available.\n",
            "[2025-04-16 03:26:02,873] [INFO] [datasets.<module>:112] [PID:2530] TensorFlow version 2.17.1 available.\n",
            "[2025-04-16 03:26:02,873] [INFO] [datasets.<module>:112] [PID:2529] TensorFlow version 2.17.1 available.\n",
            "[2025-04-16 03:26:02,874] [INFO] [datasets.<module>:112] [PID:2528] TensorFlow version 2.17.1 available.\n",
            "[2025-04-16 03:26:02,874] [INFO] [datasets.<module>:125] [PID:2530] JAX version 0.4.33 available.\n",
            "[2025-04-16 03:26:02,874] [INFO] [datasets.<module>:125] [PID:2529] JAX version 0.4.33 available.\n",
            "[2025-04-16 03:26:02,874] [INFO] [datasets.<module>:125] [PID:2528] JAX version 0.4.33 available.\n",
            "[2025-04-16 03:26:02,884] [INFO] [datasets.<module>:54] [PID:2527] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-16 03:26:02,885] [INFO] [datasets.<module>:66] [PID:2527] Polars version 1.9.0 available.\n",
            "[2025-04-16 03:26:02,885] [INFO] [datasets.<module>:77] [PID:2527] Duckdb version 1.1.3 available.\n",
            "[2025-04-16 03:26:02,886] [INFO] [datasets.<module>:112] [PID:2527] TensorFlow version 2.17.1 available.\n",
            "[2025-04-16 03:26:02,887] [INFO] [datasets.<module>:125] [PID:2527] JAX version 0.4.33 available.\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "\u001b[33m[2025-04-16 03:26:07,109] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:2528] [RANK:1] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:07,109] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:2527] [RANK:0] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:07,109] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:2530] [RANK:3] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:07,109] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:2528] [RANK:1] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:07,109] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:2527] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:07,109] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:2530] [RANK:3] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:07,109] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:2529] [RANK:2] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:07,110] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:2529] [RANK:2] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "config.json: 100% 956/956 [00:00<00:00, 7.54MB/s]\n",
            "[2025-04-16 03:26:07,708] [INFO] [axolotl.normalize_config:237] [PID:2528] [RANK:1] cuda memory usage baseline: 0.000GB (+0.509GB misc)\u001b[39m\n",
            "[2025-04-16 03:26:07,721] [INFO] [axolotl.normalize_config:237] [PID:2530] [RANK:3] cuda memory usage baseline: 0.000GB (+0.509GB misc)\u001b[39m\n",
            "[2025-04-16 03:26:07,732] [INFO] [axolotl.normalize_config:237] [PID:2527] [RANK:0] cuda memory usage baseline: 0.000GB (+0.509GB misc)\u001b[39m\n",
            "[2025-04-16 03:26:07,735] [INFO] [axolotl.normalize_config:237] [PID:2529] [RANK:2] cuda memory usage baseline: 0.000GB (+0.509GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "tokenizer_config.json: 100% 55.5k/55.5k [00:00<00:00, 69.5MB/s]\n",
            "tokenizer.json: 100% 17.2M/17.2M [00:00<00:00, 190MB/s]\n",
            "special_tokens_map.json: 100% 454/454 [00:00<00:00, 4.58MB/s]\n",
            "[2025-04-16 03:26:11,905] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:2528] [RANK:1] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2025-04-16 03:26:11,906] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:2528] [RANK:1] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2025-04-16 03:26:11,906] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:2528] [RANK:1] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2025-04-16 03:26:11,906] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:2528] [RANK:1] UNK: None / None\u001b[39m\n",
            "[2025-04-16 03:26:11,906] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2528] [RANK:1] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[rank1]:[W416 03:26:11.037340456 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "[2025-04-16 03:26:11,909] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:2529] [RANK:2] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2025-04-16 03:26:11,909] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:2529] [RANK:2] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2025-04-16 03:26:11,909] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:2529] [RANK:2] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2025-04-16 03:26:11,909] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:2529] [RANK:2] UNK: None / None\u001b[39m\n",
            "[2025-04-16 03:26:11,909] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2529] [RANK:2] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[rank2]:[W416 03:26:11.040168072 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "[2025-04-16 03:26:11,938] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:2527] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2025-04-16 03:26:11,938] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:2527] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2025-04-16 03:26:11,938] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:2527] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2025-04-16 03:26:11,938] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:2527] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2025-04-16 03:26:11,938] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2527] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-16 03:26:11,938] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:2527] [RANK:0] Unable to find prepared dataset in last_run_prepared/adef9620f189ee0217bf93e46372d369\u001b[39m\n",
            "[2025-04-16 03:26:11,938] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:2527] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:26:11,938] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:2527] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2025-04-16 03:26:11,938] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:2527] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-04-16 03:26:12,297] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:2530] [RANK:3] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2025-04-16 03:26:12,297] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:2530] [RANK:3] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2025-04-16 03:26:12,297] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:2530] [RANK:3] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2025-04-16 03:26:12,297] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:2530] [RANK:3] UNK: None / None\u001b[39m\n",
            "[2025-04-16 03:26:12,297] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2530] [RANK:3] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[rank3]:[W416 03:26:12.428100982 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "Generating train split: 11657 examples [00:00, 22986.52 examples/s]\n",
            "[2025-04-16 03:26:13,263] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:2527] [RANK:0] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-16 03:26:13,289] [INFO] [axolotl.__call__:577] [PID:2527] [RANK:0] Using chat template:\n",
            "---\n",
            "{{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 Jul 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts: 100% 11657/11657 [03:34<00:00, 54.27 examples/s]\n",
            "[2025-04-16 03:29:48,339] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:2527] [RANK:0] min_input_len: 138\u001b[39m\n",
            "[2025-04-16 03:29:48,340] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:2527] [RANK:0] max_input_len: 4001\u001b[39m\n",
            "Dropping Long Sequences: 100% 11657/11657 [00:07<00:00, 1551.32 examples/s]\n",
            "[2025-04-16 03:29:56,643] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:333] [PID:2527] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/adef9620f189ee0217bf93e46372d369\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 11657/11657 [00:00<00:00, 31538.58 examples/s]\n",
            "[rank0]:[W416 03:29:57.292592875 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "[2025-04-16 03:29:58,100] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:2528] [RANK:1] Unable to find prepared dataset in last_run_prepared/adef9620f189ee0217bf93e46372d369\u001b[39m\n",
            "[2025-04-16 03:29:58,100] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:2530] [RANK:3] Unable to find prepared dataset in last_run_prepared/adef9620f189ee0217bf93e46372d369\u001b[39m\n",
            "[2025-04-16 03:29:58,100] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:2529] [RANK:2] Unable to find prepared dataset in last_run_prepared/adef9620f189ee0217bf93e46372d369\u001b[39m\n",
            "[2025-04-16 03:29:58,100] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:2528] [RANK:1] Loading raw datasets...\u001b[39m\n",
            "[2025-04-16 03:29:58,100] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:2530] [RANK:3] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:29:58,100] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:2528] [RANK:1] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2025-04-16 03:29:58,100] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:2529] [RANK:2] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:29:58,100] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:2530] [RANK:3] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2025-04-16 03:29:58,100] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:2528] [RANK:1] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-04-16 03:29:58,101] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:2530] [RANK:3] No seed provided, using default seed of 42\u001b[39m\n",
            "\u001b[33m[2025-04-16 03:29:58,101] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:2529] [RANK:2] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2025-04-16 03:29:58,101] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:2529] [RANK:2] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-04-16 03:29:58,796] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:2529] [RANK:2] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-16 03:29:58,803] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:2528] [RANK:1] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-16 03:29:58,819] [INFO] [axolotl.__call__:577] [PID:2529] [RANK:2] Using chat template:\n",
            "---\n",
            "{{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 Jul 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "---\u001b[39m\n",
            "[2025-04-16 03:29:58,828] [INFO] [axolotl.__call__:577] [PID:2528] [RANK:1] Using chat template:\n",
            "---\n",
            "{{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 Jul 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "---\u001b[39m\n",
            "[2025-04-16 03:29:58,838] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:2530] [RANK:3] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-16 03:29:58,862] [INFO] [axolotl.__call__:577] [PID:2530] [RANK:3] Using chat template:\n",
            "---\n",
            "{{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 Jul 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "---\u001b[39m\n",
            "[2025-04-16 03:29:59,103] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:2529] [RANK:2] min_input_len: 138\u001b[39m\n",
            "[2025-04-16 03:29:59,103] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:2529] [RANK:2] max_input_len: 4001\u001b[39m\n",
            "[2025-04-16 03:29:59,115] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:2528] [RANK:1] min_input_len: 138\u001b[39m\n",
            "[2025-04-16 03:29:59,115] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:2528] [RANK:1] max_input_len: 4001\u001b[39m\n",
            "[2025-04-16 03:29:59,197] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:2530] [RANK:3] min_input_len: 138\u001b[39m\n",
            "[2025-04-16 03:29:59,197] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:2530] [RANK:3] max_input_len: 4001\u001b[39m\n",
            "[2025-04-16 03:30:00,976] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2527] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-16 03:30:01,230] [INFO] [axolotl.monkeypatch.attention.ring_attn.register_ring_attn:56] [PID:2527] [RANK:0] Enabling ring attention sequence parallelism: each sequence will be processed across 2 GPUs\u001b[39m\n",
            "[2025-04-16 03:30:01,231] [INFO] [axolotl.monkeypatch.attention.ring_attn.register_ring_attn:93] [PID:2527] [RANK:0] Sequence parallel group assignments: {0: 0, 1: 0, 2: 1, 3: 1}\u001b[39m\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 65.7MB/s]\n",
            "[2025-04-16 03:30:02,342] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2529] [RANK:2] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-16 03:30:02,376] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2528] [RANK:1] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-16 03:30:02,468] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:2530] [RANK:3] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:04<00:00, 1.10GB/s]\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:05<00:00, 989MB/s] \n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:04<00:00, 1.09GB/s]\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:02<00:00, 480MB/s] \n",
            "Loading checkpoint shards: 100% 4/4 [00:18<00:00,  4.75s/it]\n",
            "generation_config.json: 100% 239/239 [00:00<00:00, 1.67MB/s]\n",
            "[2025-04-16 03:30:39,905] [INFO] [axolotl.utils.models.load_model:1292] [PID:2529] [RANK:2] cuda memory usage after model load: 5.640GB (+0.325GB cache, +2.124GB misc)\u001b[39m\n",
            "[2025-04-16 03:30:39,921] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:2529] [RANK:2] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-16 03:30:39,923] [INFO] [axolotl.utils.models.load_model:1328] [PID:2529] [RANK:2] Converting modules to torch.bfloat16\u001b[39m\n",
            "Loading checkpoint shards: 100% 4/4 [00:20<00:00,  5.01s/it]\n",
            "\n",
            "Loading checkpoint shards: 100% 4/4 [00:20<00:00,  5.02s/it]\n",
            "[2025-04-16 03:30:40,481] [INFO] [axolotl.utils.models.load_model:1387] [PID:2529] [RANK:2] cuda memory usage after adapters: 7.609GB (+2.281GB cache, +2.124GB misc)\u001b[39m\n",
            "[2025-04-16 03:30:40,757] [INFO] [axolotl.utils.models.load_model:1292] [PID:2530] [RANK:3] cuda memory usage after model load: 5.640GB (+0.325GB cache, +1.983GB misc)\u001b[39m\n",
            "[2025-04-16 03:30:40,761] [INFO] [axolotl.utils.models.load_model:1292] [PID:2528] [RANK:1] cuda memory usage after model load: 5.640GB (+0.325GB cache, +2.124GB misc)\u001b[39m\n",
            "[2025-04-16 03:30:40,766] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:2530] [RANK:3] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-16 03:30:40,768] [INFO] [axolotl.utils.models.load_model:1328] [PID:2530] [RANK:3] Converting modules to torch.bfloat16\u001b[39m\n",
            "[2025-04-16 03:30:40,770] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:2528] [RANK:1] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-16 03:30:40,773] [INFO] [axolotl.utils.models.load_model:1328] [PID:2528] [RANK:1] Converting modules to torch.bfloat16\u001b[39m\n",
            "[2025-04-16 03:30:40,902] [INFO] [axolotl.utils.models.load_model:1387] [PID:2530] [RANK:3] cuda memory usage after adapters: 7.609GB (+2.281GB cache, +1.983GB misc)\u001b[39m\n",
            "[2025-04-16 03:30:41,172] [INFO] [axolotl.utils.models.load_model:1292] [PID:2527] [RANK:0] cuda memory usage after model load: 5.640GB (+0.325GB cache, +1.983GB misc)\u001b[39m\n",
            "[2025-04-16 03:30:41,181] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:2527] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-16 03:30:41,184] [INFO] [axolotl.utils.models.load_model:1328] [PID:2527] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
            "trainable params: 1,054,081,024 || all params: 9,084,342,272 || trainable%: 11.6033\n",
            "[2025-04-16 03:30:41,310] [INFO] [axolotl.utils.models.load_model:1387] [PID:2528] [RANK:1] cuda memory usage after adapters: 7.609GB (+2.281GB cache, +2.124GB misc)\u001b[39m\n",
            "[2025-04-16 03:30:41,318] [INFO] [axolotl.utils.models.load_model:1387] [PID:2527] [RANK:0] cuda memory usage after adapters: 7.609GB (+2.281GB cache, +1.983GB misc)\u001b[39m\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "[2025-04-16 03:30:42,600] [INFO] [axolotl.train.save_initial_configs:339] [PID:2527] [RANK:0] Pre-saving adapter config to /content/llama-output...\u001b[39m\n",
            "[2025-04-16 03:30:42,600] [INFO] [axolotl.train.save_initial_configs:343] [PID:2527] [RANK:0] Pre-saving tokenizer to /content/llama-output...\u001b[39m\n",
            "[2025-04-16 03:30:42,857] [INFO] [axolotl.train.save_initial_configs:346] [PID:2527] [RANK:0] Pre-saving model config to /content/llama-output...\u001b[39m\n",
            "[2025-04-16 03:30:42,867] [INFO] [axolotl.train.execute_training:183] [PID:2527] [RANK:0] Starting trainer...\u001b[39m\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilson_ng\u001b[0m (\u001b[33mwilson_ng-govtech\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250416_033045-llama-v0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mllama-v0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/wilson_ng-govtech/reach-fine-tuning\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/wilson_ng-govtech/reach-fine-tuning/runs/llama-v0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "[2025-04-16 03:30:47,257] [INFO] [axolotl.callbacks.on_train_begin:811] [PID:2527] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
            "  0% 0/2914 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "[rank1]: Traceback (most recent call last):\n",
            "[rank1]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "[rank1]:     return _run_code(code, main_globals, None,\n",
            "[rank1]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "[rank1]:     exec(code, run_globals)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 117, in <module>\n",
            "[rank1]:     fire.Fire(do_cli)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "[rank1]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "[rank1]:     component, remaining_args = _CallAndUpdateTrace(\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "[rank1]:     component = fn(*varargs, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 91, in do_cli\n",
            "[rank1]:     return do_train(parsed_cfg, parsed_cli_args)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 50, in do_train\n",
            "[rank1]:     model, tokenizer, trainer = train(cfg=cfg, dataset_meta=dataset_meta)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 507, in train\n",
            "[rank1]:     execute_training(cfg, trainer, resume_from_checkpoint)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 193, in execute_training\n",
            "[rank1]:     trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2245, in train\n",
            "[rank1]:     return inner_training_loop(\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2560, in _inner_training_loop\n",
            "[rank1]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3736, in training_step\n",
            "[rank1]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py\", line 374, in compute_loss\n",
            "[rank1]:     return super().compute_loss(\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3801, in compute_loss\n",
            "[rank1]:     outputs = model(**inputs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank1]:     return self._call_impl(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank1]:     return forward_call(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
            "[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
            "[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank1]:     return self._call_impl(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank1]:     return forward_call(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 814, in forward\n",
            "[rank1]:     return model_forward(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 802, in __call__\n",
            "[rank1]:     return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
            "[rank1]:     return func(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1756, in forward\n",
            "[rank1]:     return self.base_model(\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank1]:     return self._call_impl(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank1]:     return forward_call(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\", line 193, in forward\n",
            "[rank1]:     return self.model.forward(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\", line 965, in wrapper\n",
            "[rank1]:     output = func(self, *args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "[rank1]:     return func(*args, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 841, in forward\n",
            "[rank1]:     loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/loss/loss_utils.py\", line 63, in ForCausalLMLoss\n",
            "[rank1]:     loss = fixed_cross_entropy(logits, shift_labels, num_items_in_batch, ignore_index, **kwargs)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/loss/loss_utils.py\", line 35, in fixed_cross_entropy\n",
            "[rank1]:     loss = nn.functional.cross_entropy(source, target, ignore_index=ignore_index, reduction=reduction)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 3479, in cross_entropy\n",
            "[rank1]:     return torch._C._nn.cross_entropy_loss(\n",
            "[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 1 has a total capacity of 39.49 GiB of which 1.25 GiB is free. Process 6899 has 38.24 GiB memory in use. Of the allocated memory 34.62 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "[rank2]: Traceback (most recent call last):\n",
            "[rank2]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "[rank2]:     return _run_code(code, main_globals, None,\n",
            "[rank2]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "[rank2]:     exec(code, run_globals)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 117, in <module>\n",
            "[rank2]:     fire.Fire(do_cli)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "[rank2]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "[rank2]:     component, remaining_args = _CallAndUpdateTrace(\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "[rank2]:     component = fn(*varargs, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 91, in do_cli\n",
            "[rank2]:     return do_train(parsed_cfg, parsed_cli_args)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 50, in do_train\n",
            "[rank2]:     model, tokenizer, trainer = train(cfg=cfg, dataset_meta=dataset_meta)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 507, in train\n",
            "[rank2]:     execute_training(cfg, trainer, resume_from_checkpoint)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 193, in execute_training\n",
            "[rank2]:     trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2245, in train\n",
            "[rank2]:     return inner_training_loop(\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2560, in _inner_training_loop\n",
            "[rank2]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3736, in training_step\n",
            "[rank2]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py\", line 374, in compute_loss\n",
            "[rank2]:     return super().compute_loss(\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3801, in compute_loss\n",
            "[rank2]:     outputs = model(**inputs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank2]:     return self._call_impl(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank2]:     return forward_call(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
            "[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
            "[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank2]:     return self._call_impl(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank2]:     return forward_call(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 814, in forward\n",
            "[rank2]:     return model_forward(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 802, in __call__\n",
            "[rank2]:     return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
            "[rank2]:     return func(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1756, in forward\n",
            "[rank2]:     return self.base_model(\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank2]:     return self._call_impl(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank2]:     return forward_call(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\", line 193, in forward\n",
            "[rank2]:     return self.model.forward(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\", line 965, in wrapper\n",
            "[rank2]:     output = func(self, *args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "[rank2]:     return func(*args, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 841, in forward\n",
            "[rank2]:     loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/loss/loss_utils.py\", line 63, in ForCausalLMLoss\n",
            "[rank2]:     loss = fixed_cross_entropy(logits, shift_labels, num_items_in_batch, ignore_index, **kwargs)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/loss/loss_utils.py\", line 35, in fixed_cross_entropy\n",
            "[rank2]:     loss = nn.functional.cross_entropy(source, target, ignore_index=ignore_index, reduction=reduction)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 3479, in cross_entropy\n",
            "[rank2]:     return torch._C._nn.cross_entropy_loss(\n",
            "[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 2 has a total capacity of 39.49 GiB of which 1.31 GiB is free. Process 6900 has 38.17 GiB memory in use. Of the allocated memory 34.62 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "[rank3]: Traceback (most recent call last):\n",
            "[rank3]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "[rank3]:     return _run_code(code, main_globals, None,\n",
            "[rank3]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "[rank3]:     exec(code, run_globals)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 117, in <module>\n",
            "[rank3]:     fire.Fire(do_cli)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "[rank3]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "[rank3]:     component, remaining_args = _CallAndUpdateTrace(\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "[rank3]:     component = fn(*varargs, **kwargs)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 91, in do_cli\n",
            "[rank3]:     return do_train(parsed_cfg, parsed_cli_args)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 50, in do_train\n",
            "[rank3]:     model, tokenizer, trainer = train(cfg=cfg, dataset_meta=dataset_meta)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 507, in train\n",
            "[rank3]:     execute_training(cfg, trainer, resume_from_checkpoint)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 193, in execute_training\n",
            "[rank3]:     trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2245, in train\n",
            "[rank3]:     return inner_training_loop(\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2560, in _inner_training_loop\n",
            "[rank3]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3782, in training_step\n",
            "[rank3]:     self.accelerator.backward(loss, **kwargs)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\", line 2454, in backward\n",
            "[rank3]:     loss.backward(**kwargs)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "[rank3]:     torch.autograd.backward(\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "[rank3]:     _engine_run_backward(\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "[rank3]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "[rank3]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 3 has a total capacity of 39.49 GiB of which 1.14 GiB is free. Process 6901 has 38.34 GiB memory in use. Of the allocated memory 35.60 GiB is allocated by PyTorch, and 540.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 117, in <module>\n",
            "    fire.Fire(do_cli)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 91, in do_cli\n",
            "    return do_train(parsed_cfg, parsed_cli_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 50, in do_train\n",
            "    model, tokenizer, trainer = train(cfg=cfg, dataset_meta=dataset_meta)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 507, in train\n",
            "    execute_training(cfg, trainer, resume_from_checkpoint)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 193, in execute_training\n",
            "    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2245, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2560, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3782, in training_step\n",
            "    self.accelerator.backward(loss, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\", line 2454, in backward\n",
            "    loss.backward(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 39.49 GiB of which 1.14 GiB is free. Process 6898 has 38.35 GiB memory in use. Of the allocated memory 35.60 GiB is allocated by PyTorch, and 542.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "[rank0]:     return _run_code(code, main_globals, None,\n",
            "[rank0]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "[rank0]:     exec(code, run_globals)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 117, in <module>\n",
            "[rank0]:     fire.Fire(do_cli)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "[rank0]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "[rank0]:     component, remaining_args = _CallAndUpdateTrace(\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "[rank0]:     component = fn(*varargs, **kwargs)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 91, in do_cli\n",
            "[rank0]:     return do_train(parsed_cfg, parsed_cli_args)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/cli/train.py\", line 50, in do_train\n",
            "[rank0]:     model, tokenizer, trainer = train(cfg=cfg, dataset_meta=dataset_meta)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 507, in train\n",
            "[rank0]:     execute_training(cfg, trainer, resume_from_checkpoint)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/axolotl/train.py\", line 193, in execute_training\n",
            "[rank0]:     trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2245, in train\n",
            "[rank0]:     return inner_training_loop(\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2560, in _inner_training_loop\n",
            "[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3782, in training_step\n",
            "[rank0]:     self.accelerator.backward(loss, **kwargs)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\", line 2454, in backward\n",
            "[rank0]:     loss.backward(**kwargs)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "[rank0]:     torch.autograd.backward(\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "[rank0]:     _engine_run_backward(\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 39.49 GiB of which 1.14 GiB is free. Process 6898 has 38.35 GiB memory in use. Of the allocated memory 35.60 GiB is allocated by PyTorch, and 542.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\u001b[0m\u001b[0m\u001b[0m\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mllama-v0\u001b[0m at: \u001b[34mhttps://wandb.ai/wilson_ng-govtech/reach-fine-tuning/runs/llama-v0\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250416_033045-llama-v0/logs\u001b[0m\n",
            "\u001b[0mW0416 03:30:53.204000 2386 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2527 closing signal SIGTERM\n",
            "W0416 03:30:53.205000 2386 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2529 closing signal SIGTERM\n",
            "W0416 03:30:53.205000 2386 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2530 closing signal SIGTERM\n",
            "E0416 03:30:53.570000 2386 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 2528) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1204, in launch_command\n",
            "    multi_gpu_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 825, in multi_gpu_launcher\n",
            "    distrib_run.run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 910, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "axolotl.cli.train FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2025-04-16_03:30:53\n",
            "  host      : 1a8a671b65c1\n",
            "  rank      : 1 (local_rank: 1)\n",
            "  exitcode  : 1 (pid: 2528)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/outputs/mistral-qlora\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"steps\",  # eval every few steps\n",
        "    eval_steps=20,                # eval every 20 steps\n",
        "    logging_steps=5,              # log training loss every 5 steps\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,                # save model every 50 steps\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"cosine\",   # Cosine decay for LR\n",
        "    warmup_ratio=0.1,             # 10% warm-up\n",
        "    bf16=True,\n",
        "    report_to=\"wandb\",            # Track with WandB\n",
        "    run_name=\"mistral-finetune\",\n",
        "    logging_dir=\"./logs\",         # For tracking logs\n",
        ")\n",
        "\n",
        "# Step 5: Data Collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Step 6: Early Stopping Callback\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=2  # stop if eval loss doesn't improve for 2 evals\n",
        ")\n",
        "\n",
        "# Step 7: Compute Perplexity\n",
        "def compute_metrics(eval_preds):\n",
        "    loss = eval_preds[\"loss\"] if isinstance(eval_preds, dict) else eval_preds.loss\n",
        "    perplexity = math.exp(loss)\n",
        "    return {\"eval_loss\": loss, \"perplexity\": perplexity}\n",
        "\n",
        "# Step 8: Initialize the Trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping],  # Add early stopping\n",
        ")\n",
        "\n",
        "# Step 9: Train the Model\n",
        "trainer.train()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZtuI-15T45Gz"
      },
      "id": "ZtuI-15T45Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YvlQ8Gd8yG6t"
      },
      "id": "YvlQ8Gd8yG6t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model artifact to gcs\n",
        "!gsutil -m rm -r gs://mddi-reach-conversation/llama-output/**\n",
        "!gsutil -m cp -r /content/llama-output/ gs://mddi-reach-conversation/"
      ],
      "metadata": {
        "id": "FGpH6qYiMSWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744730987984,
          "user_tz": -480,
          "elapsed": 53440,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f717775e-ab9c-47cf-ecc0-5c8f33ab7d96"
      },
      "id": "FGpH6qYiMSWH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing gs://mddi-reach-conversation/mistral-output/README.md#1744695848343972...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/adapter_config.json#1744695848322978...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/adapter_model.safetensors#1744695871889325...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/README.md#1744695848539387...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/adapter_config.json#1744695849306100...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/adapter_model.safetensors#1744695872109259...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/optimizer.pt#1744695893551287...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/rng_state_0.pth#1744695848674136...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/rng_state_1.pth#1744695848422612...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/scheduler.pt#1744695848687468...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/special_tokens_map.json#1744695849548288...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/tokenizer.json#1744695849996496...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/tokenizer.model#1744695849603206...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/tokenizer_config.json#1744695848695636...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/trainer_state.json#1744695848690849...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2600/training_args.bin#1744695848523000...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/README.md#1744695848725267...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/adapter_config.json#1744695849486588...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/adapter_model.safetensors#1744695873170371...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/rng_state_0.pth#1744695848858408...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/optimizer.pt#1744695894628094...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/rng_state_1.pth#1744695848684532...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/scheduler.pt#1744695848894562...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/special_tokens_map.json#1744695848784156...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/tokenizer.json#1744695850334577...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/tokenizer.model#1744695850306811...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/tokenizer_config.json#1744695848862717...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/trainer_state.json#1744695849623095...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2800/training_args.bin#1744695848771546...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/README.md#1744695848820587...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/adapter_config.json#1744695848846416...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/optimizer.pt#1744695895020626...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/rng_state_0.pth#1744695849775333...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/adapter_model.safetensors#1744695872409570...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/special_tokens_map.json#1744695848823146...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/rng_state_1.pth#1744695848998330...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/tokenizer.json#1744695850434996...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/trainer_state.json#1744695848991817...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/tokenizer.model#1744695849779784...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/scheduler.pt#1744695848824703...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/training_args.bin#1744695848843462...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/README.md#1744695848586120...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/adapter_config.json#1744695848574259...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2881/tokenizer_config.json#1744695848696940...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/adapter_model.safetensors#1744695872838443...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/optimizer.pt#1744695894567420...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/rng_state_0.pth#1744695849002141...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/scheduler.pt#1744695848981356...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/special_tokens_map.json#1744695848599494...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/rng_state_1.pth#1744695848525272...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/tokenizer.json#1744695850126956...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/tokenizer.model#1744695849560650...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/tokenizer_config.json#1744695849000925...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/trainer_state.json#1744695848723232...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-2948/training_args.bin#1744695848530577...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/special_tokens_map.json#1744695848366440...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/config.json#1744695848351507...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/tokenizer.json#1744695849904782...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/tokenizer.model#1744695849336717...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/tokenizer_config.json#1744695848402552...\n",
            "/ [60/60 objects] 100% Done                                                     \n",
            "Operation completed over 60 objects.                                             \n",
            "Copying file:///content/mistral-output/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/tokenizer.json [Content-Type=application/json]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file:///content/mistral-output/checkpoint-2948/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2948/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2881/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2800/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-2880/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "- [60/60 files][  6.5 GiB/  6.5 GiB] 100% Done  78.5 MiB/s ETA 00:00:00         \n",
            "Operation completed over 60 objects/6.5 GiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "57Vqu5KwLqDb"
      },
      "id": "57Vqu5KwLqDb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "# Load base Mistral model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "n45Uv1cALvPA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "dd6c0823892941369d83567866478fea",
            "f2d6a71c3617413f92afa753542247d8",
            "cdecdec8a1df481e92e738ba4fbd02ee",
            "a8e1cb161ba94b458a3876f84d1a6e70",
            "b0132493ca1446769473d8c303a11db6",
            "032496a0293c4d5f83af68b672d81897",
            "ced779fba09d4eeb8092bf6cae49b99d",
            "0a31c529dff346409a96b5d37aefcf58",
            "d6d23df5d711405b859c8edfaf88255a",
            "d569b0aae9a04a71b59979ffb24f28ca",
            "a845d5d413eb40dfa1db1a97e8c96f62"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744730997885,
          "user_tz": -480,
          "elapsed": 9903,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b38b64bd-3689-4e4f-9d58-76a228f53d58"
      },
      "id": "n45Uv1cALvPA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-04-15 15:29:50,833] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd6c0823892941369d83567866478fea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load fine-tuned PEFT adapter\n",
        "model = PeftModel.from_pretrained(base_model, \"/content/mistral-output\")\n",
        "\n",
        "# Merge LoRA weights into base model\n",
        "merged_model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "cJlIZXIQX_WP"
      },
      "id": "cJlIZXIQX_WP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: mean={param.data.mean().item():.4f}, std={param.data.std().item():.4f}\")"
      ],
      "metadata": {
        "id": "ZNdszShVxGU9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744730998678,
          "user_tz": -480,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f8078b-1119-4e10-dc32-cb89f80b4ee6"
      },
      "id": "ZNdszShVxGU9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.model.embed_tokens.weight: mean=-0.0000, std=0.0027\n",
            "base_model.model.model.layers.0.self_attn.q_proj.weight: mean=0.0000, std=0.0042\n",
            "base_model.model.model.layers.0.self_attn.k_proj.weight: mean=-0.0000, std=0.0044\n",
            "base_model.model.model.layers.0.self_attn.v_proj.weight: mean=-0.0000, std=0.0020\n",
            "base_model.model.model.layers.0.self_attn.o_proj.weight: mean=0.0000, std=0.0020\n",
            "base_model.model.model.layers.0.mlp.gate_proj.weight: mean=0.0000, std=0.0032\n",
            "base_model.model.model.layers.0.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.0.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.0.input_layernorm.weight: mean=0.0845, std=0.2461\n",
            "base_model.model.model.layers.0.post_attention_layernorm.weight: mean=0.4258, std=0.0640\n",
            "base_model.model.model.layers.1.self_attn.q_proj.weight: mean=-0.0000, std=0.0040\n",
            "base_model.model.model.layers.1.self_attn.k_proj.weight: mean=-0.0000, std=0.0049\n",
            "base_model.model.model.layers.1.self_attn.v_proj.weight: mean=0.0000, std=0.0024\n",
            "base_model.model.model.layers.1.self_attn.o_proj.weight: mean=-0.0000, std=0.0024\n",
            "base_model.model.model.layers.1.mlp.gate_proj.weight: mean=0.0000, std=0.0032\n",
            "base_model.model.model.layers.1.mlp.up_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.1.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.1.input_layernorm.weight: mean=0.2354, std=0.3164\n",
            "base_model.model.model.layers.1.post_attention_layernorm.weight: mean=0.6133, std=0.0972\n",
            "base_model.model.model.layers.2.self_attn.q_proj.weight: mean=0.0000, std=0.0043\n",
            "base_model.model.model.layers.2.self_attn.k_proj.weight: mean=-0.0000, std=0.0056\n",
            "base_model.model.model.layers.2.self_attn.v_proj.weight: mean=0.0000, std=0.0022\n",
            "base_model.model.model.layers.2.self_attn.o_proj.weight: mean=0.0000, std=0.0023\n",
            "base_model.model.model.layers.2.mlp.gate_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.2.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.2.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.2.input_layernorm.weight: mean=1.1328, std=0.6797\n",
            "base_model.model.model.layers.2.post_attention_layernorm.weight: mean=0.7773, std=0.1260\n",
            "base_model.model.model.layers.3.self_attn.q_proj.weight: mean=0.0000, std=0.0043\n",
            "base_model.model.model.layers.3.self_attn.k_proj.weight: mean=-0.0000, std=0.0057\n",
            "base_model.model.model.layers.3.self_attn.v_proj.weight: mean=0.0000, std=0.0025\n",
            "base_model.model.model.layers.3.self_attn.o_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.3.mlp.gate_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.3.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.3.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.3.input_layernorm.weight: mean=0.9023, std=0.3418\n",
            "base_model.model.model.layers.3.post_attention_layernorm.weight: mean=0.9414, std=0.1328\n",
            "base_model.model.model.layers.4.self_attn.q_proj.weight: mean=-0.0000, std=0.0040\n",
            "base_model.model.model.layers.4.self_attn.k_proj.weight: mean=0.0000, std=0.0052\n",
            "base_model.model.model.layers.4.self_attn.v_proj.weight: mean=0.0000, std=0.0025\n",
            "base_model.model.model.layers.4.self_attn.o_proj.weight: mean=0.0000, std=0.0025\n",
            "base_model.model.model.layers.4.mlp.gate_proj.weight: mean=-0.0000, std=0.0032\n",
            "base_model.model.model.layers.4.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.4.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.4.input_layernorm.weight: mean=1.1641, std=0.3984\n",
            "base_model.model.model.layers.4.post_attention_layernorm.weight: mean=1.0234, std=0.1260\n",
            "base_model.model.model.layers.5.self_attn.q_proj.weight: mean=0.0000, std=0.0041\n",
            "base_model.model.model.layers.5.self_attn.k_proj.weight: mean=-0.0000, std=0.0054\n",
            "base_model.model.model.layers.5.self_attn.v_proj.weight: mean=0.0000, std=0.0023\n",
            "base_model.model.model.layers.5.self_attn.o_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.5.mlp.gate_proj.weight: mean=-0.0000, std=0.0032\n",
            "base_model.model.model.layers.5.mlp.up_proj.weight: mean=0.0000, std=0.0028\n",
            "base_model.model.model.layers.5.mlp.down_proj.weight: mean=0.0000, std=0.0028\n",
            "base_model.model.model.layers.5.input_layernorm.weight: mean=1.3984, std=0.3262\n",
            "base_model.model.model.layers.5.post_attention_layernorm.weight: mean=1.1484, std=0.1465\n",
            "base_model.model.model.layers.6.self_attn.q_proj.weight: mean=0.0000, std=0.0041\n",
            "base_model.model.model.layers.6.self_attn.k_proj.weight: mean=0.0000, std=0.0054\n",
            "base_model.model.model.layers.6.self_attn.v_proj.weight: mean=-0.0000, std=0.0024\n",
            "base_model.model.model.layers.6.self_attn.o_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.6.mlp.gate_proj.weight: mean=0.0000, std=0.0032\n",
            "base_model.model.model.layers.6.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.6.mlp.down_proj.weight: mean=0.0000, std=0.0028\n",
            "base_model.model.model.layers.6.input_layernorm.weight: mean=1.2969, std=0.3555\n",
            "base_model.model.model.layers.6.post_attention_layernorm.weight: mean=1.2344, std=0.1514\n",
            "base_model.model.model.layers.7.self_attn.q_proj.weight: mean=-0.0000, std=0.0040\n",
            "base_model.model.model.layers.7.self_attn.k_proj.weight: mean=-0.0000, std=0.0053\n",
            "base_model.model.model.layers.7.self_attn.v_proj.weight: mean=0.0000, std=0.0025\n",
            "base_model.model.model.layers.7.self_attn.o_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.7.mlp.gate_proj.weight: mean=-0.0000, std=0.0033\n",
            "base_model.model.model.layers.7.mlp.up_proj.weight: mean=0.0000, std=0.0028\n",
            "base_model.model.model.layers.7.mlp.down_proj.weight: mean=-0.0000, std=0.0028\n",
            "base_model.model.model.layers.7.input_layernorm.weight: mean=1.4375, std=0.3906\n",
            "base_model.model.model.layers.7.post_attention_layernorm.weight: mean=1.3438, std=0.1973\n",
            "base_model.model.model.layers.8.self_attn.q_proj.weight: mean=0.0000, std=0.0039\n",
            "base_model.model.model.layers.8.self_attn.k_proj.weight: mean=-0.0000, std=0.0052\n",
            "base_model.model.model.layers.8.self_attn.v_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.8.self_attn.o_proj.weight: mean=-0.0000, std=0.0026\n",
            "base_model.model.model.layers.8.mlp.gate_proj.weight: mean=0.0000, std=0.0033\n",
            "base_model.model.model.layers.8.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.8.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.8.input_layernorm.weight: mean=1.4922, std=0.3652\n",
            "base_model.model.model.layers.8.post_attention_layernorm.weight: mean=1.4062, std=0.2285\n",
            "base_model.model.model.layers.9.self_attn.q_proj.weight: mean=0.0000, std=0.0038\n",
            "base_model.model.model.layers.9.self_attn.k_proj.weight: mean=0.0000, std=0.0052\n",
            "base_model.model.model.layers.9.self_attn.v_proj.weight: mean=-0.0000, std=0.0023\n",
            "base_model.model.model.layers.9.self_attn.o_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.9.mlp.gate_proj.weight: mean=-0.0000, std=0.0032\n",
            "base_model.model.model.layers.9.mlp.up_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.9.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.9.input_layernorm.weight: mean=1.8125, std=0.4199\n",
            "base_model.model.model.layers.9.post_attention_layernorm.weight: mean=1.4453, std=0.2471\n",
            "base_model.model.model.layers.10.self_attn.q_proj.weight: mean=0.0000, std=0.0039\n",
            "base_model.model.model.layers.10.self_attn.k_proj.weight: mean=-0.0000, std=0.0054\n",
            "base_model.model.model.layers.10.self_attn.v_proj.weight: mean=0.0000, std=0.0023\n",
            "base_model.model.model.layers.10.self_attn.o_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.10.mlp.gate_proj.weight: mean=-0.0000, std=0.0032\n",
            "base_model.model.model.layers.10.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.10.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.10.input_layernorm.weight: mean=1.6719, std=0.4648\n",
            "base_model.model.model.layers.10.post_attention_layernorm.weight: mean=1.4688, std=0.2520\n",
            "base_model.model.model.layers.11.self_attn.q_proj.weight: mean=-0.0000, std=0.0039\n",
            "base_model.model.model.layers.11.self_attn.k_proj.weight: mean=-0.0000, std=0.0052\n",
            "base_model.model.model.layers.11.self_attn.v_proj.weight: mean=0.0000, std=0.0025\n",
            "base_model.model.model.layers.11.self_attn.o_proj.weight: mean=-0.0000, std=0.0026\n",
            "base_model.model.model.layers.11.mlp.gate_proj.weight: mean=-0.0000, std=0.0032\n",
            "base_model.model.model.layers.11.mlp.up_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.11.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.11.input_layernorm.weight: mean=1.8750, std=0.5430\n",
            "base_model.model.model.layers.11.post_attention_layernorm.weight: mean=1.5156, std=0.2598\n",
            "base_model.model.model.layers.12.self_attn.q_proj.weight: mean=-0.0000, std=0.0038\n",
            "base_model.model.model.layers.12.self_attn.k_proj.weight: mean=0.0000, std=0.0051\n",
            "base_model.model.model.layers.12.self_attn.v_proj.weight: mean=-0.0000, std=0.0023\n",
            "base_model.model.model.layers.12.self_attn.o_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.12.mlp.gate_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.12.mlp.up_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.12.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.12.input_layernorm.weight: mean=2.0625, std=0.5859\n",
            "base_model.model.model.layers.12.post_attention_layernorm.weight: mean=1.6250, std=0.3164\n",
            "base_model.model.model.layers.13.self_attn.q_proj.weight: mean=-0.0000, std=0.0039\n",
            "base_model.model.model.layers.13.self_attn.k_proj.weight: mean=0.0000, std=0.0052\n",
            "base_model.model.model.layers.13.self_attn.v_proj.weight: mean=-0.0000, std=0.0025\n",
            "base_model.model.model.layers.13.self_attn.o_proj.weight: mean=0.0000, std=0.0027\n",
            "base_model.model.model.layers.13.mlp.gate_proj.weight: mean=0.0000, std=0.0031\n",
            "base_model.model.model.layers.13.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.13.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.13.input_layernorm.weight: mean=2.0156, std=0.5703\n",
            "base_model.model.model.layers.13.post_attention_layernorm.weight: mean=1.7188, std=0.3086\n",
            "base_model.model.model.layers.14.self_attn.q_proj.weight: mean=-0.0000, std=0.0037\n",
            "base_model.model.model.layers.14.self_attn.k_proj.weight: mean=-0.0000, std=0.0046\n",
            "base_model.model.model.layers.14.self_attn.v_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.14.self_attn.o_proj.weight: mean=-0.0000, std=0.0028\n",
            "base_model.model.model.layers.14.mlp.gate_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.14.mlp.up_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.14.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.14.input_layernorm.weight: mean=2.1562, std=0.5352\n",
            "base_model.model.model.layers.14.post_attention_layernorm.weight: mean=1.7891, std=0.2852\n",
            "base_model.model.model.layers.15.self_attn.q_proj.weight: mean=-0.0000, std=0.0037\n",
            "base_model.model.model.layers.15.self_attn.k_proj.weight: mean=-0.0000, std=0.0046\n",
            "base_model.model.model.layers.15.self_attn.v_proj.weight: mean=-0.0000, std=0.0028\n",
            "base_model.model.model.layers.15.self_attn.o_proj.weight: mean=-0.0000, std=0.0028\n",
            "base_model.model.model.layers.15.mlp.gate_proj.weight: mean=0.0000, std=0.0032\n",
            "base_model.model.model.layers.15.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.15.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.15.input_layernorm.weight: mean=2.4375, std=0.4746\n",
            "base_model.model.model.layers.15.post_attention_layernorm.weight: mean=1.9297, std=0.2871\n",
            "base_model.model.model.layers.16.self_attn.q_proj.weight: mean=-0.0000, std=0.0037\n",
            "base_model.model.model.layers.16.self_attn.k_proj.weight: mean=-0.0000, std=0.0047\n",
            "base_model.model.model.layers.16.self_attn.v_proj.weight: mean=0.0000, std=0.0028\n",
            "base_model.model.model.layers.16.self_attn.o_proj.weight: mean=0.0000, std=0.0028\n",
            "base_model.model.model.layers.16.mlp.gate_proj.weight: mean=-0.0000, std=0.0032\n",
            "base_model.model.model.layers.16.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.16.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.16.input_layernorm.weight: mean=2.4219, std=0.4551\n",
            "base_model.model.model.layers.16.post_attention_layernorm.weight: mean=2.0938, std=0.2852\n",
            "base_model.model.model.layers.17.self_attn.q_proj.weight: mean=-0.0000, std=0.0037\n",
            "base_model.model.model.layers.17.self_attn.k_proj.weight: mean=0.0000, std=0.0046\n",
            "base_model.model.model.layers.17.self_attn.v_proj.weight: mean=-0.0000, std=0.0028\n",
            "base_model.model.model.layers.17.self_attn.o_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.17.mlp.gate_proj.weight: mean=0.0000, std=0.0033\n",
            "base_model.model.model.layers.17.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.17.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.17.input_layernorm.weight: mean=2.2031, std=0.3516\n",
            "base_model.model.model.layers.17.post_attention_layernorm.weight: mean=2.2656, std=0.2949\n",
            "base_model.model.model.layers.18.self_attn.q_proj.weight: mean=-0.0000, std=0.0037\n",
            "base_model.model.model.layers.18.self_attn.k_proj.weight: mean=0.0000, std=0.0045\n",
            "base_model.model.model.layers.18.self_attn.v_proj.weight: mean=-0.0000, std=0.0028\n",
            "base_model.model.model.layers.18.self_attn.o_proj.weight: mean=-0.0000, std=0.0028\n",
            "base_model.model.model.layers.18.mlp.gate_proj.weight: mean=-0.0000, std=0.0033\n",
            "base_model.model.model.layers.18.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.18.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.18.input_layernorm.weight: mean=2.4531, std=0.3477\n",
            "base_model.model.model.layers.18.post_attention_layernorm.weight: mean=2.4062, std=0.2930\n",
            "base_model.model.model.layers.19.self_attn.q_proj.weight: mean=-0.0000, std=0.0036\n",
            "base_model.model.model.layers.19.self_attn.k_proj.weight: mean=-0.0000, std=0.0044\n",
            "base_model.model.model.layers.19.self_attn.v_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.19.self_attn.o_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.19.mlp.gate_proj.weight: mean=0.0000, std=0.0033\n",
            "base_model.model.model.layers.19.mlp.up_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.19.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.19.input_layernorm.weight: mean=2.5156, std=0.3125\n",
            "base_model.model.model.layers.19.post_attention_layernorm.weight: mean=2.5781, std=0.3008\n",
            "base_model.model.model.layers.20.self_attn.q_proj.weight: mean=0.0000, std=0.0036\n",
            "base_model.model.model.layers.20.self_attn.k_proj.weight: mean=0.0000, std=0.0042\n",
            "base_model.model.model.layers.20.self_attn.v_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.20.self_attn.o_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.20.mlp.gate_proj.weight: mean=-0.0000, std=0.0033\n",
            "base_model.model.model.layers.20.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.20.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.20.input_layernorm.weight: mean=2.5625, std=0.3340\n",
            "base_model.model.model.layers.20.post_attention_layernorm.weight: mean=2.7812, std=0.3594\n",
            "base_model.model.model.layers.21.self_attn.q_proj.weight: mean=-0.0000, std=0.0036\n",
            "base_model.model.model.layers.21.self_attn.k_proj.weight: mean=-0.0000, std=0.0042\n",
            "base_model.model.model.layers.21.self_attn.v_proj.weight: mean=0.0000, std=0.0031\n",
            "base_model.model.model.layers.21.self_attn.o_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.21.mlp.gate_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.21.mlp.up_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.21.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.21.input_layernorm.weight: mean=2.5469, std=0.3633\n",
            "base_model.model.model.layers.21.post_attention_layernorm.weight: mean=2.9844, std=0.3867\n",
            "base_model.model.model.layers.22.self_attn.q_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.22.self_attn.k_proj.weight: mean=-0.0000, std=0.0041\n",
            "base_model.model.model.layers.22.self_attn.v_proj.weight: mean=-0.0000, std=0.0032\n",
            "base_model.model.model.layers.22.self_attn.o_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.22.mlp.gate_proj.weight: mean=0.0000, std=0.0034\n",
            "base_model.model.model.layers.22.mlp.up_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.22.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.22.input_layernorm.weight: mean=2.5781, std=0.4160\n",
            "base_model.model.model.layers.22.post_attention_layernorm.weight: mean=3.0938, std=0.3867\n",
            "base_model.model.model.layers.23.self_attn.q_proj.weight: mean=-0.0000, std=0.0035\n",
            "base_model.model.model.layers.23.self_attn.k_proj.weight: mean=-0.0000, std=0.0042\n",
            "base_model.model.model.layers.23.self_attn.v_proj.weight: mean=0.0000, std=0.0033\n",
            "base_model.model.model.layers.23.self_attn.o_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.23.mlp.gate_proj.weight: mean=0.0000, std=0.0034\n",
            "base_model.model.model.layers.23.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.23.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.23.input_layernorm.weight: mean=2.5938, std=0.3516\n",
            "base_model.model.model.layers.23.post_attention_layernorm.weight: mean=3.2344, std=0.3867\n",
            "base_model.model.model.layers.24.self_attn.q_proj.weight: mean=-0.0000, std=0.0035\n",
            "base_model.model.model.layers.24.self_attn.k_proj.weight: mean=0.0000, std=0.0041\n",
            "base_model.model.model.layers.24.self_attn.v_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.24.self_attn.o_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.24.mlp.gate_proj.weight: mean=0.0000, std=0.0034\n",
            "base_model.model.model.layers.24.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.24.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.24.input_layernorm.weight: mean=2.8281, std=0.3887\n",
            "base_model.model.model.layers.24.post_attention_layernorm.weight: mean=3.3594, std=0.3848\n",
            "base_model.model.model.layers.25.self_attn.q_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.25.self_attn.k_proj.weight: mean=-0.0000, std=0.0039\n",
            "base_model.model.model.layers.25.self_attn.v_proj.weight: mean=-0.0000, std=0.0035\n",
            "base_model.model.model.layers.25.self_attn.o_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.25.mlp.gate_proj.weight: mean=0.0000, std=0.0034\n",
            "base_model.model.model.layers.25.mlp.up_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.25.mlp.down_proj.weight: mean=-0.0000, std=0.0029\n",
            "base_model.model.model.layers.25.input_layernorm.weight: mean=2.8906, std=0.4043\n",
            "base_model.model.model.layers.25.post_attention_layernorm.weight: mean=3.4688, std=0.3730\n",
            "base_model.model.model.layers.26.self_attn.q_proj.weight: mean=-0.0000, std=0.0033\n",
            "base_model.model.model.layers.26.self_attn.k_proj.weight: mean=-0.0000, std=0.0038\n",
            "base_model.model.model.layers.26.self_attn.v_proj.weight: mean=-0.0000, std=0.0036\n",
            "base_model.model.model.layers.26.self_attn.o_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.26.mlp.gate_proj.weight: mean=0.0000, std=0.0034\n",
            "base_model.model.model.layers.26.mlp.up_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.26.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.26.input_layernorm.weight: mean=2.7812, std=0.4844\n",
            "base_model.model.model.layers.26.post_attention_layernorm.weight: mean=3.5469, std=0.3594\n",
            "base_model.model.model.layers.27.self_attn.q_proj.weight: mean=0.0000, std=0.0034\n",
            "base_model.model.model.layers.27.self_attn.k_proj.weight: mean=0.0000, std=0.0040\n",
            "base_model.model.model.layers.27.self_attn.v_proj.weight: mean=0.0000, std=0.0035\n",
            "base_model.model.model.layers.27.self_attn.o_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.27.mlp.gate_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.27.mlp.up_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.27.mlp.down_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.27.input_layernorm.weight: mean=2.8438, std=0.3672\n",
            "base_model.model.model.layers.27.post_attention_layernorm.weight: mean=3.6562, std=0.3203\n",
            "base_model.model.model.layers.28.self_attn.q_proj.weight: mean=-0.0000, std=0.0033\n",
            "base_model.model.model.layers.28.self_attn.k_proj.weight: mean=-0.0000, std=0.0036\n",
            "base_model.model.model.layers.28.self_attn.v_proj.weight: mean=-0.0000, std=0.0040\n",
            "base_model.model.model.layers.28.self_attn.o_proj.weight: mean=-0.0000, std=0.0033\n",
            "base_model.model.model.layers.28.mlp.gate_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.28.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.28.mlp.down_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.28.input_layernorm.weight: mean=2.7500, std=0.6055\n",
            "base_model.model.model.layers.28.post_attention_layernorm.weight: mean=3.7500, std=0.2812\n",
            "base_model.model.model.layers.29.self_attn.q_proj.weight: mean=0.0000, std=0.0031\n",
            "base_model.model.model.layers.29.self_attn.k_proj.weight: mean=0.0000, std=0.0034\n",
            "base_model.model.model.layers.29.self_attn.v_proj.weight: mean=0.0000, std=0.0045\n",
            "base_model.model.model.layers.29.self_attn.o_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.29.mlp.gate_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.29.mlp.up_proj.weight: mean=-0.0000, std=0.0030\n",
            "base_model.model.model.layers.29.mlp.down_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.29.input_layernorm.weight: mean=3.0312, std=0.5742\n",
            "base_model.model.model.layers.29.post_attention_layernorm.weight: mean=3.7344, std=0.2451\n",
            "base_model.model.model.layers.30.self_attn.q_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.30.self_attn.k_proj.weight: mean=-0.0000, std=0.0033\n",
            "base_model.model.model.layers.30.self_attn.v_proj.weight: mean=0.0000, std=0.0046\n",
            "base_model.model.model.layers.30.self_attn.o_proj.weight: mean=0.0000, std=0.0035\n",
            "base_model.model.model.layers.30.mlp.gate_proj.weight: mean=-0.0000, std=0.0034\n",
            "base_model.model.model.layers.30.mlp.up_proj.weight: mean=0.0000, std=0.0031\n",
            "base_model.model.model.layers.30.mlp.down_proj.weight: mean=0.0000, std=0.0030\n",
            "base_model.model.model.layers.30.input_layernorm.weight: mean=2.9219, std=0.8477\n",
            "base_model.model.model.layers.30.post_attention_layernorm.weight: mean=3.7812, std=0.2520\n",
            "base_model.model.model.layers.31.self_attn.q_proj.weight: mean=-0.0000, std=0.0031\n",
            "base_model.model.model.layers.31.self_attn.k_proj.weight: mean=0.0000, std=0.0033\n",
            "base_model.model.model.layers.31.self_attn.v_proj.weight: mean=-0.0000, std=0.0047\n",
            "base_model.model.model.layers.31.self_attn.o_proj.weight: mean=-0.0000, std=0.0036\n",
            "base_model.model.model.layers.31.mlp.gate_proj.weight: mean=-0.0000, std=0.0036\n",
            "base_model.model.model.layers.31.mlp.up_proj.weight: mean=0.0000, std=0.0032\n",
            "base_model.model.model.layers.31.mlp.down_proj.weight: mean=0.0000, std=0.0029\n",
            "base_model.model.model.layers.31.input_layernorm.weight: mean=2.9219, std=0.8906\n",
            "base_model.model.model.layers.31.post_attention_layernorm.weight: mean=3.6406, std=0.3164\n",
            "base_model.model.model.norm.weight: mean=5.3125, std=0.6562\n",
            "base_model.model.lm_head.weight: mean=0.0000, std=0.0042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GS5Tc9aFB2JU"
      },
      "id": "GS5Tc9aFB2JU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mistral_to_llama(entry, system_prompt=\"You are a helpful AI assistant for classifying stance.\"):\n",
        "    entry = entry.strip()\n",
        "\n",
        "    # Remove leading/trailing <s> or </s> if duplicated or misformatted\n",
        "    if entry.startswith(\"<s>\"):\n",
        "        entry = entry[len(\"<s>\"):].strip()\n",
        "    if entry.endswith(\"</s>\"):\n",
        "        entry = entry[:-len(\"</s>\")].strip()\n",
        "\n",
        "    llama_chat = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n{system_prompt}<|eot_id|>\"\n",
        "\n",
        "    while True:\n",
        "        inst_start = entry.find(\"[INST]\")\n",
        "        inst_end = entry.find(\"[/INST]\")\n",
        "\n",
        "        if inst_start == -1 or inst_end == -1:\n",
        "            break\n",
        "\n",
        "        # Extract instruction\n",
        "        instruction = entry[inst_start + len(\"[INST]\"):inst_end].strip()\n",
        "\n",
        "        # Find the next closing </s> *after* the [/INST]\n",
        "        s_end = entry.find(\"</s>\", inst_end)\n",
        "        if s_end == -1:\n",
        "            output = entry[inst_end + len(\"[/INST]\"):].strip()\n",
        "            entry = \"\"  # no more segments\n",
        "        else:\n",
        "            output = entry[inst_end + len(\"[/INST]\"):s_end].strip()\n",
        "            entry = entry[s_end + len(\"</s>\"):].strip()\n",
        "\n",
        "        if instruction:\n",
        "            llama_chat += f\"<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|>\"\n",
        "        if output:\n",
        "            llama_chat += f\"<|start_header_id|>assistant<|end_header_id|>\\n{output}<|eot_id|>\"\n",
        "\n",
        "    return llama_chat if \"<|start_header_id|>user<|end_header_id|>\" in llama_chat else None\n",
        "\n",
        "test_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_test.csv\").rename({'key_point': 'stance', 'person_id': 'user'}, axis=1)\n",
        "\n",
        "test_data['llama_prompt'] = test_data['prompt'].apply(mistral_to_llama)"
      ],
      "metadata": {
        "id": "h04rwaPDfFsN"
      },
      "id": "h04rwaPDfFsN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an input prompt\n",
        "input_text = list(test_data.prompt.values)[4]\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text.replace(\"(1 for agree, 0 for not agree)\", \"Strictly only output 1 for agree, 0 for not agree\").replace(\"<s><s>\", \"<s>\"), return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
        "\n",
        "# Generate text\n",
        "output = merged_model.generate(inputs[\"input_ids\"], attention_mask=inputs['attention_mask'], pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "# Decode the generated text\n",
        "generated_text = tokenizer.decode(output[0])\n",
        "\n",
        "# Print the generated text\n",
        "print(generated_text.split(\"[/INST]\")[-1], list(test_data.label.values)[4])"
      ],
      "metadata": {
        "id": "POFVtmqGlsn8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744732324840,
          "user_tz": -480,
          "elapsed": 1400,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbfa6b9-3c6d-4b91-df0b-ff67cab70864"
      },
      "id": "POFVtmqGlsn8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0\n",
            "\n",
            "Contributor234's comments suggest that they have concerns about the 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "guS1zO4CJtC5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744732345605,
          "user_tz": -480,
          "elapsed": 62,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2db017b2-e21d-44b3-ae69-e03bdd133b60"
      },
      "id": "guS1zO4CJtC5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s><s>[INST]Determine whether Contributor234 holds the same view as this statement: \\'Contributors agreed with the need for societal attitudes to evolve alongside structural reforms to reduce academic pressure and broaden definitions of success.’? Based on the following conversation summary, respond with ‘1’ if they share the view, or ‘0’ otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 234 and other contributors: \\n Contributor283: Singapore as a society has yet to realise that academic qualifications are no barometer of ability, intelligence, or successI have seen a lot of \"scholars\" do incredibly stupid things that are completely out of touch with reality\\nContributor771: There are people who memorized word to word for exams... But no problem solving brain... Heard that that\\'s what foreign students do... Lecturers thought they copied from books or friends.. tested them.. they wrote all word for word from their notes / books...\\nContributor296: I have learnt never to trust a politician The current politicians are mostly just talk only. End of the day all paper still needed. Can see from the flanks of ministers in Singapore, all have Top education, even the President elect criterion needs to be CEO of Top companies, simple which Top company will give a uneducated person to be CEOGov if sincered should stop outsourcing work and set an example\\nContributor1462: This is also an issue in many other countries, the paper qualification becomes a filterEven in Malaysia, just like here, to start training as an inspector in the police force, one would need at least a Bachelor’s degree\\nContributor1650: lets take a quote from the sci fi series of star trek where no one works for anything everyone works for what they like..... in that essence the person will learn the key skills required to do the job..... u dont need to be good have a A* for spelling and grammar to do 90% of the jobs out there.... u just need to do the job with great efficiency and accuracy....having someone whom is passionate for the job y would anyone need to filter anyone?\\nContributor1462: Hmm examples?I know that certain corporate finance/sales roles in banks don’t require degree-level skills for the usual tasks and to socialise with clientele. However, the environment is elitist, and thus they filter out potential candidates…\\nContributor234: Humans are good at looking at patterns. What gets you far? What gets you a good job. Do we see meritocracy reflected in when we enter the workforce? Does some schools give more opportunities than others?What is the purpose if sg education? One is to prepare for the workforce, but what is being taught might not be needed on the job. We can see loads of useless skillsfuture where the certs hold no value.Or is it to teach about morals like cleaning trays or respecting diverse cultures. But with a significant portion of our population not having an local sg education, don\\'t we need to expand the scope?We need to reevaluate the system with the end goal in mind. What is the purpose of what we are doing. If we educate, do we have jobs available?If we need jobs like healthcare, shouldn\\'t we make more slots?If an A grade student in singapore is hard to distinguish from an A grade overseas, why are we subjecting our students to difficult assessments?\\n\\n\\nContributor537: I will give MC to myself\\nContributor715: I not sure if doctor can give MC to themselves\\nContributor537: They can\\'t. I meant it to be satire :)\\nContributor786: Fingerprint need to be converted into digital data - image compression and data compression and stored into a database before fingerprint authentication can be performed for sign-in.If hackers can hacked into the database, it can steal the digital fingerprint without the needs to cut the finger.*Bilingualism*1. With the increasing bifurcated world, the heightening geopolitical tussling and tariffs coercion - bilingualism will be increasingly important for us to ensure we are able to communicate in English as a working language as well as a language of unity among our various racial communities.2. Second languages can be used to liaise and communicate with foreign countries.3. Eg. Chinese can use Mandarin to communicate with China, Taiwan, HK and other countries with Chinese diaspora.4. Malays can be used to communicate with Malaysia, Indonesia, Brunei as well as foreign countries with Malays diaspora.5. Indians can be used to communicate with India, Pakistan, Bangladesh, Sri Lanka and other countries with Indian diaspora.6. Languages such as French, Germans, Italian, Portugese, Japanese, Korean, Vietnamese, Thai, Myanmar etc can be used to communicate with the respective Countries of origin.7. These will help Singapore to open up opportunities for business, investment, trade, travel etc with many foreign countries all over the world to secure our future in creating business opportunities and job creation in Singapore as geopolitics tussling deepen and heighten.8. Hence diversity is a positive development for us (not a negative development - depending how Society view it).9. Some countries view single race nationalist as their strength and push out diversity and minorities - due to intolerance and xenophobic views.10. Singapore on the other hands embrace diversity, forge unity among different races and tap on the strength and values of different races to make our Nation strong and diverse - and build connection with countries all over the world through our various diaspora races.11. Hence bilingualism is the product of our tolerant and benevolent Society whereby we accept and value diversity and view it as our strength rather than a source of friction.12. With the unraveling of deepening tension in the Global stage, bilingualism and our diversity through mutual respect will put us in a good stead - as we will be able to navigate ourselves in the complex world to create and find niches for ourselves in business, investment and create jobs for ourselves as traditional source of our prosperity come under stress.Indeed we are a Country rule by Saints 圣人之治。\\nContributor234: some schools are better than others. Some bilingualism will create more opportunities. Some schools have special programme for not all languages. And some jobs require languages that might not be required.Compare malay to chinese, which will a eurasian benefit more? Have we created as much opportunities for minorities? Both in education and jobsWhy are we teaching Tamil when hindi is more used in India?And to be more diverse, shouldnt we change to cmio quota to changing times? Perhaps we can have more Indians and malays grow in proportion instead of importing to maintain supermajority chinese\\n\\n\\nContributor234: Diversity is not the biggest factor. Sure it might help but there are many others like political climate, stability,  location, ease of businessWe are on the topic of educationI dont think so much emphasis be devoted in bilingualism when most jobs dont need it. We even have great ai to do translation.Maybe it\\'s to help with culture and singaporean identity. But imo singaporean identity is divided more than everEspecially division based on languageToo often I see cliques of Chinese and Indians in my office talking in their own language\\n\\n\\nContributor1293: This would be the benefit of bilingualism. We can break and \\'spy\\' on their conversation if you know the language.Especially when we have foreign staff everywhere.Plus waiting to speak/type into translation tool is slow and might be inaccurate (due to technical terms etc). Hence we rarely see world leaders purely using translation tools, but rely on actual translators\\nContributor786: Normally a business deal will be cordial and sealed when we are able to speak their language.Yesterday, I spoke Mandarin to a Taiwanese though both of us can speak English and the contractual terms are in English.We strike up an informal and cordial conversation and throw in some jokes and humor in Mandarin with splattering of English for technical terms (in which I am not able to express the right term in Mandarin) and close the deal easily.I think if we both converse in English, the mood is not so cordial.I can\\'t imagine whipping out my handphone, speak into the Google translate for translation and then talk to the other party Anyone can do that in a business conversation?\\nContributor234: Yet this is a reality of a non Chinese when speaking to mainland/Taiwan for workDoes a competent minority that does not know Chinese have to be sidelined in opportunities because they might miss out on rubbing shoulders with the clientWhat is this state of our workplace?Because of the extremely high English proficiency of our Indian workers, we can communicate to India easily without learning hindi\\n\\n\\nContributor786: 1. Eg. Previously when need to do project with India, We bring in an Indian staff to speak in their language.2. Previously I also got Myanmar colleague as we have dealing in Myanmar.3. When we need to do China project, we meet the clients with Chinese staff.4. But backend can be supported by other races.For eg. My chief network engineer is an Indian staff.\\nContributor234: My issue with the bilingualism is that children is forced to study in a way they have no passion for, and the result of the language education is dubious. If you need language, put it in the job requirements and get someone who really likes the language. You can find numerous Chinese who can barely speak proper mandarin. Sure they might have a basic understanding but you cannot assume they know the language based on their skin\\n\\n\\nContributor786: 5. When I need to produce a project plan to submit to China for a China project, I wrote in English and translate it into Mandarin using Google translate.6. When I read the article, and show it to my China national colleague, he laugh loudly - because the report sounds very comical.7. Finally, he help me to rewrite the whole project plan using my English version.\\nContributor234: Mr Chan vision for a broader definition of success. The old metric of success is passing, excelling all subjects. Being better than peers to win the limited placements. One of subjects being mother tongue. So if bilingualism is that important, is someone who has trouble at their 2nd language a Failure? [/INST] 0\\n\\nContributor234\\'s comments suggest that they have concerns about the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from transformers import logging\n",
        "\n",
        "# Suppress the specific warning\n",
        "warnings.filterwarnings(\"ignore\", message=\"Setting `pad_token_id` to `eos_token_id`\")\n",
        "\n",
        "# Alternatively, set logging to error level to suppress other warnings\n",
        "logging.set_verbosity_error()\n"
      ],
      "metadata": {
        "id": "lSh22pTK4hHt"
      },
      "id": "lSh22pTK4hHt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "BuoHfxza5DMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744731032159,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "687ca234-2463-4d4d-f5fc-218de6d38b8c"
      },
      "id": "BuoHfxza5DMO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format Test Data\n",
        "from tqdm import tqdm\n",
        "all_predictions = []\n",
        "for test_prompt in tqdm(list(test_data.prompt.values)):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(test_prompt.replace(\"(1 for agree, 0 for not agree)\", \"You must strictly only output 1 for agree, 0 for not agree\").replace(\"<s><s>\", \"<s>\"), return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
        "\n",
        "    # Generate text\n",
        "    output = merged_model.generate(inputs[\"input_ids\"], attention_mask=inputs['attention_mask'], pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0] )\n",
        "    generated_text_cleaned = generated_text.split(\"[/INST]\")[-1]\n",
        "    if \"1\" in generated_text_cleaned:\n",
        "        prediction = 1\n",
        "    elif \"0\" in generated_text_cleaned:\n",
        "        prediction = 0\n",
        "    else:\n",
        "        prediction = -1\n",
        "    all_predictions.append(prediction)\n",
        "test_data[\"pred\"] = all_predictions\n"
      ],
      "metadata": {
        "id": "-K0mNdEoLvv3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744732170178,
          "user_tz": -480,
          "elapsed": 1133385,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7de690f-8fc3-40ce-e04b-ba47b1fd44e9"
      },
      "id": "-K0mNdEoLvv3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1349/1349 [18:53<00:00,  1.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Percentage of incorrectly parsed output: {len(test_data[test_data['pred'] == -1])/len(test_data)}\")\n"
      ],
      "metadata": {
        "id": "Vy3QROAULxJT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744732170178,
          "user_tz": -480,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87eec052-310f-4095-f2dd-971066f39514"
      },
      "id": "Vy3QROAULxJT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of incorrectly parsed output: 0.005189028910303929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score,\n",
        "    auc,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "# Metrics calculation\n",
        "def compute_metrics(true_labels, prediction):\n",
        "    metrics = {}\n",
        "    metrics[\"accuracy\"] = accuracy_score(true_labels, prediction)\n",
        "    metrics[\"f1\"] = f1_score(true_labels, prediction)\n",
        "    metrics[\"precision\"] = precision_score(true_labels, prediction)\n",
        "    metrics[\"recall\"] = recall_score(true_labels, prediction)\n",
        "    metrics[\"f1_weighted\"] = f1_score(true_labels, prediction, average = \"weighted\")\n",
        "    metrics[\"recall_weighted\"] = recall_score(true_labels,prediction, average = \"weighted\")\n",
        "    metrics[\"precision_weighted\"] = precision_score(true_labels, prediction, average = \"weighted\")\n",
        "    metrics[\"f1_marco\"] = f1_score(true_labels, prediction, average = \"macro\")\n",
        "    metrics[\"precision_marco\"] = precision_score(true_labels, prediction, average = \"macro\")\n",
        "    metrics[\"recall_marco\"] = recall_score(true_labels, prediction, average = \"macro\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "0dYR7ila3UAA"
      },
      "id": "0dYR7ila3UAA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred_to_evaluate = test_data[test_data[\"pred\"]!=-1]\n",
        "\n",
        "\n",
        "compute_metrics(list(pred_to_evaluate[\"label\"].values), list(pred_to_evaluate[\"pred\"].values))\n"
      ],
      "metadata": {
        "id": "OOzcfKEFLzNs",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744732278589,
          "user_tz": -480,
          "elapsed": 64,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc9d1fb-f3ff-4680-e5a3-049ac637b191"
      },
      "id": "OOzcfKEFLzNs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5312965722801788,\n",
              " 'f1': 0.5741367637102234,\n",
              " 'precision': 0.5280199252801993,\n",
              " 'recall': 0.629080118694362,\n",
              " 'f1_weighted': 0.5267179602714996,\n",
              " 'recall_weighted': 0.5312965722801788,\n",
              " 'precision_weighted': 0.5320807790760923,\n",
              " 'f1_marco': 0.5265050015734215,\n",
              " 'precision_marco': 0.5320990164434392,\n",
              " 'recall_marco': 0.5308574246166421}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_to_evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WXoW-7QgJPvb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744732226365,
          "user_tz": -480,
          "elapsed": 330,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "781864a0-fe0e-4c93-dbe3-9209df50d92c"
      },
      "id": "WXoW-7QgJPvb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      discussion_id                                             stance  \\\n",
              "0               223  Contributors expressed concern over the securi...   \n",
              "1               223  Contributors suggested that the Government sho...   \n",
              "2               223  Contributors expressed concern about the impac...   \n",
              "3               227  Contributors agreed with the need for societal...   \n",
              "4               227  Contributors agreed with the need for societal...   \n",
              "...             ...                                                ...   \n",
              "1344            242  Contributors emphasized the need for a strong ...   \n",
              "1345            242  Contributors emphasized the need for a strong ...   \n",
              "1346            242  Contributors discussed the importance of havin...   \n",
              "1347            242  Contributors discussed the importance of havin...   \n",
              "1348            242  Contributors discussed the importance of havin...   \n",
              "\n",
              "                     contributor_name  key_point_id  contributor_id  \\\n",
              "0           Loh Zheng Han | 97210312           2659            1381   \n",
              "1     Ching Jia Alex Chen | 97313019           2660            1552   \n",
              "2                        Yew Heng Pah          2702             501   \n",
              "3                        Liew Poh Eng          2906              18   \n",
              "4              Adam Haziq Mohd Arshad          2906             208   \n",
              "...                               ...           ...             ...   \n",
              "1344                     Matthew Chua          3550             178   \n",
              "1345                       Jinhui Lee          3550            1193   \n",
              "1346                     Matthew Chua          3551             178   \n",
              "1347           Adam Haziq Mohd Arshad          3551             208   \n",
              "1348                       Jinhui Lee          3551            1193   \n",
              "\n",
              "      expressed_view  user                                              topic  \\\n",
              "0               True  1407  The parliamentary session on February 4th will...   \n",
              "1              False  1578  The parliamentary session on February 4th will...   \n",
              "2               True   527  The parliamentary session on February 4th will...   \n",
              "3              False    44  The discussion revolves around Minister Chan's...   \n",
              "4               True   234  The discussion revolves around Minister Chan's...   \n",
              "...              ...   ...                                                ...   \n",
              "1344            True   204  The discussion revolves around Singapore's fis...   \n",
              "1345            True  1219  The discussion revolves around Singapore's fis...   \n",
              "1346           False   204  The discussion revolves around Singapore's fis...   \n",
              "1347            True   234  The discussion revolves around Singapore's fis...   \n",
              "1348            True  1219  The discussion revolves around Singapore's fis...   \n",
              "\n",
              "                                topic_statement  label  \\\n",
              "0               Parliament Sitting (4 Feb 2025)      1   \n",
              "1               Parliament Sitting (4 Feb 2025)      0   \n",
              "2               Parliament Sitting (4 Feb 2025)      1   \n",
              "3             Speech at MOE x NIE x IPS Lecture      0   \n",
              "4             Speech at MOE x NIE x IPS Lecture      1   \n",
              "...                                         ...    ...   \n",
              "1344  Singapore's fiscal planning effectiveness      1   \n",
              "1345  Singapore's fiscal planning effectiveness      1   \n",
              "1346  Singapore's fiscal planning effectiveness      0   \n",
              "1347  Singapore's fiscal planning effectiveness      1   \n",
              "1348  Singapore's fiscal planning effectiveness      1   \n",
              "\n",
              "                                         content_concat  \\\n",
              "0     Contributor726: You are not reading US politic...   \n",
              "1     Contributor726: You are not reading US politic...   \n",
              "2     Contributor527: Regarding the trump tariffs.. ...   \n",
              "3     Contributor543: I think today's topic ties in ...   \n",
              "4     Contributor283: Singapore as a society has yet...   \n",
              "...                                                 ...   \n",
              "1344  Contributor527: I think this will be the start...   \n",
              "1345  Contributor1219: When the government continuou...   \n",
              "1346  Contributor527: I think this will be the start...   \n",
              "1347  Contributor2132: like breaking up opposition s...   \n",
              "1348  Contributor1219: When the government continuou...   \n",
              "\n",
              "                                                 prompt  pred  \n",
              "0     <s>[INST]Determine whether Contributor1407 hol...     1  \n",
              "1     <s>[INST]Determine whether Contributor1578 hol...     1  \n",
              "2     <s>[INST]Determine whether Contributor527 hold...     1  \n",
              "3     <s>[INST]Determine whether Contributor44 holds...     0  \n",
              "4     <s>[INST]Determine whether Contributor234 hold...     0  \n",
              "...                                                 ...   ...  \n",
              "1344  <s>[INST]Determine whether Contributor204 hold...     1  \n",
              "1345  <s>[INST]Determine whether Contributor1219 hol...     1  \n",
              "1346  <s>[INST]Determine whether Contributor204 hold...     1  \n",
              "1347  <s>[INST]Determine whether Contributor234 hold...     1  \n",
              "1348  <s>[INST]Determine whether Contributor1219 hol...     1  \n",
              "\n",
              "[1342 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7fc76f4-cace-45de-8e29-d40070123cf5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discussion_id</th>\n",
              "      <th>stance</th>\n",
              "      <th>contributor_name</th>\n",
              "      <th>key_point_id</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>expressed_view</th>\n",
              "      <th>user</th>\n",
              "      <th>topic</th>\n",
              "      <th>topic_statement</th>\n",
              "      <th>label</th>\n",
              "      <th>content_concat</th>\n",
              "      <th>prompt</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>223</td>\n",
              "      <td>Contributors expressed concern over the securi...</td>\n",
              "      <td>Loh Zheng Han | 97210312</td>\n",
              "      <td>2659</td>\n",
              "      <td>1381</td>\n",
              "      <td>True</td>\n",
              "      <td>1407</td>\n",
              "      <td>The parliamentary session on February 4th will...</td>\n",
              "      <td>Parliament Sitting (4 Feb 2025)</td>\n",
              "      <td>1</td>\n",
              "      <td>Contributor726: You are not reading US politic...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor1407 hol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>223</td>\n",
              "      <td>Contributors suggested that the Government sho...</td>\n",
              "      <td>Ching Jia Alex Chen | 97313019</td>\n",
              "      <td>2660</td>\n",
              "      <td>1552</td>\n",
              "      <td>False</td>\n",
              "      <td>1578</td>\n",
              "      <td>The parliamentary session on February 4th will...</td>\n",
              "      <td>Parliament Sitting (4 Feb 2025)</td>\n",
              "      <td>0</td>\n",
              "      <td>Contributor726: You are not reading US politic...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor1578 hol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>223</td>\n",
              "      <td>Contributors expressed concern about the impac...</td>\n",
              "      <td>Yew Heng Pah</td>\n",
              "      <td>2702</td>\n",
              "      <td>501</td>\n",
              "      <td>True</td>\n",
              "      <td>527</td>\n",
              "      <td>The parliamentary session on February 4th will...</td>\n",
              "      <td>Parliament Sitting (4 Feb 2025)</td>\n",
              "      <td>1</td>\n",
              "      <td>Contributor527: Regarding the trump tariffs.. ...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor527 hold...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>227</td>\n",
              "      <td>Contributors agreed with the need for societal...</td>\n",
              "      <td>Liew Poh Eng</td>\n",
              "      <td>2906</td>\n",
              "      <td>18</td>\n",
              "      <td>False</td>\n",
              "      <td>44</td>\n",
              "      <td>The discussion revolves around Minister Chan's...</td>\n",
              "      <td>Speech at MOE x NIE x IPS Lecture</td>\n",
              "      <td>0</td>\n",
              "      <td>Contributor543: I think today's topic ties in ...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor44 holds...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>227</td>\n",
              "      <td>Contributors agreed with the need for societal...</td>\n",
              "      <td>Adam Haziq Mohd Arshad</td>\n",
              "      <td>2906</td>\n",
              "      <td>208</td>\n",
              "      <td>True</td>\n",
              "      <td>234</td>\n",
              "      <td>The discussion revolves around Minister Chan's...</td>\n",
              "      <td>Speech at MOE x NIE x IPS Lecture</td>\n",
              "      <td>1</td>\n",
              "      <td>Contributor283: Singapore as a society has yet...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor234 hold...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1344</th>\n",
              "      <td>242</td>\n",
              "      <td>Contributors emphasized the need for a strong ...</td>\n",
              "      <td>Matthew Chua</td>\n",
              "      <td>3550</td>\n",
              "      <td>178</td>\n",
              "      <td>True</td>\n",
              "      <td>204</td>\n",
              "      <td>The discussion revolves around Singapore's fis...</td>\n",
              "      <td>Singapore's fiscal planning effectiveness</td>\n",
              "      <td>1</td>\n",
              "      <td>Contributor527: I think this will be the start...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor204 hold...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>242</td>\n",
              "      <td>Contributors emphasized the need for a strong ...</td>\n",
              "      <td>Jinhui Lee</td>\n",
              "      <td>3550</td>\n",
              "      <td>1193</td>\n",
              "      <td>True</td>\n",
              "      <td>1219</td>\n",
              "      <td>The discussion revolves around Singapore's fis...</td>\n",
              "      <td>Singapore's fiscal planning effectiveness</td>\n",
              "      <td>1</td>\n",
              "      <td>Contributor1219: When the government continuou...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor1219 hol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>242</td>\n",
              "      <td>Contributors discussed the importance of havin...</td>\n",
              "      <td>Matthew Chua</td>\n",
              "      <td>3551</td>\n",
              "      <td>178</td>\n",
              "      <td>False</td>\n",
              "      <td>204</td>\n",
              "      <td>The discussion revolves around Singapore's fis...</td>\n",
              "      <td>Singapore's fiscal planning effectiveness</td>\n",
              "      <td>0</td>\n",
              "      <td>Contributor527: I think this will be the start...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor204 hold...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>242</td>\n",
              "      <td>Contributors discussed the importance of havin...</td>\n",
              "      <td>Adam Haziq Mohd Arshad</td>\n",
              "      <td>3551</td>\n",
              "      <td>208</td>\n",
              "      <td>True</td>\n",
              "      <td>234</td>\n",
              "      <td>The discussion revolves around Singapore's fis...</td>\n",
              "      <td>Singapore's fiscal planning effectiveness</td>\n",
              "      <td>1</td>\n",
              "      <td>Contributor2132: like breaking up opposition s...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor234 hold...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>242</td>\n",
              "      <td>Contributors discussed the importance of havin...</td>\n",
              "      <td>Jinhui Lee</td>\n",
              "      <td>3551</td>\n",
              "      <td>1193</td>\n",
              "      <td>True</td>\n",
              "      <td>1219</td>\n",
              "      <td>The discussion revolves around Singapore's fis...</td>\n",
              "      <td>Singapore's fiscal planning effectiveness</td>\n",
              "      <td>1</td>\n",
              "      <td>Contributor1219: When the government continuou...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor1219 hol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1342 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7fc76f4-cace-45de-8e29-d40070123cf5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7fc76f4-cace-45de-8e29-d40070123cf5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7fc76f4-cace-45de-8e29-d40070123cf5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ca7dc51-fb12-4b59-87b6-efe46179afbb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ca7dc51-fb12-4b59-87b6-efe46179afbb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ca7dc51-fb12-4b59-87b6-efe46179afbb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2dba0cc5-c92b-4f39-b2fb-27b6e3aeb721\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pred_to_evaluate')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2dba0cc5-c92b-4f39-b2fb-27b6e3aeb721 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pred_to_evaluate');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pred_to_evaluate",
              "summary": "{\n  \"name\": \"pred_to_evaluate\",\n  \"rows\": 1342,\n  \"fields\": [\n    {\n      \"column\": \"discussion_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 223,\n        \"max\": 242,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          240,\n          239,\n          223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stance\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"Contributors expressed concern that providing cash and credit handouts might create a sense of entitlement and suggested promoting self-reliance and resilience.\",\n          \"Contributors expressed concern about the sustainability of these handouts and whether they address the root causes of rising costs.\",\n          \"Contributors questioned the government's approach of pegging BTO prices to the market rates, which are rising rapidly, making it difficult for younger generations to afford housing.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contributor_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 180,\n        \"samples\": [\n          \"Dolly Wong\",\n          \"Yip Peng Kiong | 96533237 \",\n          \"May-Ann Lim | 98471950 \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"key_point_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 200,\n        \"min\": 2659,\n        \"max\": 3551,\n        \"num_unique_values\": 150,\n        \"samples\": [\n          3116,\n          2983,\n          3377\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contributor_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 569,\n        \"min\": 18,\n        \"max\": 2105,\n        \"num_unique_values\": 180,\n        \"samples\": [\n          695,\n          1420,\n          2049\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expressed_view\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 569,\n        \"min\": 44,\n        \"max\": 2132,\n        \"num_unique_values\": 180,\n        \"samples\": [\n          721,\n          1446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"The discussion revolves around the Committee of Supply speeches delivered by Singapore's Minister for Manpower, Dr. Tan See Leng, and Minister for Health, Ong Ye Kung. Dr. Tan's speech focused on building an adaptable workforce, supporting business transformation, managing foreign labour needs, and fostering inclusive workplaces. He highlighted initiatives like the SkillsFuture Workforce Development Grant and the Career Health SG programme to enhance workforce resilience and business productivity. Mr. Ong's speech addressed healthcare improvements, including subsidy enhancements, capacity expansion, and quality improvements, aiming to balance affordability, availability, and quality of healthcare services.\",\n          \"The discussion revolves around the Committee of Supply speeches delivered by Minister for National Development Desmond Lee and Minister for Transport Chee Hong Tat. Mr. Lee's speech focused on plans to keep public housing affordable, accessible, and inclusive, highlighting efforts to ramp up the supply of new housing, reduce waiting times, and support diverse housing needs, including for seniors and lower-income families. Mr. Chee's speech outlined plans to enhance transport connectivity, including expanding the rail network, improving bus services, and strengthening the air hub with investments in infrastructure and innovation.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_statement\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"MOM and MOH COS Speeches\",\n          \"MND and MOT COS Speeches\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_concat\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 416,\n        \"samples\": [\n          \"Contributor311: Climate vouchers may also be extended to non-electronic items like blackout curtains.With higher climate heat, blackout curtains block UV light, conceal light, save energy during rainy seasons, create better sleep environment and home privacy. Most importantly, they reduce noise pollution in this densely populated city.In the long run, it saves utility bills.\\nContributor527: This is one classic example of how government can still save money.. this is regard to have proper planning for road access points, facilities, bus stops, u turn points and etcLike I did shared to reach when we are at reach Whatsapp chat previously about why only start to construct new u turn points after this new bto site that residents complained that need to drive long distance to make u turn on main road. This should be incorporated in design phase. There is also another one mp posting about residents feedback about need to walk one big round to access bus stop ( new bto site) and after hearing feedback, we now created a pathway direct to bus stop so residents dont need walk one big round. So again this one is poor planning that resulted in need to spend extra money to fix after construction is completed. So these extra spending actually could be saved if there is good planning before construction start.Some might think these are small money, but then if every bto project have all these little small money spent due to poor planning. These small money spent does adds up..Anyway my thinking to this solution is to have no barrier gentry. Like the old airport hawker centre carpark and also the punggol north shore carpark - No barrier carpark entry and exit.Hope with no barrier gentry, it could help in terms on clearing those cars that enter and exit carpark.https://www.tomshardware.com/pc-components/dram/leading-dram-makers-may-stop-producing-ddr4-and-ddr3-by-late-2025?fbclid=IwY2xjawIicWxleHRuA2FlbQIxMQABHXzyaK0lnoiGW8AhXPz0d_p-JMSiQxYtJM_5BV66ZeurtKhDltQuiNHt7w_aem_y3cBzdCT9G0JNavsstVCiwLook at this..Everyone is talking about AI, but then other then AI, those mid tier chipset, memory chips and etc.. all china dominate in terms on pricing.Can see the clear trend ahead.. and do we still want to follow in with more expensive buying or divert away from especially america to look into growing marker especially in BRICS+ European cars manufacturer all also can't compete with china. Japanese cars manufacturer also can't compete with chinaThere is going to have a big shift.. so we really need to catch the wave early\\nContributor325: I appreciate the use of a range of policy tools, like fiscal policy measures, such as CDC vouchers, utility rebates, and the SG60 package, that help households manage rising costs. In addition, structural policies such as top-ups to productivity, R&D, and AI adoption funds aim to enhance long-term competitiveness and support wage growth. The focus on climate resilience, including investments in coastal protection and clean transportation, further complements these initiatives by supporting a more sustainable economy.But I think there are still more ways for govt to address inflation and encourage real wage growth.- On the monetary policy front, I think govt can consider tighter SGD exchange rate to rein in imported inflation.- And further fiscal measures like subsidies or more credits designed for us to buy essential goods.- And structural policies like agri-tech, vertical farming, and further diversify our supply chain and import sources to countries that are friendly towards globalisation.- And consider other policy tools like subsidising residential rentals for residents, and subsidise business rentals for local business owners.\\nContributor726: Yes, although our income will be increased augmented by government subsidies, CDC vouchers etc, our cost of living will keep rising every year, like a dog chasing to bite its tail. The culprits are the landowners especially the bankers, financial institutions and the REITS corporations. They reap all the gains that we may have annually.I propose that the government consider these two strategies to damper the inflation.1. To pass a legislation to control the run away rentals that these companies listed above charge every few years.2. To give the people shares in the businesses of REITS as shareholders in the manner that Goh Chok Tong implemented previously. People can then gain a proportionate share in the profits of the rentals. These shares are not salable in the open market but to sell it back to the government.\\nContributor1589: Not an economist, and will comment on areas that are of concern to me as a Singaporean by birth, of Singapore parentage. The most pressing issue at present is the quality/ standards of our living and the overcrowding issues we are experiencing at the moment. High criterions set to ensure only quality candidates to permanently reside in Singapore and having a place to reside here in our shores are important. Is no longer a matter of bringing truckloads of insane money to secure a spot here but the credentials that come with such. This is likely not addressed in Budget 2025, but should be looked into, imho. Up to a billion dollars to upgrade our hawkers over the next 20 to 30 years is a good initative to retain our heritage and its longevity. PM Wong also spoke about the importance of productivity as a nation to be competitive on a global level. It is true and we have always been, but to always play the catch up game is a neverending pursuit. Realistically, we are not UK, China or US, the power/ huge nations, and we will never be. Being a tiny nation with limited resources, and having immense recognition from abroad for being many of the TOPs on the global map i.e, Singapore Airlines. The next step is to refine our current artwork and take steps to furnish genuine quality pieces to not solely showcase that we are TOPs, but with skills and intensity. I feel that a part of the budget can be placed at such and not at all times on a competitive level with the power nations.\\nContributor1431: These supporting measures are not new per se, as well as much needed and much appreciated by all. And as with budget, it is financially inclined or focused, correctly so. However, a society require more then financial assistance, as it is one component of the many other factors. As a result of this Budget, will Singapore or Singaporeans can continue or rise further in the new challenging world. The society and human fabric where Singapore has come from the founding days, where is this part going to fall under, which  component of the government?  In receiving these assistance, will the other facets of family matters, career challenges and risks, will all fall into place?. Will the $300 assistance for part time studies, support new jobs? Where does MIT stands on this? If our employment rate is healthy, are we bridging any gaps? Money will solve one part of the many macro issues surely, and we hope in the near future, as we look back, some of these successes are due to this assistance in this Budget.\",\n          \"Contributor527: I am think sweet spot would be about 45 minutes lunch breakBus driver deserve a longer lunch break\\nContributor1189: they are compensated through breaks they take in between of journeyswhich can range from 15 -20 minsBus drivers are paid using  how many  trips they make and the overtime they can stack , most are malaysians and prefer lesser break time to make more money so ..\\nContributor581: unfortunately, lunch hour/dinner hour is also peak hour ... multiple other breaks is a good trade-off (my opinion) and they get priority queue for food too\\nContributor1189: yes , NTWU canteens give them priority queue for food\\nContributor527: Have part time drive to cover?Like we have standby bus driver for mrt disruptionSo should be able to find part time driver to drive for that few hours right?\\nContributor581: if many drivers want this, sure... but is this really what they want?\\nContributor527: I am sure there will have some that are semi retired don't mind drive a few hours part timeThose are maybe past bus driver themselves\\nContributor581: for example for me, i would prefer to have 20min lunch break, work work earn more... then take a long holiday (multiple days leave at a stretch on special occasions)but i m not bus driver \\ud83e\\udd23\\nContributor527: But I read report that if bus driver is late for schedule and or bus bay full and need time to find parking. It all eat into the time. So imagine 25 minutes lunch break become 15 minutes lunch break for example.This is too rushing\\nContributor581: i agree that tackling and resolving reliability issues will be more effective in improving my transportation experience, than adding more rail lines\\nContributor1189: Bus drivers have three shifts - A  for AM shift , P for PM shift , S/T shift are the day shift driver with rest back in the afternoon and usually operate during  the AM / PM peak hour . So usually during lunch / dinner break , the S/T shift bus driver will step in and I am not sure what report u read but some routes practise the jump bus so the driver will change bus when he return to the terminus and another bus captain will continue the journey with a different bus . Yes , they are congestion and parking issues if all the buses comeback at once , that is why they should tackle and resolve the reliability issue firstIf there are late for lunch hour or dinner hour , the operation command centre will usually give them extra time and start the route halfway to ensure that they are properlly rested\\nContributor527: I read from straits time article\\nContributor1189: or have their meal\\nContributor527: This one is more detail explanation.. good info to know thanks\\nContributor1189: bcoz i was from that industry and have friends in the industry so i know the situation better\\nContributor581: the tengah line and seletar line seem to be very much parallel to existing lines... just based on first impressions of the very rough info released by the govt.... in the past, adding rails created lots of benefits  because the rail lines were strategically placed to serve whole regions. now we already have an extensive rail network, adding more n more creates more complexity with less incremental benefits (my opinion)putting effort to maintain n improve reliability of existing network is more important even though it may not look so \\\"grand\\\" on somebody's portfolio\\nContributor44: Probably right or good to have more mrt lines as population increases, increase in new housing areas not served by mrt, to avoid further overcrowding on existing lines... but transport, medical, housing all should plan ahead together in tandem in view of population plans, changes, demographic and needs change...How about PMDs...? Are they still allowed on pedestrian paths...? Their speed limit higher correct...? Dangerous for pedestrians...Stressful even just to be pedestrians these days...\\nContributor527: Oh ya this is more towards shopping malls in housing estate..What I noticed is that nowadays those new shopping malls in housing estate the parking lot in these malls like quite little.Don't know is it because of government encourage car lite..Some shopping malls pickup and drop off points is also inside the shopping malls.So when carpark is full, those drivers going to pickup and drop off will also get stuck in the queueThis cause frustration.. especially for riders going into the mall or waiting at pickup point for driver to arriveExample like woodleigh mall.So I am thinking, maybe for ura when planning for areas that is cater for shopping malls..Can also see whether can have requirements that pickup and drop off points entry and exit point should be separate from entry and exit of shopping malls?So drivers going to pick up passenger should not share the same entry point as those going to mall carpark\\nContributor325: It\\u2019s great to see the extension of the Cross Island Line to cover the west side of Singapore. I believe it\\u2019s important to have alternative train lines reaching the west, so that incidents like the breakdown between Jurong East and Buona Vista late last year don\\u2019t cause such major disruptions again.I feel that housing and transport go hand in hand. It\\u2019s crucial for the govt to plan ahead and overhaul our road infrastructure to better accommodate PMAs, PMDs, autonomous vehicles, and bicycles. Personally, I still feel that sharing footpaths with some of these devices is unsafe, dedicated lanes or roads for these modes of transport are still necessary.On top of that, we need better bus frequency, especially for the more ulu HDB estates. While flats in these areas may be cheaper, good transport accessibility is still essential. It\\u2019s unreasonable to wait 15 to 30 minutes for a bus, followed by another 15 to 30 minutes just to reach the nearest MRT station, and then spend 30 minutes to an hour on the train, only to find out the workplace is yet another 15 to 30 minutes away by bus. This kind of daily commute is exhausting. I strongly feel that future planning should prioritise deploying autonomous buses to help address these transport challenges.\\nContributor206: https://www.mot.gov.sg/news/details/written-reply-to-parliamentary-question-on-reinstating-late-night-bus-routes-and-services-to-support-nightlife-sector-recoveryIn terms of connectivity and transportation, it would be good to explore offering late night bus routes at an affordable rate for users, while remaining profitable for the operator.Users this can help- people who stayed with their group after dinner, and are too broke for Grab/Gojek/Taxis- F&B or other staff that end work late and missed the last bus/mrt home\\nContributor688: For transport, they should look at how to solve the root of the problem for traffic jam. Is it really a case of too many cars or is it due to bad driving attitude of the drivers which lead to traffic jam. If didnt solve the root of the problem, then no point increasing the number of buses or increase the ERP/COE etc as at the end of the day, the problem still remain unsolved.\\nContributor256: It\\u2019s awesome to hear how our government has built more hdbs, and working to improve connectivity. But if you think about it; our housing and public transport was quite nasty. We neglected to build ahead of demand and choose instead to let them lag demand. Our infrastructure is designed to be under produced; forcing it to be efficient but not robust. So yes. Good job on improving. But improvements from a 35 marks to 60 marks\\u2026. Isn\\u2019t it to be expected? How low can you go?$5bn for air travel; and just $1bn for public transport. The priorities is always to attract outsiders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1342,\n        \"samples\": [\n          \"<s>[INST]Determine whether Contributor1920 holds the same view as this statement: 'Contributors called for regulation of the tuition industry to ensure ethical advertising and prevent exploitation of parents' fears.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 1920 and other contributors: \\n Contributor76: School with 40paxs in a class and short period, wonder if they have time for different solving methods.\\nContributor420: No time\\nContributor466: It is a choice each parent must choose n bear the consequence. No right or wrong here. My choice is I want to tutor my son. I paid a price for it. The outcome is satisfactory. My son was good enough to do Laws n is now a lawyer. I became a QA Manager in an aviation company by the time I retired. I guess I could become a QA Manager earlier if I did not tutor my son. Some of my colleagues became Managers much earlier. There is no regret. Both of us achieved our goals. Later for me.\\nContributor420: Great choice!To watch your son to become dragon and to watch your daughter to become Phoenix- great!\\nContributor466: I only have a son. I am not trying to groom a dragon! I am trying to groom my son.\\nContributor1377: A child 's success in life is not determined by his PSLE score or the school he goes to. It takes more than academic achievements and CCAs involvement that help shaped his success. In my opinion, it is his personal aspirations, motivation and the experiences he has in his life that help spur him on the road to success. In Singapore and most part of Asia, an individual 's success is measured by how much wealth he has, his social status and his standing in the society which comes as a result of an investment in his education. Thus, the frenzied attention given to tuition classes for those whose parents are more than eager to groom a dragon or a phoenix.\\nContributor466: Agree. We as parents should not be too dominant in our children developments. We help them to achieve their goals or dreams but it is their dreams or goals not ours.\\nContributor1377: As parents, we have the moral responsibility to see to their growth and development. But ,  i feel we ought to be mindful that they are individuals who have their preferences and choices which may not align with ours. Excessive tuition do not help.\\nContributor420: Parental expectation of their children which they gave birth to\\ud83d\\ude01\\nContributor1377: Yes, it is only natural. But I feel ultimately, parents want their children to be happy individuals and while we act as their guardians, they should be given ample space and time to develop their own interests. Excessive tuition leaves them with no time nor space.\\nContributor731: Total messages:7474\\nContributor2056: /stat@combot\\nContributor626: In fact, the pressure to succeed can have far-reaching consequences, as highlighted in the following insight:\\\"The evil of comparison lies between success and failure, where the inability to attain one's goals or aspirations marks the beginning of failure, leading to the degeneration of self-love and self-worth. In this reality, the stark contrast between rich and poor further exacerbates the issue, casting a long shadow of unhappiness over one's lifetime \\u2013 a harsh truth that affects minds and ages universally.\\\" - anonymity\\nContributor1920: The usage of tuition has far shifted from its original purpose, which is that of aiding struggling students brush up on their knowledge such that they are able to catch up to their peers. Tuition today has another objective: To put students ahead of their peers.This societal change in mindset of what tuition\\u2019s main objective is for stems from the push in getting good grades (to an excessive extent). While Minister CCS has good intents, and it is certainly a good start, a industry worth millions of dollars will not change unless there is a change in mindset of parents.Parents need to first acknowledge that perhaps their child\\u2019s grades should not be the be all and end all. That perhaps a child may have interests in a certain topic and not as much in others. While we should strive to do well, excessive focus on only doing well takes away from a child\\u2019s learning, where they are learning for the sake of memorisation or for doing well, but do not retain knowledge in the long term.In my opinion, tuition is crucial only for struggling students who may have difficulties in certain subjects or topics, and not a mean to obtain good grades, our teachers should be sufficient. There is no benefit to excessive tuition, and forcing your child to attend more tuition will not always yield better results (see diminishing returns).The tuition industry should be far more regulated, especially with their advertisements. I\\u2019ve seen advertisements of tuition centres where students who have scored well are put front and center.To say this may be somewhat deceptive is an understatement. Not all students may do well even after tuition, and these advertisements set unrealistic standards.\\n\\n\\nContributor626: Code of Conduct and Guidelines?\\nContributor420: Rules and Strict regulations to be imposed\\ud83d\\ude0a\\nContributor626: Restrict the \\\"comparison or KPI or success rates\\\" of a tuition centre. Simply, no comparative advertising!Similarly for other professional bodies: law, accounting, medical.\\nContributor420: Mostly, on Maths, Science, English and Mother tongue tuition\\nContributor830: Just ban tuition centres and restart, reboot to serve weaker students.Let Free Market fir private tutors for those who can afford it.Let PTA and individual school work out a tuition scheme for all.Personal responsibility, self help abd don't wait for Nanny to solve all the problems within one capability to do so.\\nContributor626: \\\"Private Tuition is a Private matter. To give or not to give, or overly give, is another matter.\\\"*The Illusion of Academic Success?*This profound statement underscores the dangers of comparison and the importance of self-worth. By recognising the impact of socioeconomic disparities and the pressure to succeed, we can begin to break free from the cycle of competition and cultivate a more positive, empowering relationship with ourselves and our children.In many Asian cultures, the pressure to excel academically is particularly intense. Parents often feel compelled to enrol their children in expensive tutoring programmes, extracurricular activities, and elite schools, all in the hopes of securing a coveted spot at a top university. But at what cost?Research has shown that this kind of pressure can have serious negative consequences for children's mental and emotional wellbeing. It can lead to anxiety, depression, and even suicidal thoughts. And yet, despite these risks, many parents feel trapped in this cycle of competition and \\\"one-upmanship\\\".So how can we break free from this cycle and find a more balanced, sustainable approach to parenting? The answer lies in embracing simplicity.By letting go of our need to control every aspect of our children's lives, we can create space for them to grow, learn, and thrive in their own unique way. By focusing on the things that truly matter \\u2013 love, connection, and community \\u2013 we can cultivate a sense of purpose and fulfilment that goes beyond mere academic achievement. ourselves and our children. And older children and youth these days: don't like to be nagged or pursued at!\\nContributor1920: Singapore has always been a place where underground transactions have taken place, whether the government likes it or not. It is a consequence of being a global partner, and a neutral party.\\n\\n\\nContributor1668: Just a thought. If something is detrimental, some form of constructive action or intervention is necessary, be it from the affected child, parents, teachers, etc. Let not the word 'excessive' be the sole benchmark for decision making by any concerned party. We will likely continue to disagree on what's excessive but if something is clearly detrimental we should act decisively depending on observable and verifiable behaviour, etc.\\nContributor626: Three considerations: ability, capability, and capacity\\nContributor420: Not 100% totally detrimental- tuition as it does help sometimes\\ud83d\\ude01Useful at times, excessively on other times, situations\\nContributor626: \\\"Pay & Pay...Pay for the Peace of Minds?\\\"Thanks KC!To give or not to give, or over giving?\\nContributor1668: What's considered excessive may be seen as rigorous or intensive coaching, therefore undoubtedly necessary by others. Hence would appeal for the need to at least step back a little to assess\\nContributor626: Two major gateways? A system checks...The PSLE and A levels exams, both are critical metrics of the spectrum of the Future of all students. The other exams include N and O level exams.Which exams are the extreme rigor of all?Answer: ?\\nContributor420: By the year 2027, no more N level Exams, according to plansSec 4s will take different  Exams by 2027\\nContributor626: *The Role of Technology?*In today's digital age, technology plays a significant role in shaping our experiences and interactions. While technology offers numerous benefits, it also presents challenges that can contribute to the complexities of human existence.\\\"Use your handphone wisely and not let it own you!\\\" - anonymityTo embrace simplicity, we must adopt a mindful approach to technology use. This involves setting boundaries and being intentional about how we engage with digital devices. For instance, establishing tech-free zones or times in the household can help foster deeper connections and reduce distractions.\\nContributor450: Only 5 out of 21 tuition centres asked dared to say they advertise ethically and the rest keeps quiet. Says something, doesnt it?\\nContributor420: Only 21? There should be over 200 tuition centres and private home tutors in Singapore - north, south, east, west!\\nContributor2095: Isn't tuition addressing a systemic issue in the education system. Like how not all the syallbus is able to be covered and there's that thinking that tuition will pick up the slack.\\nContributor626: *Digital Well-Being*Promoting digital well-being is crucial for maintaining a healthy relationship with technology. This includes educating ourselves and our children about the impact of excessive screen time on mental and physical health. Encouraging activities that promote offline engagement, such as outdoor play, reading, and creative hobbies, can help strike a balance.*The Importance of Emotional Intelligence?*Emotional intelligence (EQ) plays a vital role in navigating the complexities of life. It involves the ability to recognise, understand, and manage our own emotions, as well as the emotions of others. High EQ contributes to better interpersonal relationships, effective communication, and overall well-being.*Developing Emotional Intelligence*To cultivate emotional intelligence, we can focus on the following strategies:1. Self-Awareness: Reflect on our emotions and identify their triggers. Journaling and mindfulness practices can enhance self-awareness.2. Empathy: Practice empathy by actively listening to others and validating their feelings. This fosters a deeper connection and understanding.3. Emotional Regulation: Develop techniques for managing emotions, such as deep breathing, meditation, and positive self-talk.4. Social Skills: Improve social interactions by honing communication skills, resolving conflicts constructively, and building rapport.\\nContributor830: Knowing that these AI chios are rsstricted items and cannot export to countries on USA Sanctioned List, I wonder do Singapore Govt have a duty of care to ensure that once arrived in Singapore as \\\"final destination\\\", they stay in Singapore and forbidden to be re-exported without permission from Govt?\\nContributor626: Good points by Lai....thank you!How to check and ensure?\\nContributor1920: Strictly speaking, even while as a member state of the UN and a trading partner of US, we are not legally obliged to ensure that exporters are not circumventing sanctions.HOWEVER, the US and UN member states have the right to sanction us and prevent or reduce trade with SG, which we cannot in no uncertain terms allow to happen.It is in Singapore\\u2019s best interest to appear as if we are doing our due diligence to ensure sanctions are abided.\\n\\n\\nContributor626: How to ship tiny things safely without damaging?\\nContributor830: i caught a glimpse of it.It is repugnant as if Ukraine stepped into a well rehearsed trap and got bambozzled by Don Corelone and Sonny with an offer that he got refused.Guess Ukraine found a dead horse on their bed now.\\nContributor626: If the world is like a theatrical, perhaps it was a stage showcasing \\\"the Carrots and the Sticks\\\"?*The Power of Gratitude over Gratification?*Gratitude is a powerful practice that can transform our perspective on life. By focusing on the positive aspects of our experiences, we can cultivate a sense of contentment and appreciation.*Practicing Gratitude?*Incorporate gratitude into daily routines through simple practices:1. Gratitude Journaling: Write down three things you are grateful for each day. This helps shift focus from what is lacking to what is abundant.2. Gratitude Letters: Write letters to express appreciation to individuals who have positively impacted your life. This strengthens relationships and fosters a sense of connection.3. Mindful Reflection: Take a few moments each day to reflect on the positive experiences and lessons learned. This promotes a positive mindset and resilience.*The Pursuit of Authenticity over Excellence?*Living authentically means being true to oneself and aligning actions with core values and beliefs. It involves embracing vulnerability, taking risks, and being open to growth and change.\\nContributor420: Topic is :Excessive tuition needs to be regulated. Thks.Strongly agree-  kee chui!\\nContributor830: I think Trump 2.0 has learned nothing from 1939 Munich Appeasement where Hitler claimed he is only recovering historic German land.Neither did Trump 2.0 learned anything from Balfour Declaration which led to 1948 War of Independence which continues right into 2025 and beyond.Suffice to say that tge dismemberment of Ukraine between Trump 2.0 and Putin is akin to 1939 Dismemberment of Poland between Stalin and Hitler which led to WW2.Unfortunately, like post-WW2 where Stalin grabbed the entire East Europe with Roosevelt and Churchill agreed with Stalin at Yalta Conference, I forsee that with the non-action of Trump 2.0 and couldn't bother about Europe, Putin willnot stop at Ukraine but will continue to menace Baltic states and East Europe to rebuild USSR 2.0 as the natural rights of Imperial Russia Tsar.Singapore?ASEAN will be just tributary states of China with USA, Russia and Xhiba carving up their Sphere of Influence like Yalta Conference 2.0.ASEAN, like Europe, is spineless without a unified leader to standup to China, Russia and China with one unite voice.When push comes to a shove, ASEAN countries will.turn nationalistic with self-interest comes first.And Devil takes the hindermost.Bluntly, Singapore have no strategic interest to USA and can be scarifice like Taiwan, S Korea, Japan and Philippines.Trump 2.0 iscan isolationists and commented USA have two beautiful oceans against any invading armies.\\nContributor626: *Embracing Authenticity*To live authentically, consider the following steps:1. Self-Discovery:Engage in self-reflection to identify core values, passions, and strengths. This provides clarity on what truly matters.2. Alignment: Ensure that actions and decisions align with core values. This fosters a sense of integrity and fulfillment.3. Courage: Embrace vulnerability and take risks that lead to personal growth. This involves stepping out of comfort zones and facing fears.How to regulate, legislate, and enforce? Thank you KC!\\nContributor830: Yes.Trump 2.0 loves limelight and always must be centre of attention.He craves the Nobel Peace Prize and hence I suspected why he blown his top at the White House seeing his Nobel Peace Prize gone up in smoke.Plus, he is proud of himself as a deal maker and so deluded that he got Ukraine over the barrel and will sign any mineral deals.\\nContributor420: Ask Min Chan Chun Sing, MOE\\nContributor830: Urgh ... why, when it is an honest mistake?Nanny Syndrome.First step.Follow China and abolish tuition centres.\\nContributor1920: Honest mistake or not, damage was done, and there should be consequences, just as there would be consequences for leaking customer\\u2019s information in any company, intentional or not.In fact, the lack of intention is way more frightening, since it indicates a lack of internal control, significantly more concerning than a malicious party.\\n\\n\\nContributor830: In this Age of Social Media, clickbaits and memes, there is no more authenticity expect how one appearance is in social media.\\nContributor626: What do these mean to our future youth? Thank you.\\nContributor830: as long as said party exercise due skill and care, competency and are experience enough to carry outbtgeir task diligently, there is no gross negligence and should they face consequences?\\nContributor1920: Yes, a mistake is a mistake is a mistake, and a mistake on such a national scale is even worse. [/INST]\",\n          \"<s>[INST]Determine whether Contributor240 holds the same view as this statement: 'Contributors expressed general concern towards \\\"Tackling Cost Pressures\\\" as it may not serve well as a long-term solution.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 240 and other contributors: \\n Contributor1407: \\ud83d\\udcac **What are your views on Budget 2025?**Overall, i think an issue that has not been addressed is the direction or assurance that the government is working to mitigate some of these rising costs. I am not a fan of cash/voucher handouts as it does not tackle the issue of the cost itself. Misleading to say tackling, maybe more like subsidising. All these are great to curb today's problem but does not solve the main issue of the never ending rising costs. I hope the government is working hard to look into this behind this.\\nContributor1695: A bit confusing...so will there be any actual cash handouts or just vouchers only? Also, there seems to be nothing for those 20yo and above to assist them in school/uni fees...\\nContributor1407: what is confusing? i mentioned that i dont like cash or voucher handouts as it doesnt solve the problem.\\nContributor240: The cash handout is for those with lower income..\\n\\n\\nContributor1695: Oic...thanksThat's a \\\"You\\\" problem\\nContributor1407: ok..?\\nContributor727: Good job by our government.\\nContributor240: The costs will keep rising, around the world also the same. That is reality.So we are nothing special. The only real way to cushion that is to make sure incomes raise at the same time.And we really need to stop to saying stuff like 'good job by our government'. We need to take care of our pple better. So much more can be done.\\n\\n\\nContributor311: I find the means test for eligibility in Home Caregiving Grant ought to be expanded that include other forms of criteria. Criteria can include severe long-term medical conditions like cancer, dementia, parkinson, etc. This in view the population is aging and caregiving cases will inevitably increase. More complicated family cases may arise over who will be the main caregiver and caregiving costs only steadily increase. And, not every family member will be willing volunteer be the stay-at-home caregiver or be financially able hire a helper look after the severely sick person. The MediHub app indicates Caregiver nomination by parents. I find it can be expanded to direct the grant directly to the Caregiver or appointed LPA donee.I also find the SG Vouchers for aged 60 and above will not reach those 80 and above especially since not all pioneers are highly educated and face difficulties handle technological changes. Imagine much older elderly with their sight and hearing problems, failing physical health, walking issues, how to always go downstairs use these vouchers frequently? It can be quite vexing. It's definitely no problem for the healthy pioneers. I cannot even imagine the Cultural Pass be used by them as well. It would be more of a hassle rather than a long-term impetus for the very much older elderly go out frequently. Perhaps the vouchers for 60 and above could be expanded include elderly assist medical items and elderly friendly products instead. It's more practical and helpful for their physical needs.\\nContributor1167: What about individual income tax?? Inflation, cost of living rising and taxes are always there.How about increasing the tax slabs & reducing the tax rates ?\\nContributor1584: Exactly. The government expects people to up-skill and be better through careers future,etc. The people in turn expect the same.\\nContributor311: Please also include more product varieties beyond fan, washing machine, wash taps, shower fittings and aircon for the fresh batch of climate vouchers.I would recommend NEA include energy efficient items like eco chargers, smart plugs, smart appliances, etc. Solar items are energy efficient as well. \\u26a1Not every household needs replacement of large items like refrigerator, air con and washing machine. NEA ought expand it's list of energy efficient items.\\nContributor1167: While corporate gets 50% cut upto 2000 and individual only 200? When individual have to fork out extra for their1. Increase in utilities2. Grocery increase3. Transport increase4. Tax increase too due to pay hike but not considering the inflation in picture5. GST hike 6. Food court & drinks hike\\nContributor311: The ActiveSG Credit criteria can be expanded include moderate impact exercises like gardening courses, hiking and cycling. Users of the credit could purchase exercise related equipment and gear. After all new cycling networks, walking trails and boardwalk are completed and more is coming. For the physically challenged, the credit be used buy a walker and mobility assist exercise equipment. Horticulture and urban farming courses can be an area Sport Singapore may look into tie in with food sustainability and security. The ActiveSG can be the starting platform for gardening hobbyists and encourage seniors be slightly more active. WSQ courses for horticultural and urban farming are for the serious takers or horticulture work-related persons. Volunteer farmhand programmes can be rolled out through ActiveSG.\\nContributor240: The ActiveSG credit can also be expanded to allow for gym memberships..\\n\\n\\nContributor311: Oh yes, include the zoo and bird park. It demands physical labour \\\"exercise\\\".\\nContributor527: Hmm..Talking about new cycling network.I am thinking that perhaps can look at park connector usage. Coz now Singapore is very connected with park connector. The intention is good as want to encourage for people to cycle to work, cycle on PCN and etcBut then with now everywhere is park connector.. is there areas of park connector that will be un-uitalise and what about the future park connector will these also be un-uitalise? If yes then perhaps can cut down spending of building new park connector ( not say totally no build, but reduce the park connector coverage or sort of).So this will then save a bit of money to put in other uses that can benefit sinagpreans\\nContributor311: Indeed. New pathworks are up and coming.. I looked through ActiveSG courses. Most of them are indoors and use the CC facilities. It ought venture outdoors more.Camping and outdoor survival courses demand much physical activity too although it's not counted as exercises.Actually I hope the park connectors instead of the usual native plants and shrubs will be designed with horticultural spaces and even fruit trees inserted in that cater to local food sustainability.Water catchment designs in the park connectors will be helpful since flash flood is getting too common here.\\nContributor527: I am thinking, maybe instead of everywhere park connector, we could have like park connector as access point to shopping malls, offices, government buildings, beach and etcSo it would be like park connector as major cycling/jogging, walking path to major buildings, attractions and beaches..In this way, park connector will be more ultalise and will not be wasting money building park connector everywhere that very few people use.UOB announces $3 billion package of special dividends and share buybacks, Q4 profit up 9%https://www.straitstimes.com/business/banking/uob-q4-profit-up-9-announces-3-billion-package-to-return-surplus-capital-to-shareholdersRemember think 2 weeks back I copy and paste the deepseek answer of share buyback ?Then I just read this article. Nothing wrong with uob on share buyback, but then this article reminds me of my 2 weeks back posting share buyback here in reach telegram.\\nContributor311: I think overseas have such concepts where malls become the stop over. So far in Singapore only MRT underground link ways more connected to malls.Actually I'm more concerned about national security and defence. In the sense of whether air raid/ bomb shelters will be built in the park connectors since other parts of the world, especially Europe is ramping up in architectural defense.\\nContributor527: I am thinking it's time for government to look into policies to prevent companies to use share buyback as a coverup for the unprofitable businesses or what.Or use share buyback to inflate stock market. These are nono I feel.\\nContributor311: Like New York, where underground passes linked to malls turned the malls into turmoil as crimes soared. May be feasible in Singapore for now but you really not know in turbulent times whether it's a plus or degenerate into a crime hub.\\nContributor75: How about trump tariff trade affect costGovt can only analyse outlook economy and budget\\nContributor240: Our military doctrine quite different from Europe. [/INST]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format Test Data\n",
        "from tqdm import tqdm\n",
        "all_base_predictions = []\n",
        "for train_prompt in tqdm(list(train_data.prompt.values)):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(train_prompt.replace(\"(1 for agree, 0 for not agree)\", \"Strictly only output 1 for agree, 0 for not agree\"), return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate text\n",
        "    output = merged_model.generate(inputs['input_ids'], pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0])\n",
        "    generated_text_cleaned = generated_text.split(\"[/INST]\")[-1]\n",
        "    if \"1\" in generated_text_cleaned:\n",
        "        prediction = 1\n",
        "    elif \"0\" in generated_text_cleaned:\n",
        "        prediction = 0\n",
        "    else:\n",
        "        prediction = -1\n",
        "    all_base_predictions.append(prediction)\n",
        "train_data[\"pred\"] = all_base_predictions"
      ],
      "metadata": {
        "id": "B8iEOVCYPtMc"
      },
      "id": "B8iEOVCYPtMc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_to_evaluate = train_data[train_data[\"pred\"]!=-1]\n",
        "print(len(train_data), len(pred_to_evaluate))\n",
        "compute_metrics(pred_to_evaluate[\"label\"], pred_to_evaluate[\"pred\"])"
      ],
      "metadata": {
        "id": "S42W66Y_PwOF"
      },
      "id": "S42W66Y_PwOF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format Test Data\n",
        "\n",
        "all_base_predictions = []\n",
        "for test_prompt in tqdm(list(test_data.prompt.values)):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate text\n",
        "    output = base_model.generate(inputs['input_ids'])\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0])\n",
        "    generated_text_cleaned = generated_text.split(\"[/INST]\")[-1]\n",
        "    if \"1\" in generated_text_cleaned:\n",
        "        prediction = 1\n",
        "    elif \"0\" in generated_text_cleaned:\n",
        "        prediction = 0\n",
        "    else:\n",
        "        prediction = -1\n",
        "    all_base_predictions.append(prediction)\n",
        "test_data[\"base_pred\"] = all_base_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ftDHr52R_8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744698894443,
          "user_tz": -480,
          "elapsed": 1338757,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "69ff4f64-98e9-457a-ef0e-aae08bfd0ec0"
      },
      "id": "81ftDHr52R_8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1349/1349 [22:18<00:00,  1.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_to_evaluate = test_data[test_data[\"base_pred\"]!=-1]\n",
        "\n",
        "compute_metrics(pred_to_evaluate[\"label\"], pred_to_evaluate[\"base_pred\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y7fTtED2YAc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744698894443,
          "user_tz": -480,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c674a9e0-e32f-4ead-859b-f9e40dab7699"
      },
      "id": "2Y7fTtED2YAc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5373271889400921,\n",
              " 'f1': 0.5611888111888111,\n",
              " 'precision': 0.5177419354838709,\n",
              " 'recall': 0.6125954198473282,\n",
              " 'f1_weighted': 0.5350945225308552,\n",
              " 'recall_weighted': 0.5373271889400921,\n",
              " 'precision_weighted': 0.5413705961052475,\n",
              " 'f1_marco': 0.535955029376082,\n",
              " 'precision_marco': 0.5405913978494623,\n",
              " 'recall_marco': 0.539809296376427}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format Test Data\n",
        "from tqdm import tqdm\n",
        "all_base_predictions = []\n",
        "for train_prompt in tqdm(list(train_data.prompt.values)):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(train_prompt.replace(\"(1 for agree, 0 for not agree)\", \"Strictly only output 1 for agree, 0 for not agree\"), return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate text\n",
        "    output = base_model.generate(inputs['input_ids'], pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0])\n",
        "    generated_text_cleaned = generated_text.split(\"[/INST]\")[-1]\n",
        "    if \"1\" in generated_text_cleaned:\n",
        "        prediction = 1\n",
        "    elif \"0\" in generated_text_cleaned:\n",
        "        prediction = 0\n",
        "    else:\n",
        "        prediction = -1\n",
        "    all_base_predictions.append(prediction)\n",
        "train_data[\"base_pred\"] = all_base_predictions"
      ],
      "metadata": {
        "id": "9AG0sZUwPjo9"
      },
      "id": "9AG0sZUwPjo9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred_to_evaluate = train_data[train_data[\"base_pred\"]!=-1]\n",
        "print(len(train_data), len(pred_to_evaluate))\n",
        "compute_metrics(pred_to_evaluate[\"label\"], pred_to_evaluate[\"base_pred\"])"
      ],
      "metadata": {
        "id": "FsYFiFPAPluc"
      },
      "id": "FsYFiFPAPluc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "reach_classification_llama.ipynb",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd6c0823892941369d83567866478fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2d6a71c3617413f92afa753542247d8",
              "IPY_MODEL_cdecdec8a1df481e92e738ba4fbd02ee",
              "IPY_MODEL_a8e1cb161ba94b458a3876f84d1a6e70"
            ],
            "layout": "IPY_MODEL_b0132493ca1446769473d8c303a11db6"
          }
        },
        "f2d6a71c3617413f92afa753542247d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_032496a0293c4d5f83af68b672d81897",
            "placeholder": "​",
            "style": "IPY_MODEL_ced779fba09d4eeb8092bf6cae49b99d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cdecdec8a1df481e92e738ba4fbd02ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a31c529dff346409a96b5d37aefcf58",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6d23df5d711405b859c8edfaf88255a",
            "value": 3
          }
        },
        "a8e1cb161ba94b458a3876f84d1a6e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d569b0aae9a04a71b59979ffb24f28ca",
            "placeholder": "​",
            "style": "IPY_MODEL_a845d5d413eb40dfa1db1a97e8c96f62",
            "value": " 3/3 [00:04&lt;00:00,  1.36s/it]"
          }
        },
        "b0132493ca1446769473d8c303a11db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "032496a0293c4d5f83af68b672d81897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced779fba09d4eeb8092bf6cae49b99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a31c529dff346409a96b5d37aefcf58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d23df5d711405b859c8edfaf88255a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d569b0aae9a04a71b59979ffb24f28ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a845d5d413eb40dfa1db1a97e8c96f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97edfae13e4e4ab6a59d93da1117a132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_700d4e33d31642339289c0191c249f89"
          }
        },
        "4af4af1188b0485caf2429f0249915bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90b347f2cec14298941e422da566c10d",
            "placeholder": "​",
            "style": "IPY_MODEL_1db8a3ce335c487bb327d6e30446b458",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "46ee28c3417c47f89eb0d81717721283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c18b18b38f20441798d4266a65c8ae31",
            "placeholder": "​",
            "style": "IPY_MODEL_fea3973ab9594290a4a7591381c52d31",
            "value": ""
          }
        },
        "5effacae387d4b0f8e287253abc4c268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_c4687bc61fc74eaebe532899be0dbb21",
            "style": "IPY_MODEL_27e5951be00c4e6cbf19843a2b668129",
            "value": true
          }
        },
        "de234ac3773648228345b53d38f3a482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_aca943421d5a478291243732f5bbf02d",
            "style": "IPY_MODEL_b3aec4709c964ee6b82b86b811560c31",
            "tooltip": ""
          }
        },
        "04759e0465a74e6186d5479b5f8e0d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_422284ad8bc04344965af0ed7cc0ac99",
            "placeholder": "​",
            "style": "IPY_MODEL_85faeaa0175f4dea8dd0771e778bdfe9",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "700d4e33d31642339289c0191c249f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "90b347f2cec14298941e422da566c10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db8a3ce335c487bb327d6e30446b458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c18b18b38f20441798d4266a65c8ae31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea3973ab9594290a4a7591381c52d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4687bc61fc74eaebe532899be0dbb21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27e5951be00c4e6cbf19843a2b668129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aca943421d5a478291243732f5bbf02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3aec4709c964ee6b82b86b811560c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "422284ad8bc04344965af0ed7cc0ac99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85faeaa0175f4dea8dd0771e778bdfe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a50e3e1b560d443eafe254ddcae68ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d52165a12e4452bb370e156e4068561",
            "placeholder": "​",
            "style": "IPY_MODEL_20e92f98648148bab111f934672d5083",
            "value": "Connecting..."
          }
        },
        "1d52165a12e4452bb370e156e4068561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e92f98648148bab111f934672d5083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}