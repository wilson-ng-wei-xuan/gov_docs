
from openai import OpenAI, AsyncOpenAI
from agno.tools import Toolkit
from agno.utils.log import log_error
from dotenv import load_dotenv, find_dotenv
import os
import json
import yaml

load_dotenv(find_dotenv())


def load_config():
    """Load configuration from a YAML file.""" 
    config_path = "config/perplexity_config.yaml"   
    try:
        # Get the directory where this script is located
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # Go up to the root directory (assuming this script is in a subdirectory)
        root_dir = os.path.dirname(script_dir)
        # Construct the full path to the config file
        full_config_path = os.path.join(root_dir, config_path)
        
        with open(full_config_path, 'r') as file:
            return yaml.safe_load(file)
    except FileNotFoundError:
        log_error(f"Config file not found: {full_config_path}")
        return {}
    except yaml.YAMLError as e:
        log_error(f"Error parsing YAML config: {e}")
        return {}




def format_messages(query: str) -> list:
    return [
        {
            "role": "system",
            "content": (
                "You are an artificial intelligence assistant and you need to "
                "engage in a helpful, detailed conversation with a user."
                "Give a detailed and comprehensive answer to the user's query. "
                "If you do not know the answer, say 'I don't know'. "
            ),
        },
        {   
            "role": "user",
            "content": (
               query
            ),
        },
    ]

class PerplexitySearch(Toolkit):
    def __init__(self, **kwargs):
        self.results = {}
        self.config = load_config()
        self.api_key = os.getenv("PERPLEXITY_API_KEY")
        self.async_client = AsyncOpenAI(api_key=self.api_key, base_url=os.getenv("PERPLEXITY_API_BASE"))
        self.client = OpenAI(api_key=self.api_key, base_url=os.getenv("PERPLEXITY_API_BASE"))
        super().__init__(name="perplexity_search_tool", tools=[self.search], **kwargs)


    async def search_async(self, search_query: str) -> str:
        """
        Performs an asynchronous search using Perplexity AI.
        This method sends a search query to the Perplexity AI API and returns the generated
        answer along with storing search results internally.
        Returns:
            str: The AI-generated answer to the search query. Returns empty string if no content
                 is available or if an error occurs during processing.
        Side Effects:
            - Updates self.results with both the answer and search results from the API response
            - Logs errors if response processing fails
        Raises:
            Exception: May raise exceptions from the underlying async client during API calls.
                      Response processing errors are caught and logged but not re-raised.
        """

        results = {}

        # chat completion without streaming
        response = await self.async_client.chat.completions.create(
            model=self.config.get('model', "sonar-pro"),
            messages=format_messages(search_query),
            max_tokens=self.config.get('max_tokens', 500),  # Use config or default
            temperature=self.config.get('temperature', 0.2),  # Use config or default
            top_p=self.config.get('top_p', 0.9)  # Use config or default
        )

        try:
            results["answer"] = response.choices[0].message.content if hasattr(response.choices[0].message, 'content') else []
            results["search_results"] = response.search_results if hasattr(response, 'search_results') else []
        except Exception as e:
            log_error(f"Error processing response: {e}")

        self.results = results
        return json.dumps(results, indent=2)

    def search(self, search_query: str) -> str:
        """Performs a web search using the Perplexity API synchronously.
        This method sends a search query to the Perplexity API and returns the generated
        answer along with storing search results internally.
        Args:
            search_query (str): The search query string to be processed by the API.
        Returns:
            str: The answer content from the API response. Returns the content of the
                 first choice message, or an empty string if no content is available.
        Side Effects:
            - Sets self.results with both the answer and search_results from the response
            - Logs error messages if response processing fails
        Note:
            Uses the model defined in self.config for chat completion without streaming.
        """
        results = {}

        # chat completion without streaming
        response = self.client.chat.completions.create(
            model=self.config.get('model', "sonar-pro"),
            messages=format_messages(search_query),
            max_tokens=self.config.get('max_tokens', 500),  # Use config or default
            temperature=self.config.get('temperature', 0.2),  # Use config or default
            top_p=self.config.get('top_p', 0.9)  # Use config or default
        )

        try:
            results["answer"] = response.choices[0].message.content if hasattr(response.choices[0].message, 'content') else []
            results["search_results"] = response.search_results if hasattr(response, 'search_results') else []
        except Exception as e:
            log_error(f"Error processing response: {e}")

        self.results = results
        return json.dumps(results, indent=2)


