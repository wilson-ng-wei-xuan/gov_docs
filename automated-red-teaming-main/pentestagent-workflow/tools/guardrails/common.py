import re
import os
from typing import Callable, Optional, List
from enum import Enum

# Globals and Types
MAX_TOOL_OUTPUT_BYTES = int(os.getenv("MAX_TOOL_OUTPUT_BYTES", 500000))
MAX_SQLI_DELAY = int(os.getenv("MAX_SQLI_DELAY", 90))
MAX_CHUNK_SIZE = int(os.getenv("MAX_CHUNK_SIZE", 4000))

SafetyResult = Optional[str]

##### Chunking functions

from typing import List, Callable
import re
from enum import Enum

def chunk_text_by_size(raw_output: str) -> List[str]:
    """
    Split text into contiguous word-based chunks without exceeding MAX_CHUNK_SIZE.

    Args:
        raw_output (str): The raw text to be chunked.

    Returns:
        List[str]: List of text chunks.
    """
    chunks = []
    output = raw_output.split()
    curr_chunk = ""

    for i in range(len(output)):
        curr_chunk += " " + output[i]
        if len(curr_chunk) > MAX_CHUNK_SIZE or i == len(output) - 1:
            chunks.append(curr_chunk.strip())
            curr_chunk = ""
    
    return chunks


def chunk_text_by_line(raw_output: str) -> List[str]:
    """
    Split text into chunks along line boundaries without exceeding MAX_CHUNK_SIZE.

    Args:
        raw_output (str): The raw text to be chunked.

    Returns:
        List[str]: List of line-based chunks.
    """
    chunks = []
    output = raw_output.splitlines()
    curr_chunk = ""

    for i in range(len(output)):
        curr_chunk += output[i] + "\n"
        if len(curr_chunk) > MAX_CHUNK_SIZE or i == len(output) - 1:
            chunks.append(curr_chunk.rstrip())
            curr_chunk = ""

    return chunks


def chunk_text_by_sentence(raw_output: str) -> List[str]:
    """
    Split text into chunks at sentence boundaries while preserving formatting.

    Handles edge cases such as:
      - Abbreviations (e.g., Dr., Mr.)
      - Decimals (e.g., 1.5)
      - URLs and file extensions
      - Multiple punctuation marks (e.g., ?!, ..)

    Args:
        raw_output (str): The raw text to be chunked.

    Returns:
        List[str]: List of sentence-based chunks.
    """
    chunks = []
    sentence_pattern = r'(?<![A-Z][a-z]\.)\s*(?<![A-Z]\.)\s*(?<=\.|\!|\?)\s+'
    sentences = re.split(sentence_pattern, raw_output)
    sentences = [s for s in sentences if s.strip()]

    curr_chunk = ""

    for sentence in sentences:
        if len(curr_chunk + sentence) > MAX_CHUNK_SIZE and curr_chunk:
            chunks.append(curr_chunk.rstrip())
            curr_chunk = sentence
        else:
            curr_chunk += sentence

    if curr_chunk.strip():
        chunks.append(curr_chunk.rstrip())

    return chunks


def chunk_html_with_overlap(raw_output: str) -> List[str]:
    """
    Split HTML text into overlapping chunks, attempting to preserve structure by breaking
    at closing tags where possible.

    Args:
        raw_output (str): The raw HTML text.

    Returns:
        List[str]: List of overlapping HTML chunks.
    """
    overlap = 500
    text = raw_output
    chunks = []
    start = 0

    while start < len(text):
        end = start + MAX_CHUNK_SIZE
        chunk = text[start:end]

        if end < len(text):
            tag_patterns = [r'</\w+>', r'</form>', r'</div>', r'</section>', r'</body>']
            best_break = -1

            for pattern in tag_patterns:
                matches = list(re.finditer(pattern, chunk[MAX_CHUNK_SIZE // 2:]))
                if matches:
                    last_match = matches[-1]
                    potential_break = MAX_CHUNK_SIZE // 2 + last_match.end()
                    if potential_break > best_break:
                        best_break = potential_break

            if best_break > 0:
                chunk = chunk[:best_break]
                end = start + best_break

        chunks.append(chunk)

        if end >= len(text):
            break
        start = end - overlap

    return chunks


##### Constants
class PAYLOAD_TYPE(Enum):
    """
    Enum representing different types of payloads and their associated chunking strategies.
    """

    TEXT = "text"
    WEB_PAGE = "web_page"
    SHELL_OUTPUT = "shell_output"

    def get_chunking_function(self) -> Callable:
        """
        Retrieve the appropriate chunking function based on the payload type.

        Returns:
            Callable: A function that splits raw text into chunks.
        """
        if self.value == "text":
            return chunk_text_by_sentence
        elif self.value == "web_page":
            return chunk_html_with_overlap
        elif self.value == "shell_output":
            return chunk_text_by_line

##### Chunking functions


def chunk_text_by_size(raw_output: str) -> List[str]:
    chunks = []
    output = raw_output.split()
    curr_chunk = ""

    for i in range(len(output)):
        curr_chunk += " " + output[i]
        if len(curr_chunk) > MAX_CHUNK_SIZE or i == len(output) - 1:
            chunks.append(curr_chunk)
            curr_chunk = []
    
    return chunks

def chunk_text_by_line(raw_output: str) -> List[str]:
    chunks = []
    output = raw_output.splitlines()
    curr_chunk = ""

    for i in range(len(output)):
        curr_chunk += output[i] + "\n"
        if len(curr_chunk) > MAX_CHUNK_SIZE or i == len(output) - 1:
            chunks.append(curr_chunk)
            curr_chunk = []
            
    return chunks

def chunk_text_by_sentence(raw_output: str) -> List[str]:
    """
    Advanced sentence chunking that handles more edge cases and preserves formatting.
    
    Args:
        raw_output: The raw text to be chunked
        max_chunk_size: Maximum size of each chunk in characters
    
    Returns:
        List of text chunks split at sentence boundaries
    """
    chunks = []
    
    # More sophisticated sentence splitting that handles:
    # - Abbreviations (Dr., Mr., etc.)
    # - Decimals (1.5, 2.3, etc.)
    # - URLs and file extensions
    # - Multiple punctuation (?!, .., etc.)
    sentence_pattern = r'(?<![A-Z][a-z]\.)\s*(?<![A-Z]\.)\s*(?<=\.|\!|\?)\s+'
    
    # Split while preserving the original spacing and newlines
    sentences = re.split(sentence_pattern, raw_output)
    sentences = [s for s in sentences if s.strip()]  # Remove empty strings
    
    curr_chunk = ""
    
    for i, sentence in enumerate(sentences):
        # For penetration testing output, preserve original formatting
        sentence_to_add = sentence
        
        # Check if adding this sentence would exceed the chunk size
        if len(curr_chunk + sentence_to_add) > MAX_CHUNK_SIZE and curr_chunk:
            # Save current chunk and start new one
            chunks.append(curr_chunk.rstrip())
            curr_chunk = sentence_to_add
        else:
            # Add sentence to current chunk
            curr_chunk += sentence_to_add
    
    # Add the last chunk if it's not empty
    if curr_chunk.strip():
        chunks.append(curr_chunk.rstrip())
    
    return chunks

def chunk_html_with_overlap(raw_output: str) -> List[str]:
        """Split text into overlapping chunks, trying to preserve HTML structure."""
        #TODO: Needs work
        overlap = 500
        text = raw_output
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + MAX_CHUNK_SIZE
            chunk = text[start:end]
            
            # If this isn't the last chunk, try to break at HTML boundaries
            if end < len(text):
                # Look for closing tags in the latter half of the chunk
                tag_patterns = [r'</\w+>', r'</form>', r'</div>', r'</section>', r'</body>']
                best_break = -1
                
                for pattern in tag_patterns:
                    matches = list(re.finditer(pattern, chunk[MAX_CHUNK_SIZE // 2:]))
                    if matches:
                        last_match = matches[-1]
                        potential_break = MAX_CHUNK_SIZE // 2 + last_match.end()
                        if potential_break > best_break:
                            best_break = potential_break
                
                if best_break > 0:
                    chunk = chunk[:best_break]
                    end = start + best_break
            
            chunks.append(chunk)
            
            # Move start position with overlap
            if end >= len(text):
                break
            start = end - overlap
            
        return chunks

##### Constants
class PAYLOAD_TYPE(Enum):
    TEXT = "text"
    WEB_PAGE = "web_page"
    SHELL_OUTPUT = "shell_output"

    def get_chunking_function(self) -> Callable:
        if self.value == "text":
            return chunk_text_by_sentence
        elif self.value == "web_page":
            return chunk_html_with_overlap
        elif self.value == "shell_output":
            return chunk_text_by_line


##### Decorator
def precheck_for(*tool_names):
    """
    Decorator for pre-check functions. Defines the set of tool functions for which this pre-check function should be applied
    Note that this is the set of base tool functions e.g. arun_web_requester is the base tool function for arun_web_requester_sqli
    """
    def decorator(fn):
        fn._applies_to = set(tool_names)
        return fn
    return decorator

# Common post-processing functions

async def redact_sensitive_info(tool_resp: str) -> str:
    """
    Args:
        tool_resp (str): Response obtained from tool (and possibly post-processing steps)

    Returns:
        str: Output result after sensitive information has been successfully redacted
    """
    # Defines the list of sensitive information that should be redacted from the output
    sensitive_patterns = [
        # # Passwords
        # r"(?i)password\s*[:=]\s*['\"]?[\w!@#$%^&*()_+-]+['\"]?",
        # # API keys
        # r"(?i)api[_-]?key\s*[:=]\s*['\"]?[\w-]+['\"]?",
        # # IP addresses
        # r"\b(?:\d{1,3}\.){3}\d{1,3}\b",
        # # Emails
        # r"\b[\w.-]+@[\w.-]+\.\w+\b",
        # # File paths
        # r"/[a-zA-Z0-9_\-/]+",
        # # SSH private keys (PEM format)
        # r"-----BEGIN PRIVATE KEY-----(.|\n)+?-----END PRIVATE KEY-----",
        # r"-----BEGIN OPENSSH PRIVATE KEY-----(.|\n)+?-----END OPENSSH PRIVATE KEY-----",
        # # GitHub personal access tokens (40-character hex)
        # r"\bghp_[A-Za-z0-9_]{36}\b",
        # # GitHub OAuth tokens (basic pattern)
        # r"\bgho_[A-Za-z0-9_]{36}\b",
        # # Generic hex tokens (32-40 chars)
        # r"\b[a-f0-9]{32,40}\b"
    ]

    for pattern in sensitive_patterns:
        tool_resp = re.sub(pattern, "[REDACTED]", tool_resp, flags = re.MULTILINE | re.IGNORECASE)

    return tool_resp

async def truncate_output(tool_resp: str) -> str:
    """
    Args:
        tool_resp (str): Response obtained from tool (and possibly post-processing steps)

    Returns:
        str: Truncates the output if necessary and prepends a note for agent to know that the message has been truncated
    """
    # TODO: Uncomment this when necessary
    # if len(tool_resp) > MAX_TOOL_OUTPUT_BYTES:
    #     tool_resp = f"Note: Tool result has been truncated from length {len(tool_resp)}...\n" + tool_resp[:MAX_TOOL_OUTPUT_BYTES]
    
    return tool_resp

# SQLI
sqli_unsafe_patterns = {
    "modification_patterns": [
        r"\bINSERT\b",           # INSERT
        r"\bDELETE\b",           # DELETE
        r"\bUPDATE\b",           # UPDATE
        r"\bDROP\b",             # DROP TABLE, DROP DATABASE
        r"\bTRUNCATE\b",         # TRUNCATE TABLE
        r"\bALTER\b",            # ALTER TABLE
        r"\bRENAME\s+TABLE\b",   # Rename table
        r"\bCREATE\s+TABLE\b",   # Creating new tables (could be destructive in some contexts)
        r"\bCREATE\s+DATABASE\b",# Creating new DB
        r"\bDROP\s+DATABASE\b",  # Dropping entire database
        r"\bRENAME\s+DATABASE\b",# Renaming database
        r"\bSET\s+GLOBAL\b",     # Dangerous server-wide changes
        r"\bLOCK\s+TABLES\b",    # Could block access to tables
        r"\bUNLOCK\s+TABLES\b",  # Unlocking if misused
    ],
    "file_patterns": [
        r"\bINTO\s+OUTFILE\b",  # Write to file
        r"\bLOAD_FILE\b",       # Read file
        r"\bSELECT\s+.*\bINTO\s+DUMPFILE\b",  # MySQL variant
        r"\bSELECT\s+.*\bINTO\s+DIR\b",      # Some DBs support INTO DIR
    ],
    "os_patterns": [
        r"\bxp_cmdshell\b",  # MSSQL command shell
        r"\bEXEC\s+xp_",     # MSSQL extended procedures
        r"\bsp_oacreate\b",  # COM object creation (OS commands)
        r"\bsp_makewebtask\b", # MSSQL: create a web task
        r"\bEXEC\s+shell\b",   # generic shell execution
        r"\bSYSTEM\b",         # MySQL SYSTEM()
    ],
    "db_os_patterns": [
        r"\bDBMS_PIPE\.",        # Oracle DB pipe
        r"\bDBMS_SCHEDULER\.",   # Oracle job scheduler
        r"\bUTL_FILE\.",          # Oracle file package
        r"\bXDB\.HTTP\_REQUEST\b" # Oracle XML DB HTTP request
    ],
    "sleep": [
        r"SLEEP\s*\(\s*(\d+)\s*\)"
    ],
    "waitfor": [
        r"WAITFOR\s+DELAY\s+'?(\d+):(\d+):(\d+)'?"
    ],
    "recursive": [
        r"\bWITH\s+RECURSIVE\b"
    ],
}

def sqli_mod_check(payload: str) -> SafetyResult:
    # Modification check
    modification_patterns = sqli_unsafe_patterns.get("modification_patterns", [])

    for pattern in modification_patterns:
        if re.search(pattern, payload, flags=re.I):
            return f"Unsafe: SQLi payload attempts file/schema modification `{pattern}`"
    
    return None

def sqli_interaction_check(payload: str) -> SafetyResult:
    # Patterns for file system interaction
    file_patterns = sqli_unsafe_patterns.get("file_patterns", [])

    # Patterns for OS / shell execution
    os_patterns = sqli_unsafe_patterns.get("os_patterns", [])

    # Patterns for SQL Server / Oracle OS interaction
    db_os_patterns = sqli_unsafe_patterns.get("db_os_patterns", [])

    # Combine all patterns
    all_patterns = file_patterns + os_patterns + db_os_patterns

    for pattern in all_patterns:
        if re.search(pattern, payload, flags=re.I):
            return f"Unsafe: SQLi payload attempts filesystem/OS interaction `{pattern}`"
        
    return None

def sqli_dos(payload: str) -> SafetyResult:
    for sleep_pattern in sqli_unsafe_patterns.get("sleep", []):
            sleep_match = re.search(sleep_pattern, payload, flags=re.I)
            if sleep_match:
                seconds = int(sleep_match.group(1))
                if seconds > MAX_SQLI_DELAY:
                    return f"Unsafe: SQLi payload attempts long sleep ({seconds}s) exceeding {MAX_SQLI_DELAY}s"

    # Check for MSSQL WAITFOR DELAY
    for waitfor_pattern in sqli_unsafe_patterns.get("waitfor", []):
        waitfor_match = re.search(waitfor_pattern, payload, flags=re.I)
        if waitfor_match:
            hours, minutes, seconds = map(int, waitfor_match.groups())
            total_seconds = hours * 3600 + minutes * 60 + seconds
            if total_seconds > MAX_SQLI_DELAY:
                return f"Unsafe: SQLi payload attempts long WAITFOR DELAY ({total_seconds}s) exceeding {MAX_SQLI_DELAY}s"

    # Recursive CTEs
    for recursive_pattern in sqli_unsafe_patterns.get("recursive", []):
        if re.search(recursive_pattern, payload, flags=re.I):
            return "Unsafe: SQLi payload contains recursive CTE which may cause DoS"
      
# XXE
xxe_unsafe_patterns = {
    "rce": [
        r"expect://",       # PHP wrapper â†’ command exec
        r"jar://",          # Java remote JAR loading
        r"netdoc://",       # Java RMI/LDAP remote objects
        r"dict://",         # Dict protocol (SSRF/RCE pivot)
        r"gopher://",       # Gopher often used for SSRF to RCE
    ],
    "cookies": [
        r"set-cookie",      # Attempts to overwrite cookies
        r"\bcookie\b",      # Stealing or injecting cookies
        r"authorization",   # Leaking Authorization headers
        r"proxy-auth",      # Proxy credential leaks
    ],
    "dos": [
        r"(?:<!ENTITY\s+.*?){10,}",                             # Keep Billion Laughs count check
        r"<!ENTITY\s+.*?\s+SYSTEM\s+['\"]data:",                # data: scheme expansion bomb
        r"<!ENTITY\s+\w+\s+\"[^\">]*&\w+;[^\">]*\">"            # Only match ENTITYs that contain internal & references inside their definition
    ]
}

def xxe_rce_check(payload: str) -> SafetyResult:
    for pattern in xxe_unsafe_patterns.get("rce", []):
        if re.search(pattern, payload, flags=re.I):
            return f"Unsafe: XXE payload may enable RCE `{pattern}`"
    return None

def xxe_cookie_check(payload: str) -> SafetyResult:
    for pattern in xxe_unsafe_patterns.get("cookies", []):
        if re.search(pattern, payload, flags=re.I):
            return f"Unsafe: XXE payload attempts cookie/session manipulation `{pattern}`"
    return None

def xxe_dos_check(payload: str) -> SafetyResult:
    for pattern in xxe_unsafe_patterns.get("dos", []):
        if re.search(pattern, payload, flags=re.I | re.S):
            return f"Unsafe: XXE payload looks like DoS attempt `{pattern}`"
    return None
