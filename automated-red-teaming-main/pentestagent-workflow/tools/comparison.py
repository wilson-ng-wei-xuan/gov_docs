from __future__ import annotations

import binascii
import codecs
import difflib
import re
import string
import threading
import time
import urllib.parse
from collections.abc import Iterable
from typing import Any, List, Optional, Tuple, Union
from agno.utils.log import logger

# ---- Constants ----
MAX_DIFFLIB_SEQUENCE_LENGTH = 10 * 1024 * 1024
LOWER_RATIO_BOUND = 0.02
UPPER_RATIO_BOUND = 0.98
DYNAMICITY_BOUNDARY_LENGTH = 20
REFLECTED_REPLACEMENT_REGEX = r"[^\n]{1,168}"
PAYLOAD_DELIMITER = "__PAYLOAD_DELIMITER__"
REFLECTED_VALUE_MARKER = "__REFLECTED_VALUE__"
REFLECTED_MAX_REGEX_PARTS = 10
REFLECTED_BORDER_REGEX = r"[^A-Za-z]+"
REFLECTED_REPLACEMENT_TIMEOUT = 3.0  # seconds
REFLECTIVE_MISS_THRESHOLD = 20
UNICODE_ENCODING = "utf8"
CUSTOM_INJECTION_MARK_CHAR = "*"
MIN_RATIO = 0.0
MAX_RATIO = 1.0
HTML_TITLE_REGEX = r"(?i)<title>(?P<result>[^<]+)</title>"
DEFAULT_PAGE_ENCODING = "iso-8859-1"
DIFF_TOLERANCE = 0.05
CONSTANT_RATIO = 0.9
SAFE_HEX_MARKER = "__SAFE_HEX__"

class REFLECTIVE_COUNTER:
    MISS = "MISS"
    HIT = "HIT"

# ---- KB (knowledge base) ----
class KB(dict):
    """
    Dict-like knowledge base with attribute access preserved.
    """

    def __init__(self) -> None:
        super().__init__()
        # default fields
        self.dynamicMarkings: List[Tuple[Optional[str], Optional[str]]] = []
        self.reflectiveMechanism: bool = True
        self.heuristicMode: bool = False
        self.reflectiveCounters = {REFLECTIVE_COUNTER.HIT: 0, REFLECTIVE_COUNTER.MISS: 0}
        self.testMode: bool = False
        self.startTime: float = time.time()
        self.page_template: str = ""
        self.page_encoding: str = DEFAULT_PAGE_ENCODING or "utf-8"
        self.last_comparison = {"headers": None, "page": None, "code": None, "ratio": None}
        self.nullConnection: bool = False
        self.heavilyDynamic: bool = False
        self.matchRatio: Optional[float] = None

    def __getattr__(self, name: str) -> Any:
        return self.get(name)

    def __setattr__(self, name: str, value: Any) -> None:
        # store anything not "private" in dict to preserve original behavior
        if name.startswith("_") or name in ("dynamicMarkings", "reflectiveMechanism", "heuristicMode", "reflectiveCounters",
                                           "testMode", "startTime", "page_template", "page_encoding", "last_comparison",
                                           "nullConnection", "heavilyDynamic", "matchRatio"):
            super().__setattr__(name, value)
        else:
            self[name] = value


kb = KB()


# ---- Utility helpers ----
def filter_none(values: Iterable) -> List:
    """Return list without falsy values (keeps same semantics as original)."""
    return [v for v in values if v] if isinstance(values, Iterable) and not isinstance(values, (str, bytes)) else []


def is_list_like(value: Any) -> bool:
    return isinstance(value, (list, tuple, set))


def get_unicode(value: Any, encoding: Optional[str] = None, none_to_null: bool = False) -> Any:
    """
    Convert bytes/other to str using heuristics.
    """
    if none_to_null and value is None:
        return "NULL"
    if isinstance(value, str):
        return value
    if isinstance(value, bytes):
        # candidates: explicit encoding, page encoding, default unicode encoding, fs encoding
        candidates = [c for c in [encoding, getattr(kb, "pageEncoding", None), UNICODE_ENCODING, None] if c]
        # try candidates
        for c in candidates:
            try:
                return value.decode(c)
            except (LookupError, UnicodeDecodeError):
                continue
        # fallback
        try:
            return value.decode(encoding or getattr(kb, "pageEncoding", None) or UNICODE_ENCODING, errors="reversible")
        except Exception:
            return value.decode(UNICODE_ENCODING, errors="replace")
    if is_list_like(value):
        return [get_unicode(v, encoding, none_to_null) for v in value]
    try:
        return str(value)
    except Exception:
        return repr(value)


def get_bytes(value: Any, encoding: Optional[str] = None, errors: str = "strict", unsafe: bool = True) -> bytes:
    """
    Convert string to bytes using encoding fallback. Keeps unsafe hex handling for compatibility.
    """
    if encoding is None:
        encoding = UNICODE_ENCODING

    if isinstance(value, bytes):
        return value
    if not isinstance(value, str):
        value = str(value)
    try:
        return value.encode(encoding, errors)
    except Exception:
        return value.encode(UNICODE_ENCODING, "replace")


def decode_hex(value: Union[str, bytes], binary: bool = True) -> Union[bytes, str]:
    s = value.decode() if isinstance(value, bytes) else value
    if s.lower().startswith("0x"):
        s = s[2:]
    try:
        out = codecs.decode(s, "hex")
    except Exception:
        out = binascii.unhexlify(s)
    return out if binary else get_unicode(out)


def get_text(value: Union[str, bytes], encoding: Optional[str] = None) -> str:
    return get_unicode(value, encoding)


def encode_string_escape(value: str) -> str:
    """Encode special whitespace characters to their repr-style escapes (e.g. tab -> \\t)."""
    if not value:
        return value
    charset = "\\%s" % string.whitespace.replace(" ", "")
    ret = value
    for ch in charset:
        ret = ret.replace(ch, repr(ch).strip("'"))
    return ret


# ---- URL decode ----
def urldecode(value: Union[str, bytes], encoding: Optional[str] = None,
              unsafe: str = "%%?&=;+" + CUSTOM_INJECTION_MARK_CHAR, convall: bool = False,
              spaceplus: bool = True) -> str:
    """
    URL-decode with optional partial decoding (convall=False keeps unsafe percent sequences).
    """
    if not value:
        return value if value is not None else ""
    s = get_unicode(value)
    if convall:
        return get_unicode(urllib.parse.unquote_plus(s) if spaceplus else urllib.parse.unquote(s), encoding)
    # partial decode: only replace safe hex sequences
    if spaceplus:
        s = s.replace("+", " ")
    charset = set(string.printable) - set(unsafe)
    def _replace(m):
        ch = decode_hex(m.group(1), binary=False)
        return ch if ch in charset else m.group(0)
    out = re.sub(r"%([0-9a-fA-F]{2})", _replace, s)
    return get_unicode(out, encoding)


# ---- String filtering ----
def filter_string_value(value: str, char_regex: str, replacement: str = "") -> str:
    """
    Return a string consisting only of chars that match char_regex.
    char_regex is expected like '[0-9a-f]'. This function keeps original inverse logic.
    """
    if not value:
        return value
    # convert to inverse character class for substitution if needed
    if "[^" not in char_regex:
        char_regex = char_regex.replace("[", "[^")
    else:
        char_regex = char_regex.replace("[^", "[")
    return re.sub(char_regex, replacement, value)


def list_to_str_value(value: Any) -> str:
    if isinstance(value, (set, tuple)) or hasattr(value, "__iter__") and not isinstance(value, (str, bytes)):
        return ", ".join(map(str, list(value)))
    return str(value)


# ---- Dynamic content removal ----
def removeDynamicContent(page: Optional[str]) -> Optional[str]:
    """Remove regions indicated by kb.dynamicMarkings from page text."""
    if not page:
        return page
    for prefix, suffix in getattr(kb, "dynamicMarkings", []):
        if prefix is None and suffix is None:
            continue
        if prefix is None:
            # remove anything up to suffix
            page = re.sub(r"(?s)^.+%s" % re.escape(suffix), suffix, page)
        elif suffix is None:
            page = re.sub(r"(?s)%s.+$" % re.escape(prefix), prefix, page)
        else:
            page = re.sub(r"(?s)%s.+?%s" % (re.escape(prefix), re.escape(suffix)), "%s%s" % (prefix, suffix), page)
    return page


def trim_alphanum(value: str) -> str:
    """Strip leading/trailing alphanumeric characters (used to avoid cutting words)."""
    if not value:
        return value
    start = 0
    end = len(value)
    while end > 0 and value[end - 1].isalnum():
        end -= 1
    while start < end and value[start].isalnum():
        start += 1
    return value[start:end]


def findDynamicContent(first_page: str, second_page: str) -> bool:
    """
    Identify dynamic regions between two pages and populate kb.dynamicMarkings.
    Returns True if any dynamic markings were set.
    """
    if not first_page or not second_page:
        return False

    logger.info("Searching for dynamic content...")
    # Avoid huge difflib sequences
    if len(first_page) > MAX_DIFFLIB_SEQUENCE_LENGTH or len(second_page) > MAX_DIFFLIB_SEQUENCE_LENGTH:
        logger.warning("Pages too long for detailed dynamic detection - skipping.")
        return False

    seq = difflib.SequenceMatcher(None, first_page, second_page)
    blocks = [b for b in seq.get_matching_blocks() if b.size > 2 * DYNAMICITY_BOUNDARY_LENGTH]

    kb.dynamicMarkings = []
    if not blocks:
        return False

    # add sentinel None to ease neighbor handling
    blocks = [None] + blocks + [None]

    for i in range(len(blocks) - 1):
        left = blocks[i]
        right = blocks[i + 1]
        if left is None and right and right.a == 0:
            continue
        if right is None and left and (left.a + left.size >= len(first_page)):
            continue

        prefix = None
        suffix = None
        if left:
            prefix = first_page[left.a:left.a + left.size][-DYNAMICITY_BOUNDARY_LENGTH:]
        if right:
            suffix = first_page[right.a:right.a + right.size][:DYNAMICITY_BOUNDARY_LENGTH]

        # attempt to refine prefix/suffix by ensuring they don't cut words
        for candidate_page in (first_page, second_page):
            if prefix and suffix:
                pattern = r"(?s)%s(.+?)%s" % (re.escape(prefix), re.escape(suffix))
                m = re.search(pattern, candidate_page)
                if m:
                    infix = m.group(1)
                    if infix and infix[0].isalnum():
                        prefix = trim_alphanum(prefix)
                    if infix and infix[-1].isalnum():
                        suffix = trim_alphanum(suffix)
                    break
        kb.dynamicMarkings.append((prefix or None, suffix or None))

    if kb.dynamicMarkings:
        logger.info("Dynamic content marked for removal (%d region%s)" %
                    (len(kb.dynamicMarkings), "s" if len(kb.dynamicMarkings) != 1 else ""))
        return True
    return False


# ---- Reflection removal (simplified & safer) ----
def _build_reflection_regex(payload: str) -> str:
    """
    Build a relaxed regex that matches lightly encoded variants of payload.
    It substitutes long percent-encoded runs and whitespace runs with a generic pattern.
    """
    if not payload:
        return ""
    # normalize whitespace
    p = re.sub(r"\s+", r"\\s*", re.escape(payload))
    # replace groups of percent-encodings like %20%2B with wildcard
    p = re.sub(r"(?:%[0-9a-fA-F]{2})+", REFLECTED_REPLACEMENT_REGEX, p)
    return p


def removeReflectiveValues(content: str, payload: str, suppress_warning: bool = False) -> str:
    """
    Try to neutralize reflected payloads in content. Replaces matches with REFLECTED_VALUE_MARKER.
    Uses a thread + timeout to avoid pathological regex performance.
    """
    if not (content and payload and isinstance(content, str)):
        return content

    if not kb.reflectiveMechanism or kb.heuristicMode:
        return content

    payload_decoded = get_unicode(urldecode(payload.replace(PAYLOAD_DELIMITER, ""), convall=True))
    # Fast direct replacement
    if payload_decoded in content:
        new = content.replace(payload_decoded, REFLECTED_VALUE_MARKER)
        kb.reflectiveCounters[REFLECTIVE_COUNTER.HIT] += 1
        if not suppress_warning:
            logger.info("Reflective value(s) found and filtering out (direct replace)")
        return new

    regex = _build_reflection_regex(payload_decoded)
    if not regex:
        return content

    # Quick optimization: ensure some parts present in content
    parts = [p for p in re.split(REFLECTED_REPLACEMENT_REGEX, regex) if p]
    if parts and not all(part.lower() in content.lower() for part in parts[:min(len(parts), REFLECTED_MAX_REGEX_PARTS)]):
        # nothing to replace
        kb.reflectiveCounters[REFLECTIVE_COUNTER.MISS] += 1
        if kb.reflectiveCounters[REFLECTIVE_COUNTER.MISS] > REFLECTIVE_MISS_THRESHOLD:
            kb.reflectiveMechanism = False
            if not suppress_warning:
                logger.debug("Turning off reflection removal mechanism (too many misses)")
        return content

    out = [content]

    def _sub_worker(pattern: str) -> None:
        try:
            out[0] = re.sub(r"(?i)%s" % pattern, REFLECTED_VALUE_MARKER, out[0])
        except Exception:
            # any regex failure -> keep original
            out[0] = content

    worker = threading.Thread(target=_sub_worker, args=(regex,))
    worker.daemon = True
    worker.start()
    worker.join(REFLECTED_REPLACEMENT_TIMEOUT)

    if worker.is_alive():
        kb.reflectiveMechanism = False
        if not suppress_warning:
            logger.debug("Turning off reflection removal mechanism (timeout)")
        return content

    if out[0] != content:
        kb.reflectiveCounters[REFLECTIVE_COUNTER.HIT] += 1
        if not suppress_warning:
            logger.info("Reflective value(s) found and filtering out")
        # Warn about frames containing the marker
        if re.search(r"(?i)FRAME[^>]+src=[^>]*%s" % re.escape(REFLECTED_VALUE_MARKER), out[0]):
            logger.warning("Frames detected containing attacked parameter values. Test those separately.")
    else:
        kb.reflectiveCounters[REFLECTIVE_COUNTER.MISS] += 1
        if kb.reflectiveCounters[REFLECTIVE_COUNTER.MISS] > REFLECTIVE_MISS_THRESHOLD:
            kb.reflectiveMechanism = False
            if not suppress_warning:
                logger.debug("Turning off reflection removal mechanism (for optimization)")

    return out[0]


# ---- Comparison logic ----
def comparison(page: Union[str, bytes, None], get_ratio_value: bool = False,
               page_length: Optional[int] = None, second_page: Optional[Union[str, bytes]] = None) -> Optional[Union[bool, float]]:
    """
    Main comparison wrapper. Returns True/False or ratio depending on get_ratio_value. None on indeterminate.
    """
    # Normalize inputs
    if page is None and page_length is None:
        return None

    # Defensive: make sure second_page is provided to SequenceMatcher
    seq_a = second_page
    seq_b = page

    # Use SequenceMatcher or length heuristics when very large
    try:
        seq_matcher = difflib.SequenceMatcher(None, seq_a, seq_b)
    except Exception as exc:
        logger.critical("Failed to create SequenceMatcher: %s", exc)
        # simple fallback
        if seq_a == seq_b:
            return MAX_RATIO if get_ratio_value else True
        return MIN_RATIO if get_ratio_value else False

    # Determine ratio
    ratio: Optional[float] = None

    if page:
        if not page_length:
            page_length = len(page)

    if kb.nullConnection and page_length and getattr(seq_matcher, "a", None):
        if not seq_matcher.a:
            logger.error("Problem occurred while retrieving original page content which prevents continuation.")
            return None
        r = 1.0 * page_length / len(seq_matcher.a)
        ratio = r if r <= 1.0 else 1.0 / r
    else:
        # convert bytes/str incompatibilities
        a_seq = seq_matcher.a
        b_seq = page
        if isinstance(a_seq, bytes) and isinstance(b_seq, str):
            b_seq = get_bytes(b_seq, getattr(kb, "pageEncoding", DEFAULT_PAGE_ENCODING), errors="ignore")
        elif isinstance(a_seq, str) and isinstance(b_seq, bytes):
            seq_matcher.set_seq1(get_bytes(a_seq, getattr(kb, "pageEncoding", DEFAULT_PAGE_ENCODING), errors="ignore"))

        if a_seq is None or b_seq is None:
            return None
        if a_seq == b_seq:
            ratio = 1.0
        elif getattr(kb, "skipSeqMatcher", False) or (isinstance(a_seq, (str, bytes)) and isinstance(b_seq, (str, bytes)) and (len(a_seq) > MAX_DIFFLIB_SEQUENCE_LENGTH or len(b_seq) > MAX_DIFFLIB_SEQUENCE_LENGTH)):
            # fallback to length-based heuristic for very large inputs
            if not a_seq or not b_seq:
                ratio = float(a_seq == b_seq)
            else:
                r = 1.0 * len(a_seq) / len(b_seq)
                ratio = r if r <= 1.0 else 1.0 / r
        else:
            # strip REFLECTED_VALUE_MARKER for matching
            if isinstance(a_seq, bytes):
                a_seq = a_seq.replace(REFLECTED_VALUE_MARKER.encode(), b"")
            elif isinstance(a_seq, str):
                a_seq = a_seq.replace(REFLECTED_VALUE_MARKER, "")
            if isinstance(b_seq, bytes):
                b_seq = b_seq.replace(REFLECTED_VALUE_MARKER.encode(), b"")
            elif isinstance(b_seq, str):
                b_seq = b_seq.replace(REFLECTED_VALUE_MARKER, "")

            if getattr(kb, "heavilyDynamic", False):
                # use line-based ratio for heavily dynamic pages
                seq1 = a_seq.split("\n") if isinstance(a_seq, str) else a_seq.split(b"\n")
                seq2 = b_seq.split("\n") if isinstance(b_seq, str) else b_seq.split(b"\n")
                # Use full ratio in this mode
                ratio = round(difflib.SequenceMatcher(None, seq1, seq2).ratio(), 3)
            else:
                ratio = round(seq_matcher.quick_ratio(), 3)

    if ratio is None:
        return None

    # If matchRatio not set but url is stable, record it
    if kb.matchRatio is None and LOWER_RATIO_BOUND <= ratio <= UPPER_RATIO_BOUND:
        kb.matchRatio = ratio
        logger.debug("setting match ratio for current parameter to %.3f", kb.matchRatio)

    if get_ratio_value:
        return ratio

    if ratio > UPPER_RATIO_BOUND:
        return True
    if ratio < LOWER_RATIO_BOUND:
        return False
    if kb.matchRatio is None:
        return None
    return (ratio - kb.matchRatio) > DIFF_TOLERANCE


# ---- xrange compatibility class (preserved but simplified) ----
class xrange:
    """
    Lightweight implementation compatible with Python's range-like behavior used in original tests.
    """

    __slots__ = ("_slice",)

    def __init__(self, *args):
        if args and isinstance(args[0], xrange):
            self._slice = slice(args[0].start, args[0].stop, args[0].step)
            return
        self._slice = slice(*args)
        if self._slice.stop is None:
            raise TypeError("xrange stop must not be None")

    @property
    def start(self):
        return self._slice.start if self._slice.start is not None else 0

    @property
    def stop(self):
        return self._slice.stop

    @property
    def step(self):
        return self._slice.step if self._slice.step is not None else 1

    def __len__(self):
        s = self._slice
        start = 0 if s.start is None else s.start
        step = 1 if s.step is None else s.step
        stop = s.stop
        return max(0, 1 + int((stop - 1 - start) // step))

    def __contains__(self, value):
        return (self.start <= value < self.stop) and ((value - self.start) % self.step == 0)

    def __getitem__(self, index):
        if isinstance(index, slice):
            start, stop, step = index.indices(len(self))
            return xrange(self._index(start), self._index(stop), step * self.step)
        if not isinstance(index, int):
            raise TypeError("xrange indices must be slices or integers")
        if index < 0:
            index += len(self)
        if index < 0 or index >= len(self):
            raise IndexError("Index %d out of %r" % (index, self))
        return self._index(index)

    def _index(self, i):
        return self.start + self.step * i

    def index(self, i):
        if self.start <= i < self.stop:
            return i - self.start
        raise ValueError("%d is not in list" % i)

    def __repr__(self):
        return f"xrange({self.start}, {self.stop}, {self.step})"
