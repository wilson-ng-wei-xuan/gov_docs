{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP5H-M8E-Bcd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829022334,
          "user_tz": -480,
          "elapsed": 2606,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "966f4251-1732-43ba-a839-931ad101abba"
      },
      "id": "iP5H-M8E-Bcd",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (1.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.12.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install axolotl[ring-flash-attn]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y8S5-DlS6pEk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829144271,
          "user_tz": -480,
          "elapsed": 121939,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e8b95bc5-419a-49bd-de14-403783c45c4a"
      },
      "id": "y8S5-DlS6pEk",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting axolotl[ring-flash-attn]\n",
            "  Downloading axolotl-0.8.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.1/275.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes==0.45.4 (from axolotl[ring-flash-attn])\n",
            "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting triton>=3.0.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting liger-kernel==0.5.6 (from axolotl[ring-flash-attn])\n",
            "  Downloading liger_kernel-0.5.6-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting packaging==23.2 (from axolotl[ring-flash-attn])\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting peft==0.15.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers==4.51.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting tokenizers>=0.21.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting accelerate==1.6.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: datasets==3.5.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (3.5.0)\n",
            "Collecting trl==0.16.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hf_xet==1.0.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading hf_xet-1.0.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Collecting optimum==1.16.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting hf_transfer (from axolotl[ring-flash-attn])\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.2.0)\n",
            "Collecting gradio==5.23.3 (from axolotl[ring-flash-attn])\n",
            "  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting modal==0.70.5 (from axolotl[ring-flash-attn])\n",
            "  Downloading modal-0.70.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pydantic==2.10.6 (from axolotl[ring-flash-attn])\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting addict (from axolotl[ring-flash-attn])\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fire (from axolotl[ring-flash-attn])\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2.32.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.19.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.8.0)\n",
            "Collecting colorama (from axolotl[ring-flash-attn])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (0.60.0)\n",
            "Requirement already satisfied: numpy<=2.0.1,>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (1.26.4)\n",
            "Collecting evaluate==0.4.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (1.13.1)\n",
            "Collecting scikit-learn==1.4.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py==12.560.30 (from axolotl[ring-flash-attn])\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting art (from axolotl[ring-flash-attn])\n",
            "  Downloading art-6.5-py3-none-any.whl.metadata (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2.17.1)\n",
            "Collecting python-dotenv==1.0.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting s3fs>=2024.5.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading s3fs-2025.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: gcsfs>=2024.5.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2024.10.0)\n",
            "Collecting adlfs>=2024.5.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading adlfs-2024.12.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ocifs==1.3.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading ocifs-1.3.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting zstandard==0.22.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (1.7.28)\n",
            "Collecting lm_eval==0.4.7 (from axolotl[ring-flash-attn])\n",
            "  Downloading lm_eval-0.4.7-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect==1.0.9 (from axolotl[ring-flash-attn])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting immutabledict==4.2.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting antlr4-python3-runtime==4.13.2 (from axolotl[ring-flash-attn])\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Collecting torchao==0.9.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "Collecting schedulefree==1.4.1 (from axolotl[ring-flash-attn])\n",
            "  Downloading schedulefree-1.4.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting axolotl-contribs-lgpl==0.0.6 (from axolotl[ring-flash-attn])\n",
            "  Downloading axolotl_contribs_lgpl-0.0.6.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting axolotl-contribs-mit==0.0.3 (from axolotl[ring-flash-attn])\n",
            "  Downloading axolotl_contribs_mit-0.0.3.tar.gz (5.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from axolotl[ring-flash-attn]) (2.5.1+cu121)\n",
            "Collecting xformers>=0.0.28.post3 (from axolotl[ring-flash-attn])\n",
            "  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting flash-attn==2.7.4.post1 (from axolotl[ring-flash-attn])\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m141.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ring-flash-attn>=0.1.4 (from axolotl[ring-flash-attn])\n",
            "  Downloading ring_flash_attn-0.1.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting yunchang==0.6.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading yunchang-0.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==1.6.0->axolotl[ring-flash-attn]) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.6.0->axolotl[ring-flash-attn]) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.6.0->axolotl[ring-flash-attn]) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0->axolotl[ring-flash-attn]) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.5.0->axolotl[ring-flash-attn]) (3.11.11)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl[ring-flash-attn])\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (0.28.1)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate==1.6.0->axolotl[ring-flash-attn])\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.1.5)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (3.10.13)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (11.1.0)\n",
            "Collecting pydub (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.23.3->axolotl[ring-flash-attn]) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==5.23.3->axolotl[ring-flash-attn])\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect==1.0.9->axolotl[ring-flash-attn]) (1.17.0)\n",
            "Collecting jsonlines (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.7->axolotl[ring-flash-attn]) (2.10.2)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlitedict (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting word2number (from lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.7->axolotl[ring-flash-attn]) (10.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (2024.12.14)\n",
            "Requirement already satisfied: click>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (8.1.8)\n",
            "Collecting grpclib==0.4.7 (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading grpclib-0.4.7.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf!=4.24.0,<6.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (4.25.5)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (13.9.4)\n",
            "Collecting synchronicity~=0.9.8 (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading synchronicity-0.9.11-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from modal==0.70.5->axolotl[ring-flash-attn]) (0.10.2)\n",
            "Collecting types-certifi (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading types_certifi-2021.10.8.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting types-toml (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading types_toml-0.10.8.20240310-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting watchfiles (from modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading watchfiles-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting oci>=2.43.1 (from ocifs==1.3.2->axolotl[ring-flash-attn])\n",
            "  Downloading oci-2.150.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting coloredlogs (from optimum==1.16.2->axolotl[ring-flash-attn])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.16.2->axolotl[ring-flash-attn]) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.10.6->axolotl[ring-flash-attn]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.10.6->axolotl[ring-flash-attn]) (2.27.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl[ring-flash-attn]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl[ring-flash-attn]) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->axolotl[ring-flash-attn]) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0->axolotl[ring-flash-attn]) (2024.11.6)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.8.0->gradio==5.23.3->axolotl[ring-flash-attn]) (14.1)\n",
            "Collecting h2<5,>=3.1.0 (from grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: multidict in /usr/local/lib/python3.10/dist-packages (from grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn]) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.16.2->axolotl[ring-flash-attn]) (1.3.0)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-datalake-store<0.1,>=0.0.53 (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting azure-identity (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.17.0 (from adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[ring-flash-attn]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[ring-flash-attn]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[ring-flash-attn]) (2.3.0)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading aiobotocore-2.21.1-py3-none-any.whl.metadata (24 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs>=2024.5.0 (from axolotl[ring-flash-attn])\n",
            "  Downloading s3fs-2025.3.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading s3fs-2024.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton>=3.0.0->axolotl[ring-flash-attn]) (69.5.1)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers>=0.0.28.post3 (from axolotl[ring-flash-attn])\n",
            "  Downloading xformers-0.0.29.post2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "  Downloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl[ring-flash-attn]) (2.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->axolotl[ring-flash-attn]) (0.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[ring-flash-attn]) (3.1.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[ring-flash-attn]) (1.3.4)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.37.2,>=1.37.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading botocore-1.37.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn]) (2.8.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[ring-flash-attn]) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (1.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.5.0->axolotl[ring-flash-attn]) (1.18.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio==5.23.3->axolotl[ring-flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio==5.23.3->axolotl[ring-flash-attn]) (1.2.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (1.17.1)\n",
            "Collecting msal<2,>=1.16.0 (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading msal-1.32.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob>=12.17.0->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (43.0.3)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.17.0->adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl[ring-flash-attn]) (4.0.12)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (4.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==5.23.3->axolotl[ring-flash-attn]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.23.3->axolotl[ring-flash-attn]) (0.14.0)\n",
            "Requirement already satisfied: pyOpenSSL<25.0.0,>=17.5.0 in /usr/local/lib/python3.10/dist-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl[ring-flash-attn]) (24.2.1)\n",
            "Requirement already satisfied: pytz>=2016.10 in /usr/local/lib/python3.10/dist-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl[ring-flash-attn]) (2024.2)\n",
            "Collecting circuitbreaker<3.0.0,>=1.3.1 (from oci>=2.43.1->ocifs==1.3.2->axolotl[ring-flash-attn])\n",
            "  Downloading circuitbreaker-2.1.3-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.5.0->axolotl[ring-flash-attn]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modal==0.70.5->axolotl[ring-flash-attn]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modal==0.70.5->axolotl[ring-flash-attn]) (2.18.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.7->axolotl[ring-flash-attn]) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[ring-flash-attn]) (0.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl[ring-flash-attn]) (5.3.0)\n",
            "Collecting sigtools>=4.0.1 (from synchronicity~=0.9.8->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading sigtools-4.0.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==5.23.3->axolotl[ring-flash-attn]) (1.5.4)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->adlfs>=2024.5.0->axolotl[ring-flash-attn])\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl[ring-flash-attn])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.6.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn])\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl[ring-flash-attn]) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (1.25.0)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3.1.0->grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3.1.0->grpclib==0.4.7->modal==0.70.5->axolotl[ring-flash-attn])\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->modal==0.70.5->axolotl[ring-flash-attn]) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.7->axolotl[ring-flash-attn]) (5.2.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl[ring-flash-attn]) (2.10.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[ring-flash-attn]) (3.2.2)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.23.3-py3-none-any.whl (46.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.0.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading liger_kernel-0.5.6-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.7-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modal-0.70.5-py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.4/509.4 kB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ocifs-1.3.2-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Downloading peft-0.15.1-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading schedulefree-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.0-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yunchang-0.6.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adlfs-2024.12.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ring_flash_attn-0.1.4-py3-none-any.whl (24 kB)\n",
            "Downloading s3fs-2024.10.0-py3-none-any.whl (29 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading art-6.5-py3-none-any.whl (610 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.4/610.4 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiobotocore-2.21.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.1/207.1 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_datalake_store-0.0.53-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oci-2.150.2-py3-none-any.whl (29.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m147.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading synchronicity-0.9.11-py3-none-any.whl (36 kB)\n",
            "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading types_certifi-2021.10.8.3-py3-none-any.whl (2.1 kB)\n",
            "Downloading types_toml-0.10.8.20240310-py3-none-any.whl (4.8 kB)\n",
            "Downloading watchfiles-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.37.1-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading circuitbreaker-2.1.3-py3-none-any.whl (7.7 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading msal-1.32.3-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading sigtools-4.0.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: axolotl-contribs-lgpl, axolotl-contribs-mit, flash-attn, langdetect, grpclib, axolotl, fire, rouge-score, sqlitedict, word2number\n",
            "  Building wheel for axolotl-contribs-lgpl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl-contribs-lgpl: filename=axolotl_contribs_lgpl-0.0.6-py3-none-any.whl size=10895 sha256=861a1f1b03029aa1103f3f9d73b5c1d1825e44fdbb0634d2db77ae3d2b26ae0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/0a/5b/0c4db6ff7b7b11979dc2d274706f66cd079198fb0f15dea37f\n",
            "  Building wheel for axolotl-contribs-mit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl-contribs-mit: filename=axolotl_contribs_mit-0.0.3-py3-none-any.whl size=6004 sha256=bc3559644b5b29c727bd667c57aa7b5fdbf43076759193019b4c4831c89b5930\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/8e/3b/84cb3147cfe6cb5853c2667823368039db4a2b9b2eeb6a0eaf\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187797312 sha256=b267f80a08e516292cdd748056a2178a45b8abedf7fca123292eb17c21c8c87c\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/ce/d5/08ea07bfc16ba218dc65a3a7ef9b6a270530bcbd2cea2ee1ca\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ec15e8e85c1064440f761f65328a21c8c848863aaa8000c9f8edb5aed08b219d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.7-py3-none-any.whl size=76261 sha256=0cfbcd1c048924397aa21aa659ee958ce9a0cfaa405dbfb3a2e10264c2b34b91\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/c0/1c/3d807409d0c67efeab2949832ba409205b1b6fe03f739ae4c1\n",
            "  Building wheel for axolotl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl: filename=axolotl-0.8.1-py3-none-any.whl size=350644 sha256=bcb28e219e315ca78c1e168a97ba0fb905bbeb9e0d20889a71e014b5b2530f61\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/48/e9/741d24d3a8d57db536ce44ff0b6d229a0dfc2b9d8285aa8985\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=26c6add747572aa3f32d522677939e9d92362b86ab126a9abb55b707580fdb75\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=21cede52991be29d979d08da0a9e360d250e47472b7013ec9bc1f5a60ffa921a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=c11fc90867b91b1c5ef9f64e5ece8574d74485921f9026d48f4e162b7755fddc\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=5970dba2bc2ada7a915b1699f748c6f2c6d9996fae47ccb9350c8a8e51cd0229\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built axolotl-contribs-lgpl axolotl-contribs-mit flash-attn langdetect grpclib axolotl fire rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, types-certifi, torchao, sqlitedict, pydub, nvidia-ml-py, circuitbreaker, antlr4-python3-runtime, addict, zstandard, yunchang, uvicorn, types-toml, triton, tomlkit, tcolorpy, sigtools, semantic-version, ruff, ring-flash-attn, python-multipart, python-dotenv, pybind11, portalocker, pathvalidate, packaging, mbstrdecoder, langdetect, jsonlines, jmespath, isodate, immutabledict, hyperframe, humanfriendly, hpack, hf_xet, hf_transfer, groovy, fire, ffmpy, colorama, art, aioitertools, aiofiles, watchfiles, typepy, tqdm-multiprocess, synchronicity, starlette, scikit-learn, sacrebleu, rouge-score, responses, pydantic, huggingface-hub, h2, coloredlogs, botocore, azure-core, xformers, tokenizers, schedulefree, safehttpx, liger-kernel, grpclib, gradio-client, flash-attn, fastapi, bitsandbytes, azure-storage-blob, axolotl-contribs-mit, accelerate, transformers, oci, msal, modal, gradio, DataProperty, aiobotocore, tabledata, s3fs, peft, ocifs, msal-extensions, azure-datalake-store, trl, pytablewriter, optimum, evaluate, azure-identity, axolotl-contribs-lgpl, lm_eval, adlfs, axolotl\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 12.570.86\n",
            "    Uninstalling nvidia-ml-py-12.570.86:\n",
            "      Successfully uninstalled nvidia-ml-py-12.570.86\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: immutabledict\n",
            "    Found existing installation: immutabledict 4.2.1\n",
            "    Uninstalling immutabledict-4.2.1:\n",
            "      Successfully uninstalled immutabledict-4.2.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.0\n",
            "    Uninstalling scikit-learn-1.6.0:\n",
            "      Successfully uninstalled scikit-learn-1.6.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.4\n",
            "    Uninstalling pydantic-2.10.4:\n",
            "      Successfully uninstalled pydantic-2.10.4\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.27.1\n",
            "    Uninstalling huggingface-hub-0.27.1:\n",
            "      Successfully uninstalled huggingface-hub-0.27.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.45.5\n",
            "    Uninstalling bitsandbytes-0.45.5:\n",
            "      Successfully uninstalled bitsandbytes-0.45.5\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "Successfully installed DataProperty-1.1.0 accelerate-1.6.0 addict-2.4.0 adlfs-2024.12.0 aiobotocore-2.21.1 aiofiles-23.2.1 aioitertools-0.12.0 antlr4-python3-runtime-4.13.2 art-6.5 axolotl-0.8.1 axolotl-contribs-lgpl-0.0.6 axolotl-contribs-mit-0.0.3 azure-core-1.33.0 azure-datalake-store-0.0.53 azure-identity-1.21.0 azure-storage-blob-12.25.1 bitsandbytes-0.45.4 botocore-1.37.1 circuitbreaker-2.1.3 colorama-0.4.6 coloredlogs-15.0.1 evaluate-0.4.1 fastapi-0.115.12 ffmpy-0.5.0 fire-0.7.0 flash-attn-2.7.4.post1 gradio-5.23.3 gradio-client-1.8.0 groovy-0.1.2 grpclib-0.4.7 h2-4.2.0 hf_transfer-0.1.9 hf_xet-1.0.0 hpack-4.1.0 huggingface-hub-0.30.2 humanfriendly-10.0 hyperframe-6.1.0 immutabledict-4.2.0 isodate-0.7.2 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 liger-kernel-0.5.6 lm_eval-0.4.7 mbstrdecoder-1.1.4 modal-0.70.5 msal-1.32.3 msal-extensions-1.3.1 nvidia-ml-py-12.560.30 oci-2.150.2 ocifs-1.3.2 optimum-1.16.2 packaging-23.2 pathvalidate-3.2.3 peft-0.15.1 portalocker-3.1.1 pybind11-2.13.6 pydantic-2.10.6 pydub-0.25.1 pytablewriter-1.2.1 python-dotenv-1.0.1 python-multipart-0.0.20 responses-0.18.0 ring-flash-attn-0.1.4 rouge-score-0.1.2 ruff-0.11.7 s3fs-2024.10.0 sacrebleu-2.5.1 safehttpx-0.1.6 schedulefree-1.4.1 scikit-learn-1.4.2 semantic-version-2.10.0 sigtools-4.0.1 sqlitedict-2.1.0 starlette-0.46.2 synchronicity-0.9.11 tabledata-1.3.4 tcolorpy-0.1.7 tokenizers-0.21.1 tomlkit-0.13.2 torchao-0.9.0 tqdm-multiprocess-0.0.11 transformers-4.51.0 triton-3.3.0 trl-0.16.1 typepy-1.3.4 types-certifi-2021.10.8.3 types-toml-0.10.8.20240310 uvicorn-0.34.2 watchfiles-1.0.5 word2number-1.1 xformers-0.0.29.post1 yunchang-0.6.0 zstandard-0.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate",
                  "bitsandbytes",
                  "huggingface_hub",
                  "peft",
                  "pynvml",
                  "sklearn",
                  "transformers"
                ]
              },
              "id": "edc89f436bd94dc4a72f7467a0c692d6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4vha5X5Hgt6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829147089,
          "user_tz": -480,
          "elapsed": 2820,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5907aca0-8ccb-4d74-a057-b9f0e1d7093a"
      },
      "id": "z4vha5X5Hgt6",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.51.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  transformers datasets peft accelerate bitsandbytes wandb deepspeed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STQoDdHuQLF7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829150123,
          "user_tz": -480,
          "elapsed": 3037,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "73db66cb-a78d-4204-abac-f290aae0fb6e"
      },
      "id": "STQoDdHuQLF7",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.51.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.4)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (0.16.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (69.5.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from deepspeed) (0.8.0)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.4)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from deepspeed) (12.560.30)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "TCbx9PsYEzdX"
      },
      "id": "TCbx9PsYEzdX"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.cloud import storage\n",
        "import os\n",
        "\n",
        "def save_json(data, filename):\n",
        "    # Get the directory from the filename\n",
        "    directory = os.path.dirname(filename)\n",
        "\n",
        "    # Check if the directory exists, if not, create it\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    # Save the data to the file\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def list_files_in_bucket(bucket_name, prefix=\"\"):\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "\n",
        "    # Print the list of file names in the bucket\n",
        "    print(\"Files in the bucket:\")\n",
        "    for blob in blobs:\n",
        "        print(blob.name)\n",
        "\n",
        "def load_json_from_gcs(bucket_name, file_name):\n",
        "    from google.cloud import storage\n",
        "    import json\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    if not file_name.endswith('.jsonl'):  # Ensure it's a JSONL file\n",
        "        raise ValueError(f\"The specified file '{file_name}' is not a JSONL file.\")\n",
        "\n",
        "    concatenated_data = []  # To accumulate JSON objects\n",
        "    try:\n",
        "        # Download and decode the file content\n",
        "        content = blob.download_as_string().decode('utf-8')\n",
        "        # Split content by lines and load each line as a separate JSON object\n",
        "        for line in content.splitlines():\n",
        "            if line.strip():  # Only parse non-empty lines\n",
        "                json_obj = json.loads(line)\n",
        "                concatenated_data.append(json_obj)  # Add JSON object to the list\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON in {file_name}: {e}\")\n",
        "\n",
        "    # Return the JSON as a string for output\n",
        "    return json.dumps(concatenated_data, indent=4)  # Prettify the JSON output\n",
        "\n",
        "def load_csv_from_gcs(bucket_name, file_name):\n",
        "    from google.cloud import storage\n",
        "    import pandas as pd\n",
        "    from io import StringIO  # Corrected import for StringIO\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    if not file_name.endswith('.csv'):  # Ensure it's a CSV file\n",
        "        raise ValueError(f\"The specified file '{file_name}' is not a CSV file.\")\n",
        "\n",
        "    try:\n",
        "        # Download CSV content and load it into a pandas DataFrame\n",
        "        content = blob.download_as_string().decode('utf-8')\n",
        "        data = pd.read_csv(StringIO(content))  # Use StringIO to parse the CSV content\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CSV file '{file_name}': {e}\")\n",
        "        return None\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def save_csv_to_gcs(bucket_name, file_name, dataframe):\n",
        "    from google.cloud import storage\n",
        "    import pandas as pd\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    if not file_name.endswith('.csv'):\n",
        "        raise ValueError(f\"The specified file '{file_name}' is not a CSV file.\")\n",
        "\n",
        "    try:\n",
        "        # Convert the DataFrame to CSV and upload it to GCS\n",
        "        csv_content = dataframe.to_csv(index=False)  # Convert DataFrame to CSV string\n",
        "        blob.upload_from_string(csv_content, content_type='text/csv')\n",
        "        print(f\"File '{file_name}' successfully saved to bucket '{bucket_name}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving CSV file '{file_name}': {e}\")"
      ],
      "metadata": {
        "id": "sec6ZoL57RQL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829156719,
          "user_tz": -480,
          "elapsed": 375,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "sec6ZoL57RQL",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_sample(df, col1, col2, frac=0.5, random_state=None):\n",
        "    total_samples = int(len(df) * frac)\n",
        "    grouped = df.groupby([col1, col2])\n",
        "    n_groups = len(grouped)\n",
        "    samples_per_group = total_samples // n_groups\n",
        "\n",
        "    sampled_df = (\n",
        "        grouped\n",
        "        .apply(lambda x: x.sample(n=min(samples_per_group, len(x)), random_state=random_state))\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    return sampled_df"
      ],
      "metadata": {
        "id": "N9I2rQKSTINa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829159439,
          "user_tz": -480,
          "elapsed": 60,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "N9I2rQKSTINa",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_train.csv\")\n",
        "augmented_full_df = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/augmented_mistral_train.csv\")\n",
        "test_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_test.csv\").rename({'key_point': 'stance', 'person_id': 'user'}, axis=1)\n",
        "vali_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_val.csv\")\n",
        "vali_data['prompt'] = vali_data[['prompt', 'label']].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n",
        "\n",
        "train_data.tail()"
      ],
      "metadata": {
        "id": "m0bDj8Vm-Jaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834030777,
          "user_tz": -480,
          "elapsed": 46128,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "bceec392-a096-4af2-ae65-bfc4b5073a83"
      },
      "id": "m0bDj8Vm-Jaj",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-8847c0ea2598>:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  vali_data['prompt'] = vali_data[['prompt', 'label']].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      group                                  user  \\\n",
              "2435      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2436      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2437      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2438      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "2439      6  dd88a7a7-de66-4503-bfee-dfc0e74f578f   \n",
              "\n",
              "                                                 stance topic_group  \\\n",
              "2435  Contributor shared varying perspectives on whe...     rideout   \n",
              "2436  Contributor had differing opinions on whether ...     rideout   \n",
              "2437  Contributor expressed different views on the t...     rideout   \n",
              "2438  Contributor shared differing opinions on wheth...     rideout   \n",
              "2439  Contributor shared differing views on the inde...     rideout   \n",
              "\n",
              "     human_label  agreement                             group_user  label  \\\n",
              "2435  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2436  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2437  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2438  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "2439  no opinion  unanimous  6dd88a7a7-de66-4503-bfee-dfc0e74f578f      0   \n",
              "\n",
              "                                       pid  chat_group_id  contributor  \\\n",
              "2435  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2436  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2437  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2438  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "2439  dd88a7a7-de66-4503-bfee-dfc0e74f578f              6           16   \n",
              "\n",
              "                                                  topic  \\\n",
              "2435  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2436  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2437  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2438  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "2439  📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...   \n",
              "\n",
              "                                         content_concat  \\\n",
              "2435  Contributor255: https://www.channelnewsasia.co...   \n",
              "2436  Contributor255: https://www.channelnewsasia.co...   \n",
              "2437  Contributor255: https://www.channelnewsasia.co...   \n",
              "2438  Contributor255: https://www.channelnewsasia.co...   \n",
              "2439  Contributor255: https://www.channelnewsasia.co...   \n",
              "\n",
              "                                                 prompt  \n",
              "2435  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2436  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2437  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2438  <s>[INST]Determine whether Contributor16 holds...  \n",
              "2439  <s>[INST]Determine whether Contributor16 holds...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac8a12a3-9ef1-4c29-ad1f-23d37465e181\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>user</th>\n",
              "      <th>stance</th>\n",
              "      <th>topic_group</th>\n",
              "      <th>human_label</th>\n",
              "      <th>agreement</th>\n",
              "      <th>group_user</th>\n",
              "      <th>label</th>\n",
              "      <th>pid</th>\n",
              "      <th>chat_group_id</th>\n",
              "      <th>contributor</th>\n",
              "      <th>topic</th>\n",
              "      <th>content_concat</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2435</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor shared varying perspectives on whe...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2436</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor had differing opinions on whether ...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2437</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor expressed different views on the t...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2438</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor shared differing opinions on wheth...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2439</th>\n",
              "      <td>6</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>Contributor shared differing views on the inde...</td>\n",
              "      <td>rideout</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>6dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>0</td>\n",
              "      <td>dd88a7a7-de66-4503-bfee-dfc0e74f578f</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>📢 *Topic* 📢\\n\\nIn Parliament today (3 July), S...</td>\n",
              "      <td>Contributor255: https://www.channelnewsasia.co...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor16 holds...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac8a12a3-9ef1-4c29-ad1f-23d37465e181')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac8a12a3-9ef1-4c29-ad1f-23d37465e181 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac8a12a3-9ef1-4c29-ad1f-23d37465e181');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38e87f52-8fde-4dd5-916a-621b4ff84650\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38e87f52-8fde-4dd5-916a-621b4ff84650')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38e87f52-8fde-4dd5-916a-621b4ff84650 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"dd88a7a7-de66-4503-bfee-dfc0e74f578f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Contributor had differing opinions on whether the process for renting out the Ridout Road properties was fair.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rideout\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no opinion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agreement\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"unanimous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group_user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"6dd88a7a7-de66-4503-bfee-dfc0e74f578f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pid\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"dd88a7a7-de66-4503-bfee-dfc0e74f578f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chat_group_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contributor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 16,\n        \"max\": 16,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\ud83d\\udce2 *Topic* \\ud83d\\udce2\\n\\nIn Parliament today (3 July), Senior Minister Teo Chee Hean delivered a Ministerial Statement on the findings from his review of the rental of the 26 Ridout Road and 31 Ridout Road properties by Minister K Shanmugam and Minister Vivian Balakrishnan, respectively. \\n\\nThis Parliament discussion comes after PM Lee directed for the Corrupt Practices Investigation Bureau (CPIB) and SM Teo to conduct reviews on the situation. Both CPIB and SM Teo\\u2019s reports were published on 28 June 2023. \\n\\n\\ud83d\\udcac *What are your views on the findings from SM Teo\\u2019s review into the rental of the Ridout Road bungalows?*\\n\\nIn SM Teo\\u2019s Ministerial Statement, he noted that:\\n\\n1\\ufe0f\\u20e3 *No evidence of corruption or criminal wrongdoing in the rental of the Ridout Road properties.*\\n\\nSM Teo said that CPIB had found no evidence of corruption or criminal wrongdoing in the rental of Ridout Road properties by the two ministers. Neither were corrupt intent or any inducements uncovered.\\n\\n2\\ufe0f\\u20e3 *Both Ministers and the public officers, as well as private sector intermediaries involved,\\u00a0had conducted themselves properly in the two rental transactions.*\\n\\nSM Teo said that Ministers, public officers and private sector intermediaries were aware of their duty to declare and avoid any conflict of interest and took appropriate steps to prevent any potential or actual conflict of interest from arising. \\n\\nNonetheless, SM Teo announced that the Public Service Division (PSD) will work with relevant ministries and statutory boards such as HDB, JTC, NEA and SLA to introduce a standard declaration requirement for selected groups of officers who have access to, or are involved in, leasing and valuation matters.\\u00a0PM will also review declarations required for property transactions for Ministers and PAP MPs. \\n\\n3\\ufe0f\\u20e3 *Both rental transactions had kept to Singapore Land Authority's (SLA) prevailing guidelines.*\\n\\nSM Teo said that the rental of the two properties did not deviate from prevailing SLA guidelines for renting out black-and-white bungalows for residential purposes. He added that both properties were within the maximum allowable tenancy of 3+3+3 years for residential properties rented out by SLA or SLA\\u2019s managing agents at any one time. \\n\\n\\ud83d\\udd14 *The Parliament discussion on Ridout Road is still ongoing. Watch the discussion live here:* https://www.youtube.com/watch?v=xn7sGrmdpTw \\ud83d\\udd14\\n\\n\\ud83d\\udc49\\ud83c\\udffc  *ST live summary on the Parliament discussion* https://www.straitstimes.com/ridout-road-bungalow-rentals-parliament-live-blog\\n\\n\\ud83d\\udc49\\ud83c\\udffc *Findings from CPIB and SM Teo's reviews*\\nhttps://www.pmo.gov.sg/Newsroom/Rental-of-State-Properties-at-Ridout-Road-by-Min-Shanmugam-and-Min-Vivian-Balakrishnan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_concat\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Contributor255: https://www.channelnewsasia.com/singapore/ridout-road-properties-officers-privileged-information-declaration-renting-government-sm-teo-3602056?cid=internal_sharetool_iphone_03072023_cnaThis directly address Point 2 for me that there are gaps and as such , the integrity is left in a question mark here for the 2 ministers instead of it being iron clad there was none .\\nContributor813: For a second point, why should the ministers not have bought their own private properties elsewhere to stay in, if the primary motive for minister Shanmugum was to monetize his home.\\nContributor255: https://www.channelnewsasia.com/singapore/ridout-road-sla-rent-black-white-bungalow-longer-lease-en-bloc-3602066?cid=internal_sharetool_iphone_03072023_cna\\nContributor813: I can accept minister balakrishnan saying that he wished to house multiple generations all in a home. Even if this is a privileged choice he can make there is nothing inherent to disagree about.\\nContributor255: The question for his long leases is whether this is knee jerk to the questions asked about the value of the refurbishment or SLA can show this was in the works a few years ago and still in planning stages\\nContributor389: Partly the way SLA handle the initial response to the allegation was rather poorly done imho\\nContributor57: did he shed a tear when he said this?\\nContributor813: I think the word privileged came out of his mouth. At any rate his home is much more aligned with the rest of the SLA properties being rented out. minister Shanmugum has all those arrangements which have a lot of attention being drawn to it.So the credible prospects can read all the contents of the list, and indeed all the managing agents possess such a list and publicize it. Do they publicize this in lockstep with SLA\\u2019s decisions to not list or to list? Otherwise it sounds like the strategy to not allow supply to cannibalize demand would be highly ineffective and any marketing in this manner would not work.If the Managing agents do manage themselves without direction from SLA, and publicize the properties so as to \\u201cmaximize the rental and occupancy\\u201d, does SLA defer to the managing agents who are \\u201cthe professionals\\u201d, as ostensibly stated by Minister Tong, or does SLA hold an independent marketing strategy and decide this themselves?\\nContributor16: the toxicities here , impressive !\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<s>[INST]Determine whether Contributor16 holds the same view as this statement: 'Contributor had differing opinions on whether the process for renting out the Ridout Road properties was fair.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 16 and other contributors: \\n Contributor255: https://www.channelnewsasia.com/singapore/ridout-road-properties-officers-privileged-information-declaration-renting-government-sm-teo-3602056?cid=internal_sharetool_iphone_03072023_cnaThis directly address Point 2 for me that there are gaps and as such , the integrity is left in a question mark here for the 2 ministers instead of it being iron clad there was none .\\nContributor813: For a second point, why should the ministers not have bought their own private properties elsewhere to stay in, if the primary motive for minister Shanmugum was to monetize his home.\\nContributor255: https://www.channelnewsasia.com/singapore/ridout-road-sla-rent-black-white-bungalow-longer-lease-en-bloc-3602066?cid=internal_sharetool_iphone_03072023_cna\\nContributor813: I can accept minister balakrishnan saying that he wished to house multiple generations all in a home. Even if this is a privileged choice he can make there is nothing inherent to disagree about.\\nContributor255: The question for his long leases is whether this is knee jerk to the questions asked about the value of the refurbishment or SLA can show this was in the works a few years ago and still in planning stages\\nContributor389: Partly the way SLA handle the initial response to the allegation was rather poorly done imho\\nContributor57: did he shed a tear when he said this?\\nContributor813: I think the word privileged came out of his mouth. At any rate his home is much more aligned with the rest of the SLA properties being rented out. minister Shanmugum has all those arrangements which have a lot of attention being drawn to it.So the credible prospects can read all the contents of the list, and indeed all the managing agents possess such a list and publicize it. Do they publicize this in lockstep with SLA\\u2019s decisions to not list or to list? Otherwise it sounds like the strategy to not allow supply to cannibalize demand would be highly ineffective and any marketing in this manner would not work.If the Managing agents do manage themselves without direction from SLA, and publicize the properties so as to \\u201cmaximize the rental and occupancy\\u201d, does SLA defer to the managing agents who are \\u201cthe professionals\\u201d, as ostensibly stated by Minister Tong, or does SLA hold an independent marketing strategy and decide this themselves?\\nContributor16: the toxicities here , impressive ! [/INST]0</s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(train_data.prompt.values)[-2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "qIBCTclHJP9l",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834030777,
          "user_tz": -480,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "eea0ef78-4088-4c96-85a2-acb93c6b2700"
      },
      "id": "qIBCTclHJP9l",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s>[INST]Determine whether Contributor16 holds the same view as this statement: 'Contributor shared differing opinions on whether the Singapore Land Authority (SLA) should rent out more colonial properties.’? Based on the following conversation summary, respond with ‘1’ if they share the view, or ‘0’ otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 16 and other contributors: \\n Contributor255: https://www.channelnewsasia.com/singapore/ridout-road-properties-officers-privileged-information-declaration-renting-government-sm-teo-3602056?cid=internal_sharetool_iphone_03072023_cnaThis directly address Point 2 for me that there are gaps and as such , the integrity is left in a question mark here for the 2 ministers instead of it being iron clad there was none .\\nContributor813: For a second point, why should the ministers not have bought their own private properties elsewhere to stay in, if the primary motive for minister Shanmugum was to monetize his home.\\nContributor255: https://www.channelnewsasia.com/singapore/ridout-road-sla-rent-black-white-bungalow-longer-lease-en-bloc-3602066?cid=internal_sharetool_iphone_03072023_cna\\nContributor813: I can accept minister balakrishnan saying that he wished to house multiple generations all in a home. Even if this is a privileged choice he can make there is nothing inherent to disagree about.\\nContributor255: The question for his long leases is whether this is knee jerk to the questions asked about the value of the refurbishment or SLA can show this was in the works a few years ago and still in planning stages\\nContributor389: Partly the way SLA handle the initial response to the allegation was rather poorly done imho\\nContributor57: did he shed a tear when he said this?\\nContributor813: I think the word privileged came out of his mouth. At any rate his home is much more aligned with the rest of the SLA properties being rented out. minister Shanmugum has all those arrangements which have a lot of attention being drawn to it.So the credible prospects can read all the contents of the list, and indeed all the managing agents possess such a list and publicize it. Do they publicize this in lockstep with SLA’s decisions to not list or to list? Otherwise it sounds like the strategy to not allow supply to cannibalize demand would be highly ineffective and any marketing in this manner would not work.If the Managing agents do manage themselves without direction from SLA, and publicize the properties so as to “maximize the rental and occupancy”, does SLA defer to the managing agents who are “the professionals”, as ostensibly stated by Minister Tong, or does SLA hold an independent marketing strategy and decide this themselves?\\nContributor16: the toxicities here , impressive ! [/INST]0</s>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(augmented_full_df.prompt.values)[-2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "7dMNNcBeJQrc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834030777,
          "user_tz": -480,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "aa155bc2-c01f-47b8-8fdc-6c1514392a33"
      },
      "id": "7dMNNcBeJQrc",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s>[INST]Determine whether Contributor316 holds the same view as this statement: 'Contributors expressed strong support for the implementation of a national coding curriculum in primary schools, emphasizing the need to equip students with essential digital skills from an early age, while also suggesting that additional resources be allocated for teacher training in this area.’? Based on the following conversation summary, respond with ‘1’ if they share the view, or ‘0’ otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 316 and other contributors: \\n Contributor166: Theres a risk that increasing financial assistance may lead to a dependence on government support rather than empowering families to improve their situations.\\nContributor567: Isnt it fascinating how some believe that financial assistance alone can solve systemic issues? Perhaps there are deeper-rooted challenges that need addressing beyond immediate financial help.\\nContributor654: Its interesting to consider how the allocation of resources might impact other segments of the population. Could focusing solely on low-income families inadvertently overlook the needs of those who are just above that threshold?\\nContributor297: Its essential to consider how these policies might also empower families to become more financially independent in the long run, fostering not just immediate support but sustainable growth within our community. Balancing assistance with opportunities for self-sufficiency could enhance the overall impact of these initiatives.\\nContributor531: I see your point, but isnt it equally important to consider encouraging self-sufficiency rather than just temporary relief? If we keep offering assistance without addressing underlying issues, wont that just lead to dependency in the long run?\\nContributor393: Im not convinced that simply providing financial assistance addresses the root causes of poverty; there needs to be a focus on empowering individuals with skills and opportunities instead.\\nContributor874: Ensuring that financial assistance reaches low-income families is vital, but we must also consider the long-term implications of dependency on these financial aids. For instance, while immediate support helps meet basic needs, it is equally essential to create pathways for skill development and job opportunities, which can lead to sustainable independence. Taking a holistic approach might yield better outcomes for families in the long run.\\nContributor400: But if we keep giving out financial assistance like that, won’t it just create a dependency instead of encouraging self-reliance? People might not be motivated to improve their situation if they feel the government will always have their back. Plus, there might be better ways to help them that focus on skills training and job opportunities instead.\\nContributor566: Its great to hear that theres support for enhancing financial assistance, particularly when looking at how initiatives like the Community Health Assist Scheme have helped lower-income families access healthcare. However, there’s also the concern that while direct financial aid is beneficial, we should explore sustainable job creation and skills training. This can empower families long-term, reducing dependency on financial assistance over time.\\nContributor610: Its interesting to consider how sustainable this financial assistance is in the long run; while it addresses immediate needs, what happens when the support runs out? Wouldnt we need to think about creating more opportunities for these families to achieve long-term financial independence rather than just meeting basic needs?\\nContributor936: It’s crucial to consider how this financial assistance program aligns with long-term sustainability and economic growth. How can we ensure that this support doesnt inadvertently create dependency rather than empowerment?\\nContributor566: Ensuring that basic needs are met is undoubtedly crucial, but we should also consider how these financial assistance programs are integrated with skill development and job training. By focusing solely on financial aid, we might inadvertently create dependency rather than empowering families to achieve long-term self-sufficiency. Its important to strike a balance between immediate support and offering avenues for individuals to enhance their skills and employment opportunities.\\nContributor992: It’s essential to recognize that while financial assistance is crucial, we should also consider the long-term sustainability of these policies. Building skills and providing educational resources could empower families more effectively than assistance alone.\\nContributor950: I strongly advocate for the implementation of a national coding curriculum in primary schools as it addresses a critical gap in our education system, especially as we move further into a digital age. One vital sub-topic to consider is the integration of coding with critical thinking and problem-solving skills. By introducing coding at an early age, students not only learn how to create technology but also develop a mindset for analytical thinking. For instance, programs like Scratch allow children to engage in creative coding while learning fundamental concepts of logic and algorithmic thinking.Moreover, it’s essential to highlight the need for teacher training. Even as we roll out a coding curriculum, we must ensure that our educators are equipped with the skills and confidence to teach these topics effectively. Investing in training programs that empower teachers will guarantee that they are not just delivering content but also inspiring students to think critically about technology. For example, if teachers have access to ongoing workshops and resources, they will be better prepared to tackle varied learning styles and foster a more inclusive environment where every student can thrive. In summary, the successful implementation of a national coding curriculum hinges not only on the curriculum content itself but also on the capabilities of our teachers. Both components are crucial for nurturing a generation that is adept in digital literacy and creative problem-solving.\\nContributor991: Education is not the filling of a pail, but the lighting of a fire, said William Butler Yeats. Rather than focusing solely on coding, perhaps we should prioritize fostering critical thinking and creativity in our students. These foundational skills can lead to a more innovative mindset in whatever field they choose to excel in.\\nContributor968: It’s interesting to consider how a coding curriculum could potentially highlight the digital divide among students, especially those from less privileged backgrounds. Increased focus on one subject might inadvertently shift attention from other important areas of learning that also foster critical thinking.\\nContributor817: I get what youre saying about teacher training, but we also need to think about how to make coding fun and engaging for the kiddos. If we just focus on the technical skills, they might lose interest fast, right? More hands-on projects or gamified learning could really boost their excitement!\\nContributor876: Have we considered that not every child may be interested in coding? Focusing solely on this could sideline other important skills and interests they might develop.\\nContributor950: Its important to consider how a national coding curriculum aligns with existing subjects and the overall primary school workload. Introducing coding should not overwhelm students or take away from foundational skills in literacy and numeracy, which are equally crucial at that age. Could we perhaps integrate coding into existing subjects, like math or science, to create a more holistic learning experience?\\nContributor571: Its important to consider the varying levels of interest and aptitude among students when it comes to coding, as not every child may engage equally with digital skills. Additionally, there could be an opportunity to integrate digital literacy into broader subjects, fostering a more holistic approach to learning. This way, we can ensure that all students, regardless of their inclination towards coding, still gain essential skills relevant to a technologically advancing world.\\nContributor316: Its worth considering that while coding skills are important, there might also be other areas of learning that deserve equal attention in the curriculum, such as critical thinking and creativity. Balancing these subjects could lead to well-rounded students who thrive in various fields, not just technology. [/INST]0</s>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(test_data.prompt.values)[-2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "vO3-Z6rSJSxd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745828853005,
          "user_tz": -480,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "deb5b0e0-1c60-453e-dc9c-5433189fa65e"
      },
      "id": "vO3-Z6rSJSxd",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST]Determine whether Contributor234 holds the same view as this statement: \\'Contributors discussed the importance of having diverse voices in parliament and the role of opposition parties in representing different viewpoints.’? Based on the following conversation summary, respond with ‘1’ if they share the view, or ‘0’ otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 234 and other contributors: \\n Contributor2132: like breaking up opposition strongholds. Some sections in Marine Parade and East Coast GRC and Tampines also have shown pretty strong opposition support.\\nContributor1463: Wow.....you guys seem to know everything. How many people live where, what kind of people they are, who they will vote for, etc etc etc. So much so that you all can draw conclusions with such certainty just by looking at the boundaries. If you all are not political consultants by now, it would be such a waste of local talent.\\nContributor875: https://str.sg/s2Gc\\nContributor774: When release who sits in which constituency?\\nContributor296: Should just pause or stop the coming water price increase, people already pocket broken holeIn few months time, everyone will feel the pinch, every sip of water will cost you\\nContributor958: Our government been planning ahead for our country and people. Like 2025 involuntarily unemployed, is a plan ahead of coming recession. Not sure how many read this. Many a times, intention not just this, it is not convey in why. As for the SG60 $600, $800 CDC vouchers is to maintain market consumption. Will it be possible to have portion into individual CPF OA as a form of savings. As for HDB BTO, it will be better to open more for Singles Scheme to allow bigger units as long as one is able to afford without loan and enforce more savings into retirement account? Can\\'t we have deductions from rental income into Retirement account instead?\\nContributor234: My eyes glazed over from the gaslighting\\n\\n\\nContributor786: 1. Singapore is the best performing government since 2020 covid until now.2. The results speak for itself.3. The accumulated budget surplus of more than $10 billion for the last 5 years in these trying time speak well as a prudent and responsible government - without incurring debt and yet able to dish out sufficient fiscal budget to help the population.4. Many global governance indicators put us in the top spot.5. However going forward, the geopolitical landscape will not be so rosy.6. US could experience a recession soon.\"Trump declines to rule out 2025 US recession\".This is \"own goal\" - self inflicted damage. https://www.channelnewsasia.com/world/donald-trump-declines-rule-2025-us-recession-4989336#:~:text=Trump%20declines%20to%20rule%20out%202025%20US%20recession\\nContributor715: It seems like trump wants to turn over the country and rebuild it不破不立\\nContributor786: He is doing something very dangerous.\\nContributor234: People have been hugely dissatisfied with the way things has been going for a long timeYou might say what hes doing is dangerous. But he promised change and is arguably delivering itFor better or worse. Change is comingThats what the americans voted forThe want change because they believe the current policies are working against them\\n\\n\\nContributor1301: what\\'s going on? why suddenly mention trump.\\nContributor234: Would only make sense. Wouldnt you vote for change if status quo feels horrible?Somehow geopolitics came to discussion. Singapore will need to respond to whatever trump doesBut also, perhaps pap might worry too that the trump ideologies of nativism and such might take root here.\\n\\n\\nContributor786: 1. Singapore cannot rely fully on the US market and need to navigate ourselves out of the troubled water.2. We need to find other brighter spots for growth.\\nContributor1301: let me read the articles shared by admin.lets focus on the issue concerning us.\\nContributor786: 3. We should take care of our own locals but yet gracious enough to welcome foreign talents that value add to our growth as our tfr fall.\\nContributor234: We always known this. You can see we trade with all. However, the world is becoming more divisive. USA is starting to put teams of Us vs Them.Will singapore risk us chip restrictions by cozying up more to mainland china?\\n\\n\\nContributor2032: I wouldn\\'t complain about the past few years of budget, but I feel spending should be more conservative given the unstable geopolitics right now.Need to be prepared for a big emergency, possibly one that is more impactful and longer than the pandemic.\\nContributor234: Yeah we need focus on bread and butterFeels like a waste when we are building founders memorial or doing big fireworks for ndp\\n\\n\\nContributor234: Who says people are playing around with their votes. If you think people are \\'playing around\\' why even have a democracy? If gov is always right we can have the benevolent dictatorship.The gov serves the people. If the people are not satisfied, or dont think the gov is serving them, then what is the gov for. Yes we want the best minds, but can we trust the best minds to serve us? Thats why we vote. Not just on paper qualifications but their character too. We dont want corporate interests and conflict or corrupt politicians \\'serving\\' the nation.Just look at what they argue for. Do they talk down to citizens? Maybe think their school is superior? Perform intellectual dishonesty to their stakeholders? We need a govt that is not just smart, but responsible and accountable for its citizens. Sure they might not be perfect but at least take responsibility for mistakes and work to fix them instead of pretending things are ok\\n\\n\\nContributor715: I disagree with only nmp and ncmp as opposition I do agree to vote by people not by party. The party may be opposition but if the member of it is good why not elect him. One example is jamus. I find that he is a standard MP, giving good opposition voice.While some opposition only knows how to attack gov which I will not vote\\nContributor786: Jamus economic policies are flaw by a few count - and if implemented will harm us.He could be a good mp but a bad policy maker.\\nContributor715: I am not economist but I feel that there is an alternative voice which prompt gov to explain better their rationale and why they did not take up the suggestions.What gov bad in explaining their policyWe need more junior professionals in parliament to debate different solutions\\nContributor234: What say you about lawrance wong strategies while he was in mnd to prevent oversupply in hdb?Or the chairman of smrt not wanting to \\'overmaintain\\'Maybe they really are doing whats best for the countryIdk what this country is to them, but to those on the ground, they are out of touchMaybe what we need is them riding in trains, or trying to budget their meals and rentOfc the smartest in society wont face these issues\\n\\n\\nContributor715: Maybe they should try surviving with a monthly salary of 3000Working 9-5 in office ot to meet the people... EtcForce to attend parliament sessionIf not every time parliament looks empty\\nContributor234: Does parliament needs to be that big anyway?Why do we have so much mayors?\\n\\n\\nContributor715: Do we even need mayor\\nContributor1654: Don’t think so\\nContributor234: Also we have best minds in gov, but they are working part time job being directorsPoor thing need extra incomeI also nsf cannot work outsideWonder if they can fully commit to governance\\n\\n\\nContributor234: Copilot:In Singapore, mayors oversee the **Community Development Councils (CDCs)**, which are responsible for fostering community bonds and supporting residents within their respective districts.Tbh i havent really made good use of community resourcesI cant really bond with my neighbours either.  They change every 6 monthsThese are probably a start of discussion. Sure they may be flawed but you have pap to keep in check. They will not wholesale take it.What pap will do is take segments and make their own new policy that is similar so they can take credit. Overall singapore still benefits from oppo doing thisAnother issue is the current gov keeps a tight lip on its resources and reasons. Yeah it may be for harmony or national defence or whatever excuse but really how to counter them when all they argue is \\'father knows best\\'\\n\\n\\nContributor234: If we dont raise proposal until its perfect then when? In covid the gov has to make quick action. Sure its not perfect but there is choices to be made and the gov is looking at optionsNow perhaps it is \\'peace\" for you, but for many they are dissatisfiedIs the gov gonna MONITOR the situation?Maybe those who complain that hdb too expensive can wait patiently for gov to fix things in a decade then start a family in their 40sOr those that complain met not maintained enough can wait for new lines to come for redundancyThe oppo is not perfect, but at least they are trying to solve things. Maybe thats why they have supporters.Pap seems to pretend things are ok. Then if its not ok they try to deflect. Dunno if its dome internal culture to avoid getting fired\\n\\n\\nContributor244: Yeah.. we have seen since 2020, parliament and representation was ok despite so many vacant MP seats. If anything, total number of MPs should have stayed the same as 2020\\nContributor234: See the response of the nric issue. At least now they are acknowledging it ill give them that\\n\\n\\nContributor2132: https://www.straitstimes.com/multimedia/graphics/2025/03/singapore-general-election-ward/index.html?utm_medium=social&utm_source=telegram&utm_campaign=sttgmajor changes in both east and westapparently due to increase in voter numbers. wonder if the population growth in the redrawn regions were significant enough for all these changes 🤷\\u200d♀️\\nContributor244: This is true all the time, at every electionWe don\\'t need stability in the house, we need people who can best navigate the unknown without spending excessively. The 1G PAP were brilliant at navigating the unknown without excessive spending. The same can\\'t be said of this 4G PAP\\nContributor234: Yeah i heard this being repeated so much timesEvery year got something newCurrent gov did some good some badBuy sometimes the bad are so glaringly obvious, one wonders where were the check and balancesOr is the gov run by yes men who just do things blindly\\n\\n\\nContributor715: Actually for voting wise what people on ground looking at is bread and butter issue. Not too much of politics. Small things such as how fast faulty things get changed and repair impact votingFor example if your corridor light bulb faulty how fast they change your light bulb when you report it.Mine change within 2days but I heard from my friends 2 weeks they haven\\'t change yet in other constituency\\nContributor786: One service apps report - change within 2 days.\\nContributor715: It goes down all the way to RC chairman willing to fight for the residentsWilling to take extra mileFor example my RC every block have a WhatsApp groupI am proud\\nContributor234: Where is my whatsapp group😭Idk what my one is doing\\n\\n\\nContributor1293: Start one or volunteer at your RC.Same concept in work, if things not moving, might as well do it myself. Haha\\nContributor234: I got my own family to support where got time to volunteer [/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oYrn73KGtRT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745828853005,
          "user_tz": -480,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4c595014-9acd-4945-ebff-f9a32a9bfa08"
      },
      "id": "5oYrn73KGtRT",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1349, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_full_df_sampled = stratified_sample(augmented_full_df, 'stance', 'human_label', frac=0.30, random_state=42)\n",
        "augmented_full_df_sampled.shape"
      ],
      "metadata": {
        "id": "Ms43bpv7KshX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834039157,
          "user_tz": -480,
          "elapsed": 8383,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d23b242e-8055-4fea-ffc9-d2e05d295f1f"
      },
      "id": "Ms43bpv7KshX",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-89bc82edf383>:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(n=min(samples_per_group, len(x)), random_state=random_state))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9082, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stratified_test = test_data.copy().sample(frac=0.7)[[ 'stance', 'prompt', 'label']].reset_index(drop=True)\n",
        "stratified_test[\"prompt\"] = stratified_test[[\"prompt\", \"label\"]].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n",
        "print(stratified_test.prompt.loc[0][-20:])\n",
        "print(stratified_test.shape)\n",
        "list(stratified_test.prompt.values)[0][-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "lpG_kNEpAMLn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834039157,
          "user_tz": -480,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e51151cd-26a2-4fb1-c26b-2ff8be34db08"
      },
      "id": "lpG_kNEpAMLn",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nology. [/INST]0</s>\n",
            "(944, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-9683cd3b886e>:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  stratified_test[\"prompt\"] = stratified_test[[\"prompt\", \"label\"]].apply(lambda x: x[0] + str(x[1]) + \"</s>\", axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.concat([\n",
        "    train_data[['chat_group_id', 'label', 'stance', 'prompt', 'human_label', 'topic_group', 'agreement', 'user', 'group_user', 'topic']],\n",
        "    #augmented_full_df[['chat_group_id',  'stance', 'content', 'class', 'context', 'human_label']].rename({'class': 'label'}, axis=1),\n",
        "    augmented_full_df_sampled[[  'stance', 'prompt', 'label']],\n",
        "    stratified_test\n",
        "    ]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "#df = train_data[['chat_group_id', 'label', 'stance', 'prompt', 'human_label', 'topic_group', 'agreement', 'user', 'group_user', 'topic']].loc[:100]\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "3Fnp9nEo-NLc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834121038,
          "user_tz": -480,
          "elapsed": 783,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "432b6707-0463-4b77-b03c-8b6f5ee6a2f9"
      },
      "id": "3Fnp9nEo-NLc",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   chat_group_id  label                                             stance  \\\n",
              "0            1.0      0  Contributor shared different perspectives on p...   \n",
              "1            1.0      0  Contributor expressed differing levels of trus...   \n",
              "\n",
              "                                              prompt human_label  \\\n",
              "0  <s>[INST]Determine whether Contributor429 hold...  no opinion   \n",
              "1  <s>[INST]Determine whether Contributor429 hold...    disagree   \n",
              "\n",
              "    topic_group  agreement                                  user  \\\n",
              "0  national_day  unanimous  04195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "1  national_day   majority  04195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "\n",
              "                              group_user  \\\n",
              "0  104195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "1  104195570-f8b3-4eab-866f-32808d77d8e1   \n",
              "\n",
              "                                               topic  \n",
              "0  *📢 Topic 📢*\\nIn his National Day Message, Prim...  \n",
              "1  *📢 Topic 📢*\\nIn his National Day Message, Prim...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a3fbf96-03ae-4ec2-85cc-fd6ddc91a0de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chat_group_id</th>\n",
              "      <th>label</th>\n",
              "      <th>stance</th>\n",
              "      <th>prompt</th>\n",
              "      <th>human_label</th>\n",
              "      <th>topic_group</th>\n",
              "      <th>agreement</th>\n",
              "      <th>user</th>\n",
              "      <th>group_user</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contributor shared different perspectives on p...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor429 hold...</td>\n",
              "      <td>no opinion</td>\n",
              "      <td>national_day</td>\n",
              "      <td>unanimous</td>\n",
              "      <td>04195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>104195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>*📢 Topic 📢*\\nIn his National Day Message, Prim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contributor expressed differing levels of trus...</td>\n",
              "      <td>&lt;s&gt;[INST]Determine whether Contributor429 hold...</td>\n",
              "      <td>disagree</td>\n",
              "      <td>national_day</td>\n",
              "      <td>majority</td>\n",
              "      <td>04195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>104195570-f8b3-4eab-866f-32808d77d8e1</td>\n",
              "      <td>*📢 Topic 📢*\\nIn his National Day Message, Prim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a3fbf96-03ae-4ec2-85cc-fd6ddc91a0de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a3fbf96-03ae-4ec2-85cc-fd6ddc91a0de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a3fbf96-03ae-4ec2-85cc-fd6ddc91a0de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c928169-1ddf-4618-aa02-8d92ced0e23d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c928169-1ddf-4618-aa02-8d92ced0e23d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c928169-1ddf-4618-aa02-8d92ced0e23d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12466,\n  \"fields\": [\n    {\n      \"column\": \"chat_group_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9309924156889844,\n        \"min\": 1.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          7.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stance\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2734,\n        \"samples\": [\n          \"Contributors expressed concerns that the current housing policies are exacerbating the affordability crisis, calling for a reassessment of pricing mechanisms and increased transparency in public housing allocation.\",\n          \"Contributors highlighted the growing concern over housing affordability, urging the government to implement more robust measures to ensure that ordinary Singaporeans can access quality and reasonably priced housing in the face of escalating prices and demand in the property market.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12466,\n        \"samples\": [\n          \"<s>[INST]Determine whether Contributor958 holds the same view as this statement: 'Contributors raised alarms over the increasing prevalence of mental health issues among youth, urging the government to enhance accessible mental health services and preventative programs in schools to support emotional well-being.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 958 and other contributors: \\n Contributor424: While digital skills are important, we shouldnt overlook the value of nurturing critical thinking and creativity in students, which are also essential for adapting to the future.\\nContributor397: What about the importance of creativity and critical thinking in addition to technical skills?\\nContributor908: I remember when I learned to ride a bike; it wasn\\u2019t just about balance or pedaling\\u2014it was about understanding my surroundings and making decisions on the fly.\\nContributor199: Isnt it also worth considering the value of arts and humanities in fostering creativity and critical thinking, which are equally essential in this digital age?\\nContributor309: While coding is crucial, we must also consider that not every student may have an interest in tech-oriented careers; should we also emphasize creative thinking and problem-solving across other disciplines to cater to varied interests?\\nContributor428: But wouldnt it be interesting to consider how critical thinking and problem-solving skills, rather than just coding, could also play a vital role in helping students navigate future challenges, like adapting to different career paths?\\nContributor842: It seems that discussions often highlight how rental prices have escalated in areas like Bukit Merah, impacting younger families trying to settle down.  Additionally, there are concerns about public transport fares increasing while the frequency and quality of service remain a topic of debate among daily commuters.  On the flip side, some may argue that local brand products in supermarkets are still affordable compared to international brands, yet it raises questions about the perceived value for money.  Theres also the perspective that many Singaporeans still enjoy a high standard of living despite these challenges, as evidenced by the thriving local food scene and recreational activities available.  Furthermore, a focus on upskilling and lifelong learning could divert attention from wage growth, as some believe that having a diverse skill set might present better career opportunities.  Lastly, while many express dissatisfaction with current pay levels, it is interesting to note how certain industries, like tech and finance, continue to offer competitive salaries that attract talent.\\nContributor800: Aiyoh, but maybe we also should think about how we can all contribute to making our own lives better, instead of just waiting for policies, right?\\nContributor189: But what about the benefits from support programs?\\nContributor264: Perhaps its time we remember, It is not the strongest of the species that survive, nor the most intelligent, but the one most responsive to change, and adapt our perspectives on the evolving economic landscape.\\nContributor791: Its like trying to save for a holiday when prices keep rising, making it feel like the goal keeps moving further away.\\nContributor538: While I understand the concerns, could it also be beneficial to explore how enhancing skills and education could create more opportunities for higher-paying jobs, rather than solely focusing on government intervention?\\nContributor84: Perhaps we should also consider how promoting more local entrepreneurship could help offset some of these challenges.\\nContributor538: Perhaps we should also explore innovative solutions that empower citizens to manage their own finances better amidst these changes.\\nContributor398: It\\u2019s interesting to consider that while wages indeed seem stagnant, many industries are exploring automation and technology that could potentially reshape job markets and enhance productivity, which might influence wages in the long run.\\nContributor673: Isnt it said that the greatest danger in times of turbulence is not the turbulence; it is to act with yesterday\\u2019s logic? Perhaps we need to rethink our strategies to genuinely address these challenges.\\nContributor327: Have we considered how community initiatives could play a role in alleviating some of these challenges?\\nContributor971: Perhaps exploring alternative income streams or new industries could provide some relief for individuals struggling with their financial situations?\\nContributor185: Its interesting how many can actually benefit from government schemes like the CPF and various grants for housing. \\ud83e\\udd14\\nContributor785: Its interesting to consider how the rise of technology and automation might change the job market in the coming years and potentially influence wage structures.\\nContributor551: Theres a lot to be said about personal responsibility and making the most of the opportunities available to us here.\\nContributor264: Have you considered how some individuals are finding alternative ways to cope with the situation, such as exploring side gigs or community-sharing initiatives?\\nContributor791: While I understand the concerns about rising costs, it\\u2019s interesting to note that the government has been focusing on initiatives like the SkillsFuture program to help citizens upskill and potentially increase their earning power, which could help mitigate some of these issues.\\nContributor527: While addressing the rising cost of living is crucial, perhaps we should also consider how we can encourage personal financial literacy among citizens to help them manage their expenses better.\\nContributor175: Its interesting how, in my experience with budgeting, small lifestyle adjustments can sometimes help buffer against rising costs.\\nContributor751: I hear you, but I cant help but think that sometimes we also need to look at how our personal budgeting choices can play a role in managing the rising costs; like when I learned to cook at home instead of always dining out, it made a significant difference in my expenses.\\nContributor791: While wage growth is important, perhaps we should also explore ways to promote better financial literacy among citizens to help manage rising costs more effectively.\\nContributor590: But you also think more support for small businesses might help, right? They can contribute to better wages and job opportunities leh.\\nContributor809: Its crucial to consider how our spending habits might also play a role in navigating these challenges.\\nContributor657: I agree but feel parents should also play a bigger role in supporting mental health at home leh\\nContributor322: Focusing solely on increasing services might overlook other factors affecting youth, like academic pressure and family dynamics.\\nContributor503: Most youth handle their challenges just fine without extra programs, don\\u2019t you think?\\nContributor120: While mental health services are vital, we must also consider the role of community support and family involvement in nurturing emotional resilience from an early age.\\nContributor820: In my experience, it\\u2019s often through challenges that we develop resilience, much like how I learned to navigate life\\u2019s ups and downs without relying heavily on external support systems.\\nContributor102: Theres a saying, What doesnt kill you makes you stronger; perhaps we should focus on building resilience rather than simply increasing resources.\\nContributor639: Absolutely, but I wonder if theres also a need to focus on building resilience in students, alongside just providing services.While its crucial to improve mental health services in schools, we might also want to consider the role of parental involvement and how they can be supported in understanding and addressing their childrens emotional needs.\\nContributor13: Perhaps, as Oscar Wilde once said, What seems to us as bitter trials are often blessings in disguise. Maybe facing challenges could lead youth to develop resilience on their own.\\nContributor184: Perhaps its worth considering if enhancing digital platforms could also provide additional support for mental well-being among youth, especially in an increasingly online world.\\nContributor958: Perhaps we should consider that the only limit to our realization of tomorrow will be our doubts of today, suggesting that fostering resilience might also play a key role in addressing these concerns.\\n\\n\\nContributor113: Perhaps we should also consider the role of families in recognizing and addressing mental health issues early, as they are often the first line of support for young people.\\nContributor120: While it\\u2019s essential to have these programs in schools, we might also need to consider engaging parents in this dialogue for a more holistic approach to mental health.\\nContributor673: While mental health is an important topic, there are also many youths who thrive without needing additional support systems, suggesting that not all require the same level of intervention.\\nContributor540: But arent we overemphasizing mental health issues when many youths simply face typical life challenges that dont necessarily need intervention?\\nContributor958: Perhaps we should remember, An ounce of prevention is worth a pound of cure. [/INST]0</s>\",\n          \"<s>[INST]Determine whether Contributor672 holds the same view as this statement: 'Contributors expressed strong approval for the government's initiative to enhance job support programs for elderly workers, emphasizing the importance of integrating older citizens into the workforce to promote dignity and economic independence.\\u2019? Based on the following conversation summary, respond with \\u20181\\u2019 if they share the view, or \\u20180\\u2019 otherwise. Even if it is implicit, consider it a match. Do not include any additional text. The following are messages by contributor 672 and other contributors: \\n Contributor430: Sometimes, the more details we have, the more we drown in information\\u2014its been said, The more you know, the more you realize you dont know.\\nContributor472: Transparency is the key to empowerment, as Ralph Waldo Emerson said, The only person you are destined to become is the person you decide to be, which emphasizes that informed choices shape our healthcare journey.\\nContributor208: While its crucial to have transparency in the claims process, as George Orwell noted, In a time of deceit, telling the truth is a revolutionary act. We must also consider if transparency can sometimes lead to information overload, making decision-making more confusing rather than clearer for citizens.\\nContributor158: Its interesting how the focus on clarity in the claim process could also lead to a greater emphasis on preventive care options, helping citizens to not only understand their coverage but also to utilize it effectively for better health outcomes.\\nContributor900: Aiyoh, but sometimes too much info also confuse people lah, must find balance leh.\\nContributor605: While clearer communication is important, the complexities of healthcare and varying individual circumstances might actually lead to more confusion rather than empowerment for citizens.\\nContributor259: While clearer communication is certainly important, one might also consider the role of technological advancements in simplifying the claims process for everyone involved.\\nContributor113: It might be interesting to explore how technological advancements could streamline the claim process, potentially reducing the need for extensive manual transparency efforts.\\nContributor92: Sometimes too much transparency can lead to confusion rather than clarity.\\nContributor377: While clarity in coverage is crucial, one has to wonder if simplifying the claim process might inadvertently limit the options available to policyholders, possibly leading to oversimplification of complex healthcare scenarios.\\nContributor605: \\u201cBut less complexity can lead to quicker resolutions, rather than getting lost in endless details.\\u201d\\nContributor472: In addition to clearer communication, enhancing digital tools for easier tracking of claims could further aid citizens in navigating the MediShield Life system more effectively.Having a clear understanding of coverage details could also encourage more proactive discussions between patients and their healthcare providers, which might lead to better health outcomes.That\\u2019s true, but also, clearer guidelines can help healthcare providers navigate the claims process better, \\u8fd9\\u6837\\u53ef\\u4ee5\\u51cf\\u5c11\\u8bef\\u89e3\\u4e0e\\u5ef6\\u8bef\\u3002\\nContributor70: \\u6211\\u540c\\u610f\\u900f\\u660e\\u5ea6\\u91cd\\u8981\\uff0c\\u4f46\\u4e5f\\u8981\\u8003\\u8651\\u7535\\u5b50\\u5316\\u652f\\u4ed8\\u7684\\u4fbf\\u6377\\u6027\\uff0c\\u8fd9\\u6837\\u53ef\\u4ee5\\u8ba9\\u6211\\u4eec\\u66f4\\u5feb\\u5904\\u7406\\u7406\\u8d54\\uff0c\\u800c\\u4e0d\\u662f\\u4ec5\\u4ec5\\u4f9d\\u8d56\\u4e8e\\u4f20\\u7edf\\u7684\\u4ea4\\u6d41\\u65b9\\u5f0f\\u3002\\nContributor605: While clarity in the MediShield Life claim process is important, sometimes the complexities of healthcare can lead to valuable learnings and experiences that empower individuals in other ways, such as adapting to challenges and building resilience.\\nContributor446: What are some specific examples of essential goods that have seen significant price increases recently?, In discussions about housing, how do we see the impact of urban planning decisions on the overall housing market?, Have there been any government initiatives in the past that effectively addressed affordability issues?, How does the inflation rate in Singapore compare to other countries in the region?, What role do local businesses play in contributing to the cost of living, and how can they adjust in response?, Can we explore the relationship between wages and the rising cost of essential goods and housing?, How do international economic factors influence the local cost of living in Singapore?\\nContributor38: While I understand the concerns about affordability, I believe that the flourishing economy and job opportunities we have in Singapore actually provide a pathway for many individuals to enhance their financial stability on their own.\\nContributor317: Could exploring alternative living arrangements, like co-living spaces, provide a unique solution to tackle the housing affordability issue?\\nContributor38: Navigating the rising cost of living could also push individuals to find innovative solutions and explore alternative lifestyles that promote self-sufficiency and community support.\\nContributor554: While I understand the concerns about affordability, I often reflect on how the challenges of rising costs can also drive innovation and resourcefulness among Singaporeans.\\nContributor317: Perhaps we can view this situation through the lens of necessity is the mother of invention, and explore innovative solutions that can arise from these challenges.\\nContributor141: Opportunity seldom knocks on the door twice; perhaps we should focus on innovation and adaptability instead to navigate these challenges.\\nContributor41: Maybe more education on budgeting and financial literacy can help people manage their expenses better, leh?\\nContributor343: While enhancing affordability is crucial, I wonder if focusing too much on prices might overlook the importance of sustainable income growth for long-term stability.\\nContributor982: While enhancing affordability in housing is crucial, we might also consider how encouraging local businesses and markets can help keep prices in check and offer more options for everyone.\\nContributor611: Perhaps exploring innovative housing solutions could relieve some pressure on affordability.\\nContributor307: \\u4e5f\\u8bb8\\u6211\\u4eec\\u53ef\\u4ee5\\u8003\\u8651\\u4e00\\u4e0b\\uff0c\\u5982\\u4f55\\u901a\\u8fc7\\u63d0\\u5347\\u6280\\u80fd\\u548c\\u6559\\u80b2\\u6765\\u5e2e\\u52a9\\u4eba\\u4eec\\u521b\\u9020\\u66f4\\u591a\\u7684\\u6536\\u5165\\u6765\\u6e90\\u3002\\nContributor655: Have we considered how technological advancements and innovations could contribute to reducing costs in the long run?\\nContributor343: While I understand the concern for affordability, perhaps we should also consider the long-term sustainability of our economic growth and how technology could play a role in reducing costs for essential goods.\\nContributor987: While its important to consider affordability, we should also acknowledge how the high costs reflect the value of Singapores robust economy and the quality of services we enjoy.\\nContributor655: Its interesting to think about how other countries tackle similar issues, sometimes implementing unique solutions that could inspire different approaches here.\\nContributor549: Have we considered that rising costs could also be seen as a reflection of a thriving economy, where higher prices may indicate increased demand and growth, rather than just a reason for concern?I\\u2019ve actually found that adapting to the changing cost of living can lead to improved financial literacy and resourcefulness; its like learning to cook with what you have instead of relying on takeout.\\nContributor381: Its crucial that while we address the rising costs, we also consider the potential impact on economic growth and innovation that these measures could introduce.\\nContributor984: Wah, I totally agree! But must also think about the type of jobs for elderly workers lah. Not all jobs good for them ah, need to match skills and health okay?\\\\nMaybe more training or upskilling programs can help older folks to find suitable jobs leh.\\nContributor477: It\\u2019s interesting to consider how programs tailored to elderly workers might also encourage companies to explore flexible working arrangements that could benefit all employees.\\nContributor159: \\u6709\\u4e9b\\u4eba\\u53ef\\u80fd\\u8003\\u8651\\u5230\\u57f9\\u517b\\u5e74\\u8f7b\\u52b3\\u52a8\\u529b\\u7684\\u673a\\u4f1a\\uff0c\\u662f\\u5426\\u4f1a\\u5f71\\u54cd\\u5230\\u8001\\u5e74\\u5de5\\u4eba\\u7684\\u5de5\\u4f5c\\u652f\\u6301\\u8ba1\\u5212\\u5462\\uff1f\\nContributor601: But isn\\u2019t there a risk that pushing older workers into jobs could actually undervalue their rich life experiences?Its often said, The only way to do great work is to love what you do, yet we must consider if all elderly workers have the opportunity to find fulfilling roles that enrich their lives as they contribute to the economy.\\nContributor73: I wonder if focusing on improving skills and education for younger workers might actually yield better long-term results for our economy instead.\\nContributor672: Sometimes, its wiser to let the old ways be, as Socrates said, The unexamined life is not worth living\\u2014perhaps there are other avenues to explore for the elderly instead of conventional work. [/INST]0</s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"disagree\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"national_day\",\n          \"budget\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agreement\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"majority\",\n          \"unanimous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 229,\n        \"samples\": [\n          \"cb58a6f8-2604-4b8d-a0d9-b9718cc134af\",\n          \"5419fb94-a5af-46ee-b019-ee1e52cc006e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group_user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 234,\n        \"samples\": [\n          \"45419fb94-a5af-46ee-b019-ee1e52cc006e\",\n          \"20c58c1ab-6e81-406a-9609-21b23cad0f62\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\\u5927\\u5bb6\\u597d\\uff0c\\u6b22\\u8fce\\u56de\\u6765\\uff01 \\u4eca\\u5929\\u8ba8\\u8bba\\u7684\\u8bdd\\u9898\\u662f\\uff1a\\n\\n*\\u56fd\\u5e86\\u732e\\u8bcd*\\n\\n\\u653f\\u5e9c\\u5c06\\u8c03\\u6574\\u7ec4\\u5c4b\\u653f\\u7b56\\uff0c\\u786e\\u4fdd\\u653f\\u7b56\\u516c\\u5e73\\u548c\\u5305\\u5bb9\\uff0c\\u540c\\u65f6\\u5b8c\\u5584\\u516c\\u79ef\\u91d1\\u5236\\u5ea6\\uff0c\\u786e\\u4fdd\\u5e74\\u957f\\u4f1a\\u5458\\u6709\\u8db3\\u591f\\u516c\\u79ef\\u91d1\\u517b\\u8001\\u3002\\u674e\\u663e\\u9f99\\u603b\\u7406\\u4f1a\\u5728\\u56fd\\u5e86\\u7fa4\\u4f17\\u5927\\u4f1a\\u4e0a\\u8bf4\\u660e\\u653f\\u5e9c\\u7684\\u8ba1\\u5212\\u3002\\n\\n\\u8fc7\\u53bb\\u4e00\\u5e74\\uff0c\\u4f4f\\u623f\\u4f9b\\u5e94\\u548c\\u4ef7\\u683c\\u8d70\\u52bf\\u53d7\\u5230\\u65b0\\u52a0\\u5761\\u4eba\\u9ad8\\u5ea6\\u5173\\u6ce8\\u3002\\u674e\\u603b\\u7406\\u5728\\u661f\\u671f\\u4e8c\\uff088\\u67088\\u65e5\\uff09\\u53d1\\u8868\\u7684\\u56fd\\u5e86\\u732e\\u8bcd\\u4e2d\\uff0c\\u91cd\\u70b9\\u8c08\\u5230\\u4f4f\\u623f\\u8bfe\\u9898\\u3002\\u4ed6\\u91cd\\u7533\\uff0c\\u5373\\u4f7f\\u5927\\u73af\\u5883\\u4e0d\\u65ad\\u53d8\\u5316\\uff0c\\u653f\\u5e9c\\u4ecd\\u5fc5\\u987b\\u786e\\u4fdd\\u5404\\u4e2a\\u6536\\u5165\\u9636\\u5c42\\u7684\\u56fd\\u4eba\\uff0c\\u90fd\\u80fd\\u4e70\\u5f97\\u5230\\u548c\\u4e70\\u5f97\\u8d77\\u653f\\u5e9c\\u7ec4\\u5c4b\\u3002\\n\\n\\ud83d\\udcac *\\u60a8\\u5bf9\\u674e\\u603b\\u7406\\u7684\\u56fd\\u5e86\\u732e\\u8bcd\\u6709\\u4ec0\\u4e48\\u60f3\\u6cd5\\uff1f \\u653f\\u5e9c\\u8fd8\\u80fd\\u591f\\u901a\\u8fc7\\u54ea\\u4e9b\\u65b9\\u6cd5\\u6276\\u6301\\u8001\\u9f84\\u5316\\u7684\\u4eba\\u53e3\\uff0c\\u4ee5\\u53ca\\u786e\\u4fdd\\u516c\\u5171\\u4f4f\\u5c4b\\u653f\\u7b56\\u80fd\\u53cd\\u6620\\u6c11\\u95f4\\u7684\\u73b0\\u5b9e\\u60c5\\u51b5\\u548c\\u4eba\\u4eec\\u7684\\u671f\\u671b\\uff1f*\\n\\n\\ud83d\\udccc *\\u516c\\u5171\\u7ec4\\u5c4b*\\n\\u56fd\\u5bb6\\u53d1\\u5c55\\u90e8\\u957f\\u674e\\u667a\\u965e\\u53bb\\u5e74\\u5e95\\u63a5\\u53d7\\u5a92\\u4f53\\u8bbf\\u95ee\\u65f6\\u66fe\\u900f\\u9732\\uff0c\\u5f53\\u5c40\\u6b63\\u5728\\u63a2\\u8ba8\\u6709\\u5173\\u516c\\u5171\\u4f4f\\u5c4b\\u653f\\u7b56\\u7684\\u6570\\u9879\\u6539\\u9769\\uff0c\\u5305\\u62ec\\u6210\\u719f\\u548c\\u975e\\u6210\\u719f\\u5e02\\u9547\\u7684\\u5206\\u7c7b\\uff0c\\u800c\\u6311\\u6218\\u5728\\u4e8e\\u786e\\u4fdd\\u5206\\u7c7b\\u80fd\\u53cd\\u6620\\u6c11\\u95f4\\u7684\\u73b0\\u5b9e\\u60c5\\u51b5\\u548c\\u4eba\\u4eec\\u7684\\u671f\\u671b\\u3002\\u4ed6\\u5f53\\u65f6\\u8bf4\\uff0c\\u4e00\\u4e2a\\u53ef\\u80fd\\u7684\\u5206\\u7c7b\\u65b9\\u5f0f\\uff0c\\u662f\\u6839\\u636e\\u6bcf\\u4e2a\\u9879\\u76ee\\u7684\\u6761\\u4ef6\\u8fdb\\u884c\\u5206\\u7c7b\\uff0c\\u4f46\\u8fd9\\u6709\\u5f85\\u7814\\u7a76\\u3002\\n\\n\\ud83d\\udccc *\\u6276\\u6301\\u8001\\u9f84\\u5316\\u4eba\\u53e3*\\n\\u56fd\\u5e86\\u732e\\u8bcd\\u4e2d\\u805a\\u7126\\u7684\\u53e6\\u4e00\\u4e2a\\u8bfe\\u9898\\u662f\\u517b\\u8001\\u8bfe\\u9898\\u3002\\u674e\\u603b\\u7406\\u8bf4\\uff0c\\u653f\\u5e9c\\u9010\\u6b65\\u6539\\u5584\\u516c\\u79ef\\u91d1\\u5236\\u5ea6\\uff0c\\u786e\\u4fdd\\u65b0\\u52a0\\u5761\\u4eba\\u5728\\u5c31\\u4e1a\\u65f6\\u671f\\u6709\\u8db3\\u591f\\u7684\\u50a8\\u84c4\\uff0c\\u53e6\\u4e00\\u65b9\\u9762\\u4e5f\\u901a\\u8fc7\\u5c31\\u4e1a\\u5956\\u52b1\\u8ba1\\u5212\\u548c\\u6e10\\u8fdb\\u5f0f\\u85aa\\u91d1\\u6a21\\u5f0f\\u7b49\\u63aa\\u65bd\\uff0c\\u4e3a\\u4f4e\\u6536\\u5165\\u5458\\u5de5\\u63d0\\u4f9b\\u63f4\\u52a9\\u3002\\n\\n\\u674e\\u603b\\u7406\\u4e5f\\u8bf4\\uff0c\\u653f\\u5e9c\\u6b63\\u91c7\\u53d6\\u63aa\\u65bd\\uff0c\\u6253\\u9020\\u66f4\\u4eb2\\u4e50\\u9f84\\u7ec4\\u5c4b\\u548c\\u793e\\u533a\\uff0c\\u5305\\u62ec\\u5174\\u5efa\\u66f4\\u591a\\u4f11\\u606f\\u7ad9\\u3001\\u89c4\\u5212\\u66f4\\u591a\\u884c\\u4eba\\u4e13\\u7528\\u533a\\uff0c\\u4ee5\\u53ca\\u5b8c\\u5584\\u90bb\\u91cc\\u793e\\u533a\\u7a7a\\u95f4\\u7684\\u8bbe\\u8ba1\\uff0c\\u548c\\u5f00\\u8bbe\\u66f4\\u591a\\u6d3b\\u8dc3\\u4e50\\u9f84\\u4e2d\\u5fc3\\u3002\\n\\n\\ud83d\\udccc *\\u653f\\u5e9c\\u786e\\u4fdd\\u6211\\u56fd\\u5236\\u5ea6\\u7ef4\\u6301\\u5ec9\\u6d01\\u7684\\u51b3\\u5fc3*\\n\\u674e\\u603b\\u7406\\u8bf4\\uff0c\\u8fd1\\u671f\\u53d1\\u751f\\u7684\\u95ee\\u9898\\u65f6\\u4e0d\\u65f6\\u4f1a\\u51fa\\u73b0\\u3002\\u4ed6\\u5f3a\\u8c03\\uff0c\\u5f53\\u4e8b\\u4ef6\\u53d1\\u751f\\u65f6\\uff0c\\u653f\\u5e9c\\u4e00\\u76f4\\u90fd\\u4ee5\\u59a5\\u5f53\\u3001\\u516c\\u5f00\\u7684\\u65b9\\u5f0f\\u5904\\u7406\\uff0c\\u5728\\u8fd1\\u51e0\\u6b21\\u4e8b\\u4ef6\\u4e0a\\u4e5f\\u4e0d\\u4f8b\\u5916\\u3002\\n\\n\\u674e\\u603b\\u7406\\u8bf4\\uff0c\\u53ea\\u6709\\u81f4\\u529b\\u7ef4\\u6301\\u9ad8\\u6807\\u51c6\\uff0c\\u624d\\u80fd\\u7ef4\\u62a4\\u65b0\\u52a0\\u5761\\u4eba\\u5bf9\\u653f\\u5e9c\\u548c\\u56fd\\u5bb6\\u4f53\\u5236\\u7684\\u4fe1\\u5fc3\\uff0c\\u52a0\\u5f3a\\u6c11\\u4f17\\u5bf9\\u653f\\u5e9c\\u7684\\u4fe1\\u4efb\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u674e\\u603b\\u7406\\u56fd\\u5e86\\u732e\\u8bcd\\uff1a\\u8c03\\u6574\\u7ec4\\u5c4b\\u4e0e\\u516c\\u79ef\\u91d1\\u653f\\u7b56\\u786e\\u4fdd\\u516c\\u5e73\\u5305\\u5bb9\\u3011\\uff1a https://www.zaobao.com.sg/news/singapore/story20230809-1421915\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u674e\\u603b\\u7406\\uff1a\\u653f\\u5e9c\\u51b3\\u5fc3\\u786e\\u4fdd\\u6211\\u56fd\\u5236\\u5ea6\\u7ef4\\u6301\\u5ec9\\u6d01\\u6b63\\u76f4\\u6709\\u8bda\\u4fe1\\u3011\\uff1a https://www.zaobao.com.sg/news/singapore/story20230809-1421917\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u603b\\u7406\\u56fd\\u5e86\\u732e\\u8bcd - \\u4eba\\u6c11\\u548c\\u653f\\u5e9c\\u7d27\\u5bc6\\u5408\\u4f5c\\u662f\\u65b0\\u52a0\\u5761\\u4f18\\u52bf \\u5e94\\u597d\\u597d\\u5b88\\u62a4\\u3011\\nhttps://www.zaobao.com.sg/realtime/singapore/story20230808-1421820\\n\\n\\ud83d\\udc49\\ud83c\\udffc \\u3010\\u89c2\\u770b\\uff1a\\u7531\\u526f\\u603b\\u7406\\u9ec4\\u5faa\\u8d22\\u5ba3\\u8bfb\\u7684\\u56fd\\u5e86\\u732e\\u8bcd\\u3011\\uff1ahttps://www.pmo.gov.sg/Newsroom/National-Day-Message-2023-Chinese \\u200e<This message was edited>\",\n          \"\\u5927\\u5bb6\\u597d\\uff0c\\u6b22\\u8fce\\u56de\\u6765! \\u6211\\u4eec\\u5c06\\u5f00\\u653e\\u7fa4\\u804a\\u8fdb\\u884c\\u8ba8\\u8bba\\u81f3\\u508d\\u665a7\\u70b9\\u3002\\u4eca\\u5929\\u7684\\u8ba8\\u8bba\\u8bfe\\u9898\\u662f\\uff1a\\n\\n\\ud83d\\udcac2023 \\u5e74\\u9884\\u7b97\\u6848\\u4e2d\\u7684\\u54ea\\u4e9b\\u63aa\\u65bd\\u5f15\\u8d77\\u60a8\\u7684\\u5171\\u9e23\\uff1f\\n\\n\\ud83d\\udccc \\u7f13\\u901a\\u80c0\\uff1a\\u66f4\\u591a\\u8865\\u52a9\\u6e21\\u96be\\u5173\\n- \\u5f3a\\u5316\\u6c38\\u4e45\\u6027\\u6d88\\u8d39\\u7a0e\\u8865\\u52a9\\u5238\\uff08GSTV\\uff09\\u8ba1\\u5212\\uff0c\\u4ee5\\u7ee7\\u7eed\\u5e2e\\u52a9\\u7b26\\u5408\\u8d44\\u683c\\u7684\\u5bb6\\u5ead\\uff0c\\u5e94\\u4ed8\\u6d88\\u8d39\\u7a0e\\u3002\\n- \\u5728\\u5b9a\\u5fc3\\u4e0e\\u63f4\\u52a9\\u914d\\u5957\\uff08Assurance Package\\uff09\\u4e0b\\uff0c \\u7b26\\u5408\\u8d44\\u683c\\u7684\\u65b0\\u52a0\\u5761\\u4eba\\u63a5\\u4e0b\\u6765\\u53ef\\u83b7\\u5f97\\u7684\\u73b0\\u91d1\\u8865\\u52a9\\u5c06\\u589e\\u52a0\\u4ecb\\u4e8e300\\u5143\\u5230650\\u5143\\u3002\\u6b64\\u5916\\uff0c\\u653f\\u5e9c\\u660e\\u5e74\\u63d0\\u4f9b\\u7684\\u793e\\u533a\\u53d1\\u5c55\\u7406\\u4e8b\\u4f1a\\u90bb\\u91cc\\u8d2d\\u7269\\u5238\\u5c06\\u589e\\u52a0100\\u5143\\n- \\u6bcf\\u540d\\u7b26\\u5408\\u8d44\\u683c\\u7684\\u65b0\\u52a0\\u5761\\u4eba\\uff0c\\u5c06\\u53ef\\u83b7\\u5f97\\u4ecb\\u4e8e200\\u5143\\u5230400\\u5143\\u7684\\u751f\\u6d3b\\u8d39\\u7279\\u522b\\u8865\\u52a9 (Cost-of-Living Special Payment\\uff09\\u3002\\u7b26\\u5408\\u8d44\\u683c\\u768455\\u5c81\\u53ca\\u4ee5\\u4e0a\\u56fd\\u4eba\\uff0c\\u5219\\u53ef\\u989d\\u5916\\u83b7\\u5f97200\\u5143\\u5230300\\u5143\\u7684\\u6d25\\u8d34\\u3002\\n\\n\\ud83d\\udccc \\u5174\\u7ecf\\u6d4e\\uff1a\\u52a9\\u4f01\\u4e1a\\u521b\\u65b0\\u817e\\u98de \\uff0c\\u8ba9\\u5458\\u5de5\\u518d\\u57f9\\u8bad\\u529b\\u4e89\\u4e0a\\u6e38\\n- \\u57282023\\u5e74\\u7684\\u8d22\\u653f\\u9884\\u7b97\\u6848\\u4e2d\\uff0c\\u653f\\u5e9c\\u4e3a\\u5168\\u56fd\\u751f\\u4ea7\\u529b\\u57fa\\u91d1\\u6ce8\\u5165\\u8d44\\u91d1\\uff0c\\u4e5f\\u65b0\\u63a8\\u51fa\\u4f01\\u4e1a\\u521b\\u65b0\\u8ba1\\u5212\\uff0c\\u4ee5\\u534f\\u52a9\\u672c\\u5730\\u4f01\\u4e1a\\u53d6\\u5f97\\u8d44\\u91d1\\uff0c\\u5c55\\u5f00\\u66f4\\u591a\\u521b\\u65b0\\u6d3b\\u52a8\\u3002\\u9664\\u4e86\\u79ef\\u6781\\u9f13\\u52b1\\u4f01\\u4e1a\\u521b\\u65b0\\u4ee5\\u5916\\uff0c\\u653f\\u5e9c\\u4e5f\\u901a\\u8fc7\\u4e24\\u9879\\u62e8\\u6b3e\\u534f\\u52a9\\u672c\\u5730\\u4f01\\u4e1a\\u6269\\u5927\\u89c4\\u6a21\\uff0c\\u6253\\u9020\\u56fd\\u9645\\u7ade\\u4e89\\u529b\\u3002\\n- \\u4e3a\\u786e\\u4fdd\\u5458\\u5de5\\u7684\\u6280\\u80fd\\u66f4\\u8d34\\u8fd1\\u5e02\\u573a\\u7684\\u5b9e\\u9645\\u9700\\u6c42\\uff0c\\u653f\\u5e9c\\u5c06\\u6210\\u7acb\\u5c31\\u4e1a\\u4e0e\\u57f9\\u8bad\\u534f\\u8c03\\u5904\\uff0c\\u901a\\u8fc7\\u57f9\\u8bad\\u4e0e\\u884c\\u4e1a\\u7684\\u914d\\u5bf9\\uff0c\\u4e3a\\u4f01\\u4e1a\\u5458\\u5de5\\u5e26\\u6765\\u66f4\\u597d\\u7684\\u85aa\\u8d44\\u6536\\u5165\\u548c\\u5c31\\u4e1a\\u524d\\u666f\\u3002\\n- \\u4e3a\\u4f4e\\u85aa\\u5de5\\u53cb\\uff0c\\u5e74\\u957f\\u8005\\uff0c\\u6b8b\\u75be\\u4eba\\u58eb\\u4e0e\\u524d\\u56da\\u72af\\u63d0\\u4f9b\\u5c31\\u4e1a\\u5e2e\\u52a9\\n\\n\\ud83d\\udccc \\u52a0\\u5f3a\\u793e\\u4f1a\\u5951\\u7ea6\\n- \\u5e2e\\u52a9\\u56fd\\u4eba\\u8fbe\\u6210\\u8d2d\\u5c4b\\u7406\\u60f3\\uff1a \\u4e3a40\\u5c81\\u53ca\\u4ee5\\u4e0b\\u5e74\\u8f7b\\u592b\\u5987\\u53ca\\u6709\\u5b69\\u5b50\\u7684\\u9996\\u8d2d\\u5bb6\\u5ead\\u63d0\\u4f9b\\u7533\\u8d2d\\u9996\\u4e2a\\u9884\\u8d2d\\u7ec4\\u5c4b\\u7684\\u989d\\u5916\\u62bd\\u7b7e\\u673a\\u4f1a\\u3002\\u5728\\u516c\\u79ef\\u91d1\\u8d2d\\u5c4b\\u6d25\\u8d34\\u4e0b\\uff0c\\u9996\\u6b21\\u8d2d\\u5c4b\\u5bb6\\u5ead\\u4e70\\u8f6c\\u552e\\u7ec4\\u5c4b\\uff0c\\u516c\\u79ef\\u91d1\\u8d2d\\u5c4b\\u6d25\\u8d34\\u589e\\u52a0\\u591a\\u8fbe3\\u4e07\\u5143\\u3002\\n- \\u9f13\\u52b1\\u56fd\\u4eba\\u751f\\u80b2\\uff1a \\u63d0\\u9ad8\\u5a74\\u513f\\u82b1\\u7ea2\\u53ca\\u513f\\u7ae5\\u57f9\\u80b2\\u6237\\u5934\\u586b\\u8865\\uff0c\\u63d0\\u4f9b\\u80b2\\u513f\\u8865\\u8d34\\u5e76\\u589e\\u52a0\\u966a\\u4ea7\\u5047\\u548c\\u80b2\\u5a74\\u5047\\n- \\u5e2e\\u52a9\\u4f4e\\u85aa\\u5bb6\\u5ead\\uff1a\\u901a\\u8fc7\\u793e\\u533a\\u8054\\u7cfb\\u7ad9\\uff08ComLink)\\uff0c\\u8fdb\\u4e00\\u6b65\\u878d\\u5408\\u653f\\u5e9c\\u4e3a\\u8f83\\u4f4e\\u6536\\u5165\\u5bb6\\u5ead\\u6240\\u63a8\\u51fa\\u7684\\u4e0d\\u540c\\u8ba1\\u5212\\u7684\\u76f8\\u540c\\u529f\\u80fd\\uff0c\\u586b\\u8865\\u5173\\u6000\\u57fa\\u91d1\\uff08ComCare Endowment Fund\\uff09\\u4e0e\\u6269\\u5927\\u5e7c\\u513f\\u57f9\\u80b2\\u8f85\\u52a9\\u8ba1\\u5212\\uff08KidSTART\\uff09\\n-\\u5e2e\\u52a9\\u5e74\\u957f\\u8005\\uff1a\\u4e3a\\u8001\\u4eba\\u62a4\\u7406\\u57fa\\u91d1\\uff08ElderCare Fund\\uff09\\u586b\\u88655\\u4ebf\\u5143\\uff0c\\u4fdd\\u5065\\u57fa\\u91d1\\uff08MediFund\\uff09\\u586b\\u886515\\u4ebf\\u5143\\n-\\u5e2e\\u52a9\\u5e73\\u53f0\\u5458\\u5de5\\uff1a \\u5f3a\\u5316\\u4f4e\\u85aa\\u5e73\\u53f0\\u4eba\\u5458\\u7684\\u9000\\u4f11\\u4fdd\\u969c\\uff0c\\u63a8\\u51fa\\u516c\\u79ef\\u91d1\\u8fc7\\u6e21\\u63f4\\u52a9\\u8ba1\\u5212\\uff0c\\u4ee5\\u51cf\\u8f7b\\u4ed6\\u4eec\\u65e5\\u540e\\u7f34\\u7eb3\\u516c\\u79ef\\u91d1\\u7684\\u8d1f\\u62c5\\n\\n\\u76f8\\u5173\\u62a5\\u9053\\uff1a\\n\\ud83d\\udc49\\ud83c\\udffb \\u4e00\\u6587\\u638c\\u63e12023\\u5e74\\u8d22\\u653f\\u9884\\u7b97\\u6848\\u8981\\u70b9\\nhttps://www.zaobao.com.sg/news/singapore/story20230214-1363163\\n\\n\\ud83d\\udc49\\ud83c\\udffb\\u3010\\u61d2\\u4eba\\u5305\\u3011\\u4f60\\u9700\\u8981\\u77e5\\u9053\\u7684\\u4e5d\\u9879\\u8d22\\u653f\\u9884\\u7b97\\u6848\\u5ba3\\u5e03\\nhttps://www.8world.com/singapore/budget2023-things-you-need-to-know-2054706\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def mistral_to_chat(entry):\n",
        "    entry = entry.strip()\n",
        "\n",
        "    # Check if entry starts with <s>[INST] and ends with </s>\n",
        "    if not entry.startswith(\"<s>[INST]\") or not entry.endswith(\"</s>\"):\n",
        "        print(\"Skipped (bad format):\", entry)\n",
        "        return None\n",
        "\n",
        "    messages = []\n",
        "    while True:\n",
        "        # Look for the next [INST] ... [/INST] ... </s> block\n",
        "        inst_start = entry.find(\"[INST]\")\n",
        "        inst_end = entry.find(\"[/INST]\")\n",
        "        s_end = entry.find(\"</s>\", inst_end)\n",
        "\n",
        "        if inst_start == -1 or inst_end == -1 or s_end == -1:\n",
        "            break\n",
        "\n",
        "        instruction = entry[inst_start + len(\"[INST]\"):inst_end].strip()\n",
        "        output = entry[inst_end + len(\"[/INST]\"):s_end].strip()\n",
        "\n",
        "        if instruction:\n",
        "            messages.append({\"role\": \"user\", \"content\": instruction})\n",
        "        if output:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": output})\n",
        "\n",
        "        # Move to the next segment\n",
        "        entry = entry[s_end + len(\"</s>\"):].strip()\n",
        "\n",
        "    if not messages:\n",
        "        return None\n",
        "\n",
        "    return {\"messages\": messages}\n",
        "\n",
        "\n",
        "def convert_list_to_jsonl(entries, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "        for entry in entries:\n",
        "            chat_format = mistral_to_chat(entry)\n",
        "            if chat_format:\n",
        "                json.dump(chat_format, outfile, ensure_ascii=False)\n",
        "                outfile.write(\"\\n\")\n",
        "train_prompts = list(df.prompt.values)\n",
        "\n",
        "convert_list_to_jsonl(train_prompts, \"train_data.jsonl\")\n"
      ],
      "metadata": {
        "id": "G4KZdSEfGK6N",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834123679,
          "user_tz": -480,
          "elapsed": 2098,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "G4KZdSEfGK6N",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "'''\n",
        "\n",
        "def save_prompts_to_jsonl(df, output_file):\n",
        "    \"\"\"\n",
        "    Save the 'prompt' column of a DataFrame to a JSONL file.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame containing the 'prompt' column.\n",
        "        output_file (str): The path to the output .jsonl file.\n",
        "    \"\"\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for prompt in df[\"prompt\"]:\n",
        "            json_line = json.dumps({\"prompt\": prompt}, ensure_ascii=False)\n",
        "            f.write(json_line + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "train_fp = \"/content/train_data.jsonl\"\n",
        "save_prompts_to_jsonl(df, train_fp)\n",
        "val_fp = \"/content/val_data.jsonl\"\n",
        "save_prompts_to_jsonl(vali_data, val_fp)\n",
        "\n",
        "def mistral_to_alpaca(entry):\n",
        "    # Strip any leading/trailing whitespace\n",
        "    entry = entry.strip()\n",
        "\n",
        "    # Find the position of the [INST] and [/INST] tags\n",
        "    inst_start = entry.find(\"[INST]\") + len(\"[INST]\")\n",
        "    inst_end = entry.find(\"[/INST]\")\n",
        "\n",
        "    # Find the position of <s> and </s> tags\n",
        "    s_start = entry.find(\"<s>\") + len(\"<s>\")\n",
        "    s_end = entry.find(\"</s>\")\n",
        "\n",
        "    if inst_start != -1 and inst_end != -1 and s_start != -1 and s_end != -1:\n",
        "        # Extract the instruction and output, without the tags\n",
        "        instruction = entry[inst_start:inst_end].strip()\n",
        "        output = entry[inst_end:s_end].strip()  # Output is between [/INST] and </s>\n",
        "\n",
        "        # Clean the instruction and output by removing the surrounding tags\n",
        "        instruction = instruction.replace('[INST]', '').replace('[/INST]', '').replace('<s>', '').replace('</s>', '').strip()\n",
        "        output = output.replace('<s>', '').replace('</s>', '').replace('[INST]', '').replace('[/INST]', '').strip()\n",
        "        if len(output) ==0:\n",
        "            print(output)\n",
        "        return {\n",
        "            \"instruction\": instruction,\n",
        "            \"output\": output\n",
        "        }\n",
        "    print(entry)\n",
        "    return None\n",
        "\n",
        "\n",
        "def mistral_to_alpaca(entry):\n",
        "    # Strip any leading/trailing whitespace\n",
        "    entry = entry.strip()\n",
        "\n",
        "    # Find the position of the [INST] and [/INST] tags\n",
        "    inst_start = entry.find(\"[INST]\") + len(\"[INST]\")\n",
        "    inst_end = entry.find(\"[/INST]\")\n",
        "\n",
        "    # Find the position of <s> and </s> tags\n",
        "    s_start = entry.find(\"<s>\") + len(\"<s>\")\n",
        "    s_end = entry.find(\"</s>\")\n",
        "\n",
        "    if inst_start != -1 and inst_end != -1 and s_start != -1 and s_end != -1:\n",
        "        # Extract the instruction and output, without the tags\n",
        "        instruction = entry[inst_start:inst_end].strip()\n",
        "        output = entry[inst_end:s_end].strip()  # Output is between [/INST] and </s>\n",
        "\n",
        "        # Clean the instruction and output by removing the surrounding tags\n",
        "        instruction = instruction.replace('[INST]', '').replace('[/INST]', '').replace('<s>', '').replace('</s>', '').strip()\n",
        "        output = output.replace('<s>', '').replace('</s>', '').replace('[INST]', '').replace('[/INST]', '').strip()\n",
        "\n",
        "        # Prepare the output in the required chat template format\n",
        "        return [\n",
        "            {\"role\": \"user\", \"content\": instruction},\n",
        "            {\"role\": \"assistant\", \"content\": output},\n",
        "        ]\n",
        "    print(entry)\n",
        "    return None\n",
        "def save_to_jsonl(train_prompts, output_file='train_data.jsonl'):\n",
        "    train_data = []\n",
        "    for entry in train_prompts:\n",
        "        alpaca = mistral_to_alpaca(entry)\n",
        "        if alpaca:\n",
        "            train_data.append(alpaca)\n",
        "\n",
        "    # Write each entry in train_data as a separate JSON object on a new line\n",
        "    with open(output_file, 'w') as f:\n",
        "        for entry in train_data:\n",
        "            f.write(json.dumps(entry) + '\\n')  # Ensuring each entry is written as an object on a new line\n",
        "train_prompts = list(df.prompt.values)\n",
        "val_prompts = list(vali_data.prompt.values)\n",
        "\n",
        "save_to_jsonl(train_prompts, \"/content/train_data.jsonl\")\n",
        "save_to_jsonl(val_prompts, \"/content/val_data.jsonl\")\n",
        "'''\n",
        "\n",
        "# # Format train data into a variable first\n",
        "# train_data = []\n",
        "# for entry in train_prompts:\n",
        "#     alpaca = mistral_to_alpaca(entry)\n",
        "#     if alpaca:\n",
        "#         train_data.append(alpaca)\n",
        "\n",
        "# # Save train data as JSONL\n",
        "# with open(\"/content/train_data.jsonl\", \"w\") as f:\n",
        "#     for entry in train_data:\n",
        "#         f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# # Format validation data into a variable first\n",
        "# val_data = []\n",
        "# for entry in val_prompts:\n",
        "#     alpaca = mistral_to_alpaca(entry)\n",
        "#     if alpaca:\n",
        "#         val_data.append(alpaca)\n",
        "\n",
        "\n",
        "# # Save validation data as JSONL\n",
        "# with open(\"/content/val_data.jsonl\", \"w\") as f:\n",
        "#     for entry in val_data:\n",
        "#         f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pZ_0_KBgS4kj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834123679,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "eb347978-8cae-4b6c-cc0f-6f5973b77e6c"
      },
      "id": "pZ_0_KBgS4kj",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\ndef save_prompts_to_jsonl(df, output_file):\\n    \"\"\"\\n    Save the \\'prompt\\' column of a DataFrame to a JSONL file.\\n\\n    Args:\\n        df (pd.DataFrame): The DataFrame containing the \\'prompt\\' column.\\n        output_file (str): The path to the output .jsonl file.\\n    \"\"\"\\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\\n        for prompt in df[\"prompt\"]:\\n            json_line = json.dumps({\"prompt\": prompt}, ensure_ascii=False)\\n            f.write(json_line + \"\\n\")\\n\\n\\n\\ntrain_fp = \"/content/train_data.jsonl\"\\nsave_prompts_to_jsonl(df, train_fp)\\nval_fp = \"/content/val_data.jsonl\"\\nsave_prompts_to_jsonl(vali_data, val_fp)\\n\\ndef mistral_to_alpaca(entry):\\n    # Strip any leading/trailing whitespace\\n    entry = entry.strip()\\n\\n    # Find the position of the [INST] and [/INST] tags\\n    inst_start = entry.find(\"[INST]\") + len(\"[INST]\")\\n    inst_end = entry.find(\"[/INST]\")\\n\\n    # Find the position of <s> and </s> tags\\n    s_start = entry.find(\"<s>\") + len(\"<s>\")\\n    s_end = entry.find(\"</s>\")\\n\\n    if inst_start != -1 and inst_end != -1 and s_start != -1 and s_end != -1:\\n        # Extract the instruction and output, without the tags\\n        instruction = entry[inst_start:inst_end].strip()\\n        output = entry[inst_end:s_end].strip()  # Output is between [/INST] and </s>\\n\\n        # Clean the instruction and output by removing the surrounding tags\\n        instruction = instruction.replace(\\'[INST]\\', \\'\\').replace(\\'[/INST]\\', \\'\\').replace(\\'<s>\\', \\'\\').replace(\\'</s>\\', \\'\\').strip()\\n        output = output.replace(\\'<s>\\', \\'\\').replace(\\'</s>\\', \\'\\').replace(\\'[INST]\\', \\'\\').replace(\\'[/INST]\\', \\'\\').strip()\\n        if len(output) ==0:\\n            print(output)\\n        return {\\n            \"instruction\": instruction,\\n            \"output\": output\\n        }\\n    print(entry)\\n    return None\\n\\n\\ndef mistral_to_alpaca(entry):\\n    # Strip any leading/trailing whitespace\\n    entry = entry.strip()\\n\\n    # Find the position of the [INST] and [/INST] tags\\n    inst_start = entry.find(\"[INST]\") + len(\"[INST]\")\\n    inst_end = entry.find(\"[/INST]\")\\n\\n    # Find the position of <s> and </s> tags\\n    s_start = entry.find(\"<s>\") + len(\"<s>\")\\n    s_end = entry.find(\"</s>\")\\n\\n    if inst_start != -1 and inst_end != -1 and s_start != -1 and s_end != -1:\\n        # Extract the instruction and output, without the tags\\n        instruction = entry[inst_start:inst_end].strip()\\n        output = entry[inst_end:s_end].strip()  # Output is between [/INST] and </s>\\n\\n        # Clean the instruction and output by removing the surrounding tags\\n        instruction = instruction.replace(\\'[INST]\\', \\'\\').replace(\\'[/INST]\\', \\'\\').replace(\\'<s>\\', \\'\\').replace(\\'</s>\\', \\'\\').strip()\\n        output = output.replace(\\'<s>\\', \\'\\').replace(\\'</s>\\', \\'\\').replace(\\'[INST]\\', \\'\\').replace(\\'[/INST]\\', \\'\\').strip()\\n\\n        # Prepare the output in the required chat template format\\n        return [\\n            {\"role\": \"user\", \"content\": instruction},\\n            {\"role\": \"assistant\", \"content\": output},\\n        ]\\n    print(entry)\\n    return None\\ndef save_to_jsonl(train_prompts, output_file=\\'train_data.jsonl\\'):\\n    train_data = []\\n    for entry in train_prompts:\\n        alpaca = mistral_to_alpaca(entry)\\n        if alpaca:\\n            train_data.append(alpaca)\\n\\n    # Write each entry in train_data as a separate JSON object on a new line\\n    with open(output_file, \\'w\\') as f:\\n        for entry in train_data:\\n            f.write(json.dumps(entry) + \\'\\n\\')  # Ensuring each entry is written as an object on a new line\\ntrain_prompts = list(df.prompt.values)\\nval_prompts = list(vali_data.prompt.values)\\n\\nsave_to_jsonl(train_prompts, \"/content/train_data.jsonl\")\\nsave_to_jsonl(val_prompts, \"/content/val_data.jsonl\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "df.prompt.str.len().describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "RuZ97KwCg5WJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829317185,
          "user_tz": -480,
          "elapsed": 83,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "30894dab-b466-4be2-94d7-6ff2d979d039"
      },
      "id": "RuZ97KwCg5WJ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     4723.000000\n",
              "mean      5521.282448\n",
              "std       3876.896382\n",
              "min        518.000000\n",
              "25%       2020.000000\n",
              "50%       2944.000000\n",
              "75%       8551.000000\n",
              "max      17635.000000\n",
              "Name: prompt, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4723.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5521.282448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3876.896382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>518.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2020.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2944.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8551.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17635.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning"
      ],
      "metadata": {
        "id": "WZSdZnrxEw3p"
      },
      "id": "WZSdZnrxEw3p"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/config.yml\n",
        "# File: /content/config.yml\n",
        "\n",
        "base_model: mistralai/Mistral-7B-Instruct-v0.2\n",
        "\n",
        "datasets:\n",
        "  - path: /content/train_data.jsonl\n",
        "    ds_type: json\n",
        "    type: chat_template\n",
        "    chat_template: tokenizer_default\n",
        "    field_messages: messages\n",
        "    message_property_mappings:\n",
        "      role: role\n",
        "      content: content\n",
        "    roles:\n",
        "      user: [\"user\"]\n",
        "      assistant: [\"assistant\"]\n",
        "    drop_system_message: true\n",
        "    roles_to_train: [\"assistant\"]\n",
        "    data_files:\n",
        "      - /content/train_data.jsonl\n",
        "\n",
        "# test_datasets:\n",
        "#   - path: /content/val_data.jsonl\n",
        "#     ds_type: json\n",
        "#     type:\n",
        "#       type: chat_template\n",
        "#       chat_template: tokenizer_default\n",
        "#     data_files:\n",
        "#       - /content/val_data.jsonl\n",
        "#     split: train\n",
        "\n",
        "dataset_processes: 1\n",
        "\n",
        "# Output\n",
        "output_dir: /content/mistral-output\n",
        "\n",
        "# LoRA config\n",
        "adapter: lora\n",
        "lora_r: 8\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.1\n",
        "lora_target_modules:\n",
        "  - q_proj\n",
        "  - k_proj\n",
        "  - v_proj\n",
        "  #- o_proj\n",
        "  #- gate_proj\n",
        "  #- up_proj\n",
        "  #- down_proj\n",
        "lora_modules_to_save:\n",
        "  - embed_tokens\n",
        "  - lm_head\n",
        "is_mistral_derived_model: true\n",
        "\n",
        "# Format\n",
        "model_type: AutoModelForCausalLM\n",
        "tokenizer_type: AutoTokenizer\n",
        "sequence_len: 8192\n",
        "pad_to_sequence_len: true\n",
        "#load_in_8bit: true\n",
        "load_in_4bit: true\n",
        "\n",
        "flash_attention: true\n",
        "sequence_parallel_degree: 2\n",
        "device_map: sequential\n",
        "\n",
        "# Training\n",
        "num_epochs: 1\n",
        "micro_batch_size: 1\n",
        "gradient_accumulation_steps: 8\n",
        "\n",
        "# Optimization\n",
        "learning_rate: 2e-4\n",
        "lr_scheduler_type: cosine\n",
        "#weight_decay: 0.001\n",
        "\n",
        "#Validation\n",
        "# evaluation_strategy: steps\n",
        "# #early_stopping_patience: 3\n",
        "# do_causal_lm_eval: false\n",
        "# eval_causal_lm_metrics:\n",
        "#   - sacrebleu\n",
        "#   - ter\n",
        "#   - perplexity\n",
        "# eval_sample_packing: false\n",
        "# eval_max_new_tokens: 9\n",
        "# eval_batch_size: 1\n",
        "# eval_steps: 1000\n",
        "# logging_steps: 1000\n",
        "\n",
        "save_steps: 200\n",
        "\n",
        "# Precision\n",
        "bf16: true\n",
        "\n",
        "# Trainer\n",
        "trainer: AxolotlTrainer\n",
        "\n",
        "# DeepSpeed\n",
        "#deepspeed: /content/ds_config_zero3.json\n",
        "\n",
        "# Wandb\n",
        "wandb_mode: online\n",
        "wandb_project: reach-fine-tuning\n",
        "wandb_name: v15\n",
        "wandb_run_id: v15\n",
        "wandb_log_model: end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptuqu3Z4tdTH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834143374,
          "user_tz": -480,
          "elapsed": 76,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1188c4b6-aa12-4afe-bf37-2f3b686297ac"
      },
      "id": "ptuqu3Z4tdTH",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/config.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ds_config_zero3.json\n",
        "{\n",
        "  \"train_batch_size\": 16,\n",
        "  \"train_micro_batch_size_per_gpu\": 1,\n",
        "  \"gradient_accumulation_steps\": 8,\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 3,\n",
        "    \"offload_optimizer\": {\n",
        "      \"device\": \"cpu\"\n",
        "    },\n",
        "    \"offload_param\": {\n",
        "      \"device\": \"cpu\"\n",
        "    },\n",
        "    \"overlap_comm\": true,\n",
        "    \"contiguous_gradients\": true\n",
        "  },\n",
        "  \"bf16\": {\n",
        "    \"enabled\": true\n",
        "  },\n",
        "  \"steps_per_print\": 100,\n",
        "  \"wall_clock_breakdown\": false\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OqO_cSQ_82t",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834144969,
          "user_tz": -480,
          "elapsed": 65,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4215caab-e454-4940-9dfc-63547b903506"
      },
      "id": "6OqO_cSQ_82t",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/ds_config_zero3.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a tensor and move it to GPU\n",
        "x = torch.randn(1, 1, device='cuda')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Ensure a GPU is installed and configured.\")\n",
        "\n",
        "# Check the available and total memory on the GPU\n",
        "allocated_memory = torch.cuda.memory_allocated()  # Memory currently in use\n",
        "reserved_memory = torch.cuda.memory_reserved()  # Memory reserved by the allocator\n",
        "free_memory = torch.cuda.memory_reserved() - torch.cuda.memory_allocated()  # Free memory\n",
        "\n",
        "print(f\"Allocated Memory: {allocated_memory / 1024 ** 2:.2f} MB\")\n",
        "print(f\"Reserved Memory: {reserved_memory / 1024 ** 2:.2f} MB\")\n",
        "print(f\"Free Memory: {free_memory / 1024 ** 2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qnuH39rY_zZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834148726,
          "user_tz": -480,
          "elapsed": 87,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f8f14898-0c59-43e2-a77a-58822a76247d"
      },
      "id": "8qnuH39rY_zZ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available! Using GPU: NVIDIA A100-SXM4-40GB\n",
            "Allocated Memory: 794.82 MB\n",
            "Reserved Memory: 1186.00 MB\n",
            "Free Memory: 391.18 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Now, import PyTorch\n",
        "import torch\n",
        "\n",
        "# You can now use PyTorch as usual\n",
        "print(torch.cuda.is_available())  # Check if CUDA is available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PS3xk-u6vBq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744781035254,
          "user_tz": -480,
          "elapsed": 1899,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c5673d14-852b-4928-f07b-35d3354a3891"
      },
      "id": "9PS3xk-u6vBq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "10aa1e394e664ebfb26e1dd249eb6c72",
            "86358fd54f724bb886fbbd80e04bfcb4",
            "61f74e459d444e8da5703a555d447c1d",
            "b6c8e2a6c8874f3b8b0d3c0f4667cb1c",
            "2a95eeb444c34fdfb6883444a2f5db49",
            "8012e553c2ac4c55997085b2ec6f8986",
            "e561b146a4b04a6a8632757b7951c608",
            "24e43f9e59364847bbbc20d3f9af1550",
            "0822820fb77d456c96978828c9f2d8d6",
            "6b0cacfc393c421d95eec5905908b5b7",
            "d4d20b4d8d4147839263187732ab7355",
            "58c2e9445e7c470f9c258a7121417a3f",
            "32369ea1f8af4d108fbd79bd7acd229e",
            "c38fbe45e2fe4a2bbbb55e4733358c91",
            "2529865dfa3142ceb6fc8dad3be579ee",
            "d5fcb45521134a559ed1e0e5ca959516",
            "13b6663f5c314d85a0cf6772d03c517e",
            "ed01d668f6ba459d9e6bfc0bd3412141",
            "7c9463a8b6044694aefa9872efdc4d8a",
            "adfc6c613d034c0db8a419aa0480d3a4"
          ]
        },
        "id": "HBiY8TDlHmOf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829326056,
          "user_tz": -480,
          "elapsed": 141,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "38039905-9703-43c0-8761-7aa6ff1360c0"
      },
      "id": "HBiY8TDlHmOf",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10aa1e394e664ebfb26e1dd249eb6c72"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "Qa1X_FXEneAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745829335339,
          "user_tz": -480,
          "elapsed": 2796,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "99b51a61-69bd-44f1-baa4-49176614d437"
      },
      "id": "Qa1X_FXEneAl",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilson_ng\u001b[0m (\u001b[33mwilson_ng-govtech\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi nvlink --status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMALLhm6HZEq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1744513637153,
          "user_tz": -480,
          "elapsed": 136,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "063c32d0-3851-4eb3-a152-4dabdf3aed6e"
      },
      "id": "EMALLhm6HZEq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-a82dd269-9d2e-6d13-818f-001427bc2793)\n",
            "\t Link 0: 25 GB/s\n",
            "\t Link 1: 25 GB/s\n",
            "\t Link 2: 25 GB/s\n",
            "\t Link 3: 25 GB/s\n",
            "\t Link 4: 25 GB/s\n",
            "\t Link 5: 25 GB/s\n",
            "\t Link 6: 25 GB/s\n",
            "\t Link 7: 25 GB/s\n",
            "\t Link 8: 25 GB/s\n",
            "\t Link 9: 25 GB/s\n",
            "\t Link 10: 25 GB/s\n",
            "\t Link 11: 25 GB/s\n",
            "GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-d14257b2-2da5-0825-6052-9757a3ba708b)\n",
            "\t Link 0: 25 GB/s\n",
            "\t Link 1: 25 GB/s\n",
            "\t Link 2: 25 GB/s\n",
            "\t Link 3: 25 GB/s\n",
            "\t Link 4: 25 GB/s\n",
            "\t Link 5: 25 GB/s\n",
            "\t Link 6: 25 GB/s\n",
            "\t Link 7: 25 GB/s\n",
            "\t Link 8: 25 GB/s\n",
            "\t Link 9: 25 GB/s\n",
            "\t Link 10: 25 GB/s\n",
            "\t Link 11: 25 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export NCCL_P2P_LEVEL=NVL"
      ],
      "metadata": {
        "id": "BzoRw4W4HfYv"
      },
      "id": "BzoRw4W4HfYv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/mistral-output*\n",
        "!rm -rf /content/wandb*\n",
        "!rm -rf /content/last_run_prepared*"
      ],
      "metadata": {
        "id": "3jBXfsASO1Tz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745834154106,
          "user_tz": -480,
          "elapsed": 795,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "3jBXfsASO1Tz",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists('/content/train_data.jsonl'))  # Should return True\n",
        "print(os.path.exists('/content/val_data.jsonl'))    # Should return True\n",
        "print(os.path.exists('/content/ds_config_zero3.json'))\n",
        "print(os.path.exists('/content/config.yml'))"
      ],
      "metadata": {
        "id": "ov1NBu3uib49"
      },
      "id": "ov1NBu3uib49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch --multi_gpu -m axolotl.cli.train /content/config.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buX2T5j6uBOY",
        "outputId": "6ff35cef-7885-42f3-9473-b28196a35565",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745841804533,
          "user_tz": -480,
          "elapsed": 7647623,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "buX2T5j6uBOY",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:accelerate.commands.launch:The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `4`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-04-28 09:56:07.156743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-28 09:56:07.178139: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-28 09:56:07.184641: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-28 09:56:07.225305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-28 09:56:07.245743: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-28 09:56:07.251915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-28 09:56:07.267469: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-28 09:56:07.284506: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-28 09:56:07.288042: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-28 09:56:07.294273: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-28 09:56:07.304857: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-28 09:56:07.311020: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-28 09:56:08.487425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-04-28 09:56:08.512872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-04-28 09:56:08.548532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-04-28 09:56:08.571600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2025-04-28 09:56:10,125] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-28 09:56:10,136] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-28 09:56:10,155] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-28 09:56:10,183] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-04-28 09:56:10,213] [INFO] [root.spawn:38] [PID:33906] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp78lmqasz/test.c -o /tmp/tmp78lmqasz/test.o\n",
            "[2025-04-28 09:56:10,225] [INFO] [root.spawn:38] [PID:33907] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp5v7ndk8i/test.c -o /tmp/tmp5v7ndk8i/test.o\n",
            "[2025-04-28 09:56:10,232] [INFO] [root.spawn:38] [PID:33906] x86_64-linux-gnu-gcc /tmp/tmp78lmqasz/test.o -laio -o /tmp/tmp78lmqasz/a.out\n",
            "[2025-04-28 09:56:10,243] [INFO] [root.spawn:38] [PID:33905] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp4orsyyj8/test.c -o /tmp/tmp4orsyyj8/test.o\n",
            "[2025-04-28 09:56:10,243] [INFO] [root.spawn:38] [PID:33907] x86_64-linux-gnu-gcc /tmp/tmp5v7ndk8i/test.o -laio -o /tmp/tmp5v7ndk8i/a.out\n",
            "[2025-04-28 09:56:10,260] [INFO] [root.spawn:38] [PID:33905] x86_64-linux-gnu-gcc /tmp/tmp4orsyyj8/test.o -laio -o /tmp/tmp4orsyyj8/a.out\n",
            "[2025-04-28 09:56:10,272] [INFO] [root.spawn:38] [PID:33908] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp5phv3zth/test.c -o /tmp/tmp5phv3zth/test.o\n",
            "[2025-04-28 09:56:10,289] [INFO] [root.spawn:38] [PID:33908] x86_64-linux-gnu-gcc /tmp/tmp5phv3zth/test.o -laio -o /tmp/tmp5phv3zth/a.out\n",
            "[2025-04-28 09:56:10,834] [INFO] [root.spawn:38] [PID:33906] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpv9005ram/test.c -o /tmp/tmpv9005ram/test.o\n",
            "[2025-04-28 09:56:10,852] [INFO] [root.spawn:38] [PID:33906] x86_64-linux-gnu-gcc /tmp/tmpv9005ram/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpv9005ram/a.out\n",
            "[2025-04-28 09:56:10,860] [INFO] [root.spawn:38] [PID:33907] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp3ompoulk/test.c -o /tmp/tmp3ompoulk/test.o\n",
            "[2025-04-28 09:56:10,864] [INFO] [root.spawn:38] [PID:33905] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpzlvfukpl/test.c -o /tmp/tmpzlvfukpl/test.o\n",
            "[2025-04-28 09:56:10,878] [INFO] [root.spawn:38] [PID:33907] x86_64-linux-gnu-gcc /tmp/tmp3ompoulk/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp3ompoulk/a.out\n",
            "[2025-04-28 09:56:10,881] [INFO] [root.spawn:38] [PID:33905] x86_64-linux-gnu-gcc /tmp/tmpzlvfukpl/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpzlvfukpl/a.out\n",
            "[2025-04-28 09:56:10,893] [INFO] [root.spawn:38] [PID:33908] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpxgni756a/test.c -o /tmp/tmpxgni756a/test.o\n",
            "[2025-04-28 09:56:10,902] [INFO] [root.spawn:38] [PID:33906] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmplpdqh6au/test.c -o /tmp/tmplpdqh6au/test.o\n",
            "[2025-04-28 09:56:10,911] [INFO] [root.spawn:38] [PID:33908] x86_64-linux-gnu-gcc /tmp/tmpxgni756a/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpxgni756a/a.out\n",
            "[2025-04-28 09:56:10,919] [INFO] [root.spawn:38] [PID:33906] x86_64-linux-gnu-gcc /tmp/tmplpdqh6au/test.o -laio -o /tmp/tmplpdqh6au/a.out\n",
            "[2025-04-28 09:56:10,928] [INFO] [root.spawn:38] [PID:33907] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp5gpzvapq/test.c -o /tmp/tmp5gpzvapq/test.o\n",
            "[2025-04-28 09:56:10,931] [INFO] [root.spawn:38] [PID:33905] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp3d4bygfu/test.c -o /tmp/tmp3d4bygfu/test.o\n",
            "[2025-04-28 09:56:10,945] [INFO] [root.spawn:38] [PID:33907] x86_64-linux-gnu-gcc /tmp/tmp5gpzvapq/test.o -laio -o /tmp/tmp5gpzvapq/a.out\n",
            "[2025-04-28 09:56:10,949] [INFO] [root.spawn:38] [PID:33905] x86_64-linux-gnu-gcc /tmp/tmp3d4bygfu/test.o -laio -o /tmp/tmp3d4bygfu/a.out\n",
            "[2025-04-28 09:56:10,960] [INFO] [root.spawn:38] [PID:33908] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpixd67k0m/test.c -o /tmp/tmpixd67k0m/test.o\n",
            "[2025-04-28 09:56:10,978] [INFO] [root.spawn:38] [PID:33908] x86_64-linux-gnu-gcc /tmp/tmpixd67k0m/test.o -laio -o /tmp/tmpixd67k0m/a.out\n",
            "[2025-04-28 09:56:12,473] [INFO] [datasets.<module>:54] [PID:33906] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-28 09:56:12,474] [INFO] [datasets.<module>:66] [PID:33906] Polars version 1.9.0 available.\n",
            "[2025-04-28 09:56:12,476] [INFO] [datasets.<module>:77] [PID:33906] Duckdb version 1.1.3 available.\n",
            "[2025-04-28 09:56:12,476] [INFO] [datasets.<module>:112] [PID:33906] TensorFlow version 2.17.1 available.\n",
            "[2025-04-28 09:56:12,477] [INFO] [datasets.<module>:125] [PID:33906] JAX version 0.4.33 available.\n",
            "[2025-04-28 09:56:12,513] [INFO] [datasets.<module>:54] [PID:33905] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-28 09:56:12,514] [INFO] [datasets.<module>:66] [PID:33905] Polars version 1.9.0 available.\n",
            "[2025-04-28 09:56:12,515] [INFO] [datasets.<module>:77] [PID:33905] Duckdb version 1.1.3 available.\n",
            "[2025-04-28 09:56:12,516] [INFO] [datasets.<module>:112] [PID:33905] TensorFlow version 2.17.1 available.\n",
            "[2025-04-28 09:56:12,517] [INFO] [datasets.<module>:125] [PID:33905] JAX version 0.4.33 available.\n",
            "[2025-04-28 09:56:12,575] [INFO] [datasets.<module>:54] [PID:33907] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-28 09:56:12,576] [INFO] [datasets.<module>:66] [PID:33907] Polars version 1.9.0 available.\n",
            "[2025-04-28 09:56:12,578] [INFO] [datasets.<module>:77] [PID:33907] Duckdb version 1.1.3 available.\n",
            "[2025-04-28 09:56:12,578] [INFO] [datasets.<module>:112] [PID:33907] TensorFlow version 2.17.1 available.\n",
            "[2025-04-28 09:56:12,579] [INFO] [datasets.<module>:125] [PID:33907] JAX version 0.4.33 available.\n",
            "[2025-04-28 09:56:12,592] [INFO] [datasets.<module>:54] [PID:33908] PyTorch version 2.5.1+cu121 available.\n",
            "[2025-04-28 09:56:12,593] [INFO] [datasets.<module>:66] [PID:33908] Polars version 1.9.0 available.\n",
            "[2025-04-28 09:56:12,595] [INFO] [datasets.<module>:77] [PID:33908] Duckdb version 1.1.3 available.\n",
            "[2025-04-28 09:56:12,596] [INFO] [datasets.<module>:112] [PID:33908] TensorFlow version 2.17.1 available.\n",
            "[2025-04-28 09:56:12,596] [INFO] [datasets.<module>:125] [PID:33908] JAX version 0.4.33 available.\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "\u001b[33m[2025-04-28 09:56:14,259] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:33906] [RANK:1] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:14,259] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:33906] [RANK:1] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:14,283] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:33905] [RANK:0] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:14,284] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:33905] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:14,347] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:33907] [RANK:2] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:14,347] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:33907] [RANK:2] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:14,368] [WARNING] [axolotl.utils.schemas.config.check_sequence_parallel_degree:1179] [PID:33908] [RANK:3] Sequence parallelism (SP) is enabled with sequence_parallel_degree=2. Please note that logged losses may differ slightly to the non-SP losses due to transformers Trainer implementation details. Please see https://github.com/axolotl-ai-cloud/axolotl/pull/2495#issuecomment-2784022042 for more details.\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:14,368] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:843] [PID:33908] [RANK:3] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "[2025-04-28 09:56:14,606] [INFO] [axolotl.normalize_config:237] [PID:33906] [RANK:1] cuda memory usage baseline: 0.000GB (+2.874GB misc)\u001b[39m\n",
            "[2025-04-28 09:56:14,641] [INFO] [axolotl.normalize_config:237] [PID:33905] [RANK:0] cuda memory usage baseline: 0.000GB (+2.169GB misc)\u001b[39m\n",
            "[2025-04-28 09:56:14,684] [INFO] [axolotl.normalize_config:237] [PID:33907] [RANK:2] cuda memory usage baseline: 0.000GB (+2.878GB misc)\u001b[39m\n",
            "[2025-04-28 09:56:14,703] [INFO] [axolotl.normalize_config:237] [PID:33908] [RANK:3] cuda memory usage baseline: 0.000GB (+3.001GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "[2025-04-28 09:56:15,557] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:33906] [RANK:1] EOS: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,557] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:33906] [RANK:1] BOS: 1 / <s>\u001b[39m\n",
            "[2025-04-28 09:56:15,557] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:33906] [RANK:1] PAD: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,557] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:33906] [RANK:1] UNK: 0 / <unk>\u001b[39m\n",
            "[2025-04-28 09:56:15,557] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33906] [RANK:1] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[rank1]:[W428 09:56:15.187442589 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "[2025-04-28 09:56:15,583] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:33905] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,583] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:33905] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2025-04-28 09:56:15,583] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:33905] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,583] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:33905] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2025-04-28 09:56:15,583] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33905] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-28 09:56:15,583] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:33905] [RANK:0] Unable to find prepared dataset in last_run_prepared/1df8ddb663bed104d4ce338c7a97028f\u001b[39m\n",
            "[2025-04-28 09:56:15,583] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:33905] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2025-04-28 09:56:15,583] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:33905] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2025-04-28 09:56:15,584] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:33905] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-04-28 09:56:15,616] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:33908] [RANK:3] EOS: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,616] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:33908] [RANK:3] BOS: 1 / <s>\u001b[39m\n",
            "[2025-04-28 09:56:15,617] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:33908] [RANK:3] PAD: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,617] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:33908] [RANK:3] UNK: 0 / <unk>\u001b[39m\n",
            "[2025-04-28 09:56:15,617] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33908] [RANK:3] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[rank3]:[W428 09:56:15.246833632 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "[2025-04-28 09:56:15,619] [DEBUG] [axolotl.utils.models.load_tokenizer:445] [PID:33907] [RANK:2] EOS: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,619] [DEBUG] [axolotl.utils.models.load_tokenizer:446] [PID:33907] [RANK:2] BOS: 1 / <s>\u001b[39m\n",
            "[2025-04-28 09:56:15,619] [DEBUG] [axolotl.utils.models.load_tokenizer:447] [PID:33907] [RANK:2] PAD: 2 / </s>\u001b[39m\n",
            "[2025-04-28 09:56:15,619] [DEBUG] [axolotl.utils.models.load_tokenizer:448] [PID:33907] [RANK:2] UNK: 0 / <unk>\u001b[39m\n",
            "[2025-04-28 09:56:15,619] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33907] [RANK:2] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[rank2]:[W428 09:56:15.249031038 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "Generating train split: 12466 examples [00:00, 22799.44 examples/s]\n",
            "[2025-04-28 09:56:16,848] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:33905] [RANK:0] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-28 09:56:16,856] [INFO] [axolotl.__call__:577] [PID:33905] [RANK:0] Using chat template:\n",
            "---\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set loop_messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set loop_messages = messages %}\n",
            "{%- endif %}\n",
            "\n",
            "{{- bos_token }}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n",
            "        {{- raise_exception('After the optional system message, conversation roles must alternate user/assistant/user/assistant/...') }}\n",
            "    {%- endif %}\n",
            "    {%- if message['role'] == 'user' %}\n",
            "        {%- if loop.first and system_message is defined %}\n",
            "            {{- ' [INST] ' + system_message + '\\n\\n' + message['content'] + ' [/INST]' }}\n",
            "        {%- else %}\n",
            "            {{- ' [INST] ' + message['content'] + ' [/INST]' }}\n",
            "        {%- endif %}\n",
            "    {%- elif message['role'] == 'assistant' %}\n",
            "        {{- ' ' + message['content'] + eos_token}}\n",
            "    {%- else %}\n",
            "        {{- raise_exception('Only user and assistant roles are supported, with the exception of an initial optional system message!') }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts: 100% 12466/12466 [03:54<00:00, 53.16 examples/s]\n",
            "[2025-04-28 10:00:11,451] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:33905] [RANK:0] min_input_len: 129\u001b[39m\n",
            "[2025-04-28 10:00:11,451] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:33905] [RANK:0] max_input_len: 6634\u001b[39m\n",
            "Dropping Long Sequences: 100% 12466/12466 [00:08<00:00, 1419.45 examples/s]\n",
            "[2025-04-28 10:00:20,365] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:333] [PID:33905] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/1df8ddb663bed104d4ce338c7a97028f\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 12466/12466 [00:00<00:00, 15600.68 examples/s]\n",
            "[rank0]:[W428 10:00:21.948265934 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:33907] [RANK:2] Unable to find prepared dataset in last_run_prepared/1df8ddb663bed104d4ce338c7a97028f\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:33906] [RANK:1] Unable to find prepared dataset in last_run_prepared/1df8ddb663bed104d4ce338c7a97028f\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:253] [PID:33908] [RANK:3] Unable to find prepared dataset in last_run_prepared/1df8ddb663bed104d4ce338c7a97028f\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:33907] [RANK:2] Loading raw datasets...\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:33906] [RANK:1] Loading raw datasets...\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:254] [PID:33908] [RANK:3] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2025-04-28 10:00:22,129] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:33906] [RANK:1] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "\u001b[33m[2025-04-28 10:00:22,129] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:33907] [RANK:2] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "\u001b[33m[2025-04-28 10:00:22,129] [WARNING] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:256] [PID:33908] [RANK:3] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:33906] [RANK:1] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:33907] [RANK:2] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-04-28 10:00:22,129] [INFO] [axolotl.utils.data.sft.load_tokenized_prepared_datasets:263] [PID:33908] [RANK:3] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-04-28 10:00:22,831] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:33906] [RANK:1] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-28 10:00:22,835] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:33907] [RANK:2] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-28 10:00:22,839] [INFO] [axolotl.utils.data.sft.get_dataset_wrapper:459] [PID:33908] [RANK:3] Loading dataset with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-04-28 10:00:22,840] [INFO] [axolotl.__call__:577] [PID:33906] [RANK:1] Using chat template:\n",
            "---\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set loop_messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set loop_messages = messages %}\n",
            "{%- endif %}\n",
            "\n",
            "{{- bos_token }}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n",
            "        {{- raise_exception('After the optional system message, conversation roles must alternate user/assistant/user/assistant/...') }}\n",
            "    {%- endif %}\n",
            "    {%- if message['role'] == 'user' %}\n",
            "        {%- if loop.first and system_message is defined %}\n",
            "            {{- ' [INST] ' + system_message + '\\n\\n' + message['content'] + ' [/INST]' }}\n",
            "        {%- else %}\n",
            "            {{- ' [INST] ' + message['content'] + ' [/INST]' }}\n",
            "        {%- endif %}\n",
            "    {%- elif message['role'] == 'assistant' %}\n",
            "        {{- ' ' + message['content'] + eos_token}}\n",
            "    {%- else %}\n",
            "        {{- raise_exception('Only user and assistant roles are supported, with the exception of an initial optional system message!') }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "---\u001b[39m\n",
            "[2025-04-28 10:00:22,844] [INFO] [axolotl.__call__:577] [PID:33907] [RANK:2] Using chat template:\n",
            "---\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set loop_messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set loop_messages = messages %}\n",
            "{%- endif %}\n",
            "\n",
            "{{- bos_token }}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n",
            "        {{- raise_exception('After the optional system message, conversation roles must alternate user/assistant/user/assistant/...') }}\n",
            "    {%- endif %}\n",
            "    {%- if message['role'] == 'user' %}\n",
            "        {%- if loop.first and system_message is defined %}\n",
            "            {{- ' [INST] ' + system_message + '\\n\\n' + message['content'] + ' [/INST]' }}\n",
            "        {%- else %}\n",
            "            {{- ' [INST] ' + message['content'] + ' [/INST]' }}\n",
            "        {%- endif %}\n",
            "    {%- elif message['role'] == 'assistant' %}\n",
            "        {{- ' ' + message['content'] + eos_token}}\n",
            "    {%- else %}\n",
            "        {{- raise_exception('Only user and assistant roles are supported, with the exception of an initial optional system message!') }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "---\u001b[39m\n",
            "[2025-04-28 10:00:22,848] [INFO] [axolotl.__call__:577] [PID:33908] [RANK:3] Using chat template:\n",
            "---\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set loop_messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set loop_messages = messages %}\n",
            "{%- endif %}\n",
            "\n",
            "{{- bos_token }}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n",
            "        {{- raise_exception('After the optional system message, conversation roles must alternate user/assistant/user/assistant/...') }}\n",
            "    {%- endif %}\n",
            "    {%- if message['role'] == 'user' %}\n",
            "        {%- if loop.first and system_message is defined %}\n",
            "            {{- ' [INST] ' + system_message + '\\n\\n' + message['content'] + ' [/INST]' }}\n",
            "        {%- else %}\n",
            "            {{- ' [INST] ' + message['content'] + ' [/INST]' }}\n",
            "        {%- endif %}\n",
            "    {%- elif message['role'] == 'assistant' %}\n",
            "        {{- ' ' + message['content'] + eos_token}}\n",
            "    {%- else %}\n",
            "        {{- raise_exception('Only user and assistant roles are supported, with the exception of an initial optional system message!') }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "---\u001b[39m\n",
            "[2025-04-28 10:00:22,959] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:33906] [RANK:1] min_input_len: 129\u001b[39m\n",
            "[2025-04-28 10:00:22,959] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:33906] [RANK:1] max_input_len: 6634\u001b[39m\n",
            "[2025-04-28 10:00:22,962] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:33907] [RANK:2] min_input_len: 129\u001b[39m\n",
            "[2025-04-28 10:00:22,962] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:33907] [RANK:2] max_input_len: 6634\u001b[39m\n",
            "[2025-04-28 10:00:22,969] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:33908] [RANK:3] min_input_len: 129\u001b[39m\n",
            "[2025-04-28 10:00:22,969] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:33908] [RANK:3] max_input_len: 6634\u001b[39m\n",
            "[2025-04-28 10:00:23,214] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33905] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-28 10:00:23,461] [INFO] [axolotl.monkeypatch.attention.ring_attn.register_ring_attn:56] [PID:33905] [RANK:0] Enabling ring attention sequence parallelism: each sequence will be processed across 2 GPUs\u001b[39m\n",
            "[2025-04-28 10:00:23,462] [INFO] [axolotl.monkeypatch.attention.ring_attn.register_ring_attn:93] [PID:33905] [RANK:0] Sequence parallel group assignments: {0: 0, 1: 0, 2: 1, 3: 1}\u001b[39m\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s][2025-04-28 10:00:24,235] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33908] [RANK:3] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-28 10:00:24,278] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33906] [RANK:1] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-04-28 10:00:24,288] [INFO] [axolotl.utils.models.load_tokenizer:462] [PID:33907] [RANK:2] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100% 3/3 [00:18<00:00,  6.15s/it]\n",
            "[2025-04-28 10:00:42,426] [INFO] [axolotl.utils.models.load_model:1292] [PID:33905] [RANK:0] cuda memory usage after model load: 4.165GB (+0.222GB cache, +3.643GB misc)\u001b[39m\n",
            "[2025-04-28 10:00:42,434] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:33905] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-28 10:00:42,436] [INFO] [axolotl.utils.models.load_model:1328] [PID:33905] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
            "trainable params: 266,862,592 || all params: 7,508,594,688 || trainable%: 3.5541\n",
            "[2025-04-28 10:00:42,631] [INFO] [axolotl.utils.models.load_model:1387] [PID:33905] [RANK:0] cuda memory usage after adapters: 4.671GB (+0.710GB cache, +3.643GB misc)\u001b[39m\n",
            "Loading checkpoint shards: 100% 3/3 [00:18<00:00,  6.09s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:18<00:00,  6.10s/it]\n",
            "[2025-04-28 10:00:43,321] [INFO] [axolotl.utils.models.load_model:1292] [PID:33906] [RANK:1] cuda memory usage after model load: 4.165GB (+0.222GB cache, +4.488GB misc)\u001b[39m\n",
            "[2025-04-28 10:00:43,330] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:33906] [RANK:1] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-28 10:00:43,330] [INFO] [axolotl.utils.models.load_model:1292] [PID:33907] [RANK:2] cuda memory usage after model load: 4.165GB (+0.222GB cache, +4.492GB misc)\u001b[39m\n",
            "[2025-04-28 10:00:43,332] [INFO] [axolotl.utils.models.load_model:1328] [PID:33906] [RANK:1] Converting modules to torch.bfloat16\u001b[39m\n",
            "[2025-04-28 10:00:43,339] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:33907] [RANK:2] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-28 10:00:43,341] [INFO] [axolotl.utils.models.load_model:1328] [PID:33907] [RANK:2] Converting modules to torch.bfloat16\u001b[39m\n",
            "Loading checkpoint shards: 100% 3/3 [00:18<00:00,  6.21s/it]\n",
            "[2025-04-28 10:00:43,690] [INFO] [axolotl.utils.models.load_model:1292] [PID:33908] [RANK:3] cuda memory usage after model load: 4.165GB (+0.222GB cache, +4.475GB misc)\u001b[39m\n",
            "[2025-04-28 10:00:43,699] [INFO] [axolotl.utils.models.prepare_model:1196] [PID:33908] [RANK:3] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-04-28 10:00:43,701] [INFO] [axolotl.utils.models.load_model:1328] [PID:33908] [RANK:3] Converting modules to torch.bfloat16\u001b[39m\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "[2025-04-28 10:00:43,860] [INFO] [axolotl.train.save_initial_configs:339] [PID:33905] [RANK:0] Pre-saving adapter config to /content/mistral-output...\u001b[39m\n",
            "[2025-04-28 10:00:43,860] [INFO] [axolotl.train.save_initial_configs:343] [PID:33905] [RANK:0] Pre-saving tokenizer to /content/mistral-output...\u001b[39m\n",
            "[2025-04-28 10:00:43,893] [INFO] [axolotl.train.save_initial_configs:346] [PID:33905] [RANK:0] Pre-saving model config to /content/mistral-output...\u001b[39m\n",
            "[2025-04-28 10:00:43,895] [INFO] [axolotl.train.execute_training:183] [PID:33905] [RANK:0] Starting trainer...\u001b[39m\n",
            "[2025-04-28 10:00:43,912] [INFO] [axolotl.utils.models.load_model:1387] [PID:33906] [RANK:1] cuda memory usage after adapters: 4.671GB (+0.710GB cache, +4.488GB misc)\u001b[39m\n",
            "[2025-04-28 10:00:43,922] [INFO] [axolotl.utils.models.load_model:1387] [PID:33907] [RANK:2] cuda memory usage after adapters: 4.671GB (+0.710GB cache, +4.492GB misc)\u001b[39m\n",
            "[2025-04-28 10:00:44,307] [INFO] [axolotl.utils.models.load_model:1387] [PID:33908] [RANK:3] cuda memory usage after adapters: 4.671GB (+0.710GB cache, +4.475GB misc)\u001b[39m\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainers/base.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilson_ng\u001b[0m (\u001b[33mwilson_ng-govtech\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250428_100046-v15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mv15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/wilson_ng-govtech/reach-fine-tuning\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/wilson_ng-govtech/reach-fine-tuning/runs/v15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "[2025-04-28 10:00:48,341] [INFO] [axolotl.callbacks.on_train_begin:811] [PID:33905] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
            "  0% 0/779 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "  0% 1/779 [00:09<2:08:39,  9.92s/it][2025-04-28 10:01:07,511] [INFO] [axolotl.callbacks.on_step_end:127] [PID:33908] [RANK:3] cuda memory usage while training: 6.205GB (+24.465GB cache, +5.221GB misc)\u001b[39m\n",
            "[2025-04-28 10:01:07,511] [INFO] [axolotl.callbacks.on_step_end:127] [PID:33906] [RANK:1] cuda memory usage while training: 6.205GB (+24.496GB cache, +5.235GB misc)\u001b[39m\n",
            "[2025-04-28 10:01:07,511] [INFO] [axolotl.callbacks.on_step_end:127] [PID:33905] [RANK:0] cuda memory usage while training: 6.205GB (+24.496GB cache, +4.389GB misc)\u001b[39m\n",
            "[2025-04-28 10:01:07,511] [INFO] [axolotl.callbacks.on_step_end:127] [PID:33907] [RANK:2] cuda memory usage while training: 6.205GB (+24.465GB cache, +5.238GB misc)\u001b[39m\n",
            "{'loss': 4.3278, 'grad_norm': 690.1953125, 'learning_rate': 1.739130434782609e-05, 'epoch': 0.0}\n",
            "{'loss': 2.7733, 'grad_norm': 236.89016723632812, 'learning_rate': 4.347826086956522e-05, 'epoch': 0.01}\n",
            "{'loss': 1.0674, 'grad_norm': 165.34364318847656, 'learning_rate': 6.956521739130436e-05, 'epoch': 0.01}\n",
            "{'loss': 0.2762, 'grad_norm': 31.747840881347656, 'learning_rate': 9.565217391304348e-05, 'epoch': 0.02}\n",
            "{'loss': 0.1846, 'grad_norm': 26.132537841796875, 'learning_rate': 0.00012173913043478263, 'epoch': 0.02}\n",
            "{'loss': 0.1098, 'grad_norm': 1.3064725399017334, 'learning_rate': 0.00014782608695652173, 'epoch': 0.02}\n",
            "{'loss': 0.1968, 'grad_norm': 72.86775970458984, 'learning_rate': 0.00017391304347826088, 'epoch': 0.03}\n",
            "{'loss': 0.3544, 'grad_norm': 55.15218734741211, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.0906, 'grad_norm': 7.617434024810791, 'learning_rate': 0.0001999922292480975, 'epoch': 0.03}\n",
            "{'loss': 0.1474, 'grad_norm': 35.10520553588867, 'learning_rate': 0.00019996891820008164, 'epoch': 0.04}\n",
            "{'loss': 0.1345, 'grad_norm': 8.935674667358398, 'learning_rate': 0.00019993007047883988, 'epoch': 0.04}\n",
            "{'loss': 0.1132, 'grad_norm': 19.094253540039062, 'learning_rate': 0.00019987569212189224, 'epoch': 0.05}\n",
            "{'loss': 0.0922, 'grad_norm': 2.289001226425171, 'learning_rate': 0.0001998057915804532, 'epoch': 0.05}\n",
            "{'loss': 0.059, 'grad_norm': 4.400848865509033, 'learning_rate': 0.00019972037971811802, 'epoch': 0.05}\n",
            "{'loss': 0.1232, 'grad_norm': 13.952926635742188, 'learning_rate': 0.00019961946980917456, 'epoch': 0.06}\n",
            "{'loss': 0.0862, 'grad_norm': 2.0371928215026855, 'learning_rate': 0.00019950307753654017, 'epoch': 0.06}\n",
            "{'loss': 0.1001, 'grad_norm': 3.418485403060913, 'learning_rate': 0.00019937122098932428, 'epoch': 0.07}\n",
            "{'loss': 0.0997, 'grad_norm': 11.487303733825684, 'learning_rate': 0.00019922392066001722, 'epoch': 0.07}\n",
            "{'loss': 0.1106, 'grad_norm': 7.060151100158691, 'learning_rate': 0.0001990611994413053, 'epoch': 0.07}\n",
            "{'loss': 0.097, 'grad_norm': 3.953749656677246, 'learning_rate': 0.00019888308262251285, 'epoch': 0.08}\n",
            "{'loss': 0.0981, 'grad_norm': 4.842765808105469, 'learning_rate': 0.00019868959788567212, 'epoch': 0.08}\n",
            "{'loss': 0.1383, 'grad_norm': 49.37892532348633, 'learning_rate': 0.00019848077530122083, 'epoch': 0.08}\n",
            "{'loss': 0.1101, 'grad_norm': 6.707489967346191, 'learning_rate': 0.00019825664732332884, 'epoch': 0.09}\n",
            "{'loss': 0.1346, 'grad_norm': 10.012404441833496, 'learning_rate': 0.00019801724878485438, 'epoch': 0.09}\n",
            "{'loss': 0.1041, 'grad_norm': 13.57508659362793, 'learning_rate': 0.00019776261689193048, 'epoch': 0.1}\n",
            "{'loss': 0.099, 'grad_norm': 6.754876613616943, 'learning_rate': 0.00019749279121818235, 'epoch': 0.1}\n",
            "{'loss': 0.111, 'grad_norm': 1.1632996797561646, 'learning_rate': 0.00019720781369857746, 'epoch': 0.1}\n",
            "{'loss': 0.0981, 'grad_norm': 9.240983963012695, 'learning_rate': 0.0001969077286229078, 'epoch': 0.11}\n",
            "{'loss': 0.1007, 'grad_norm': 12.343720436096191, 'learning_rate': 0.00019659258262890683, 'epoch': 0.11}\n",
            "{'loss': 0.1737, 'grad_norm': 17.684307098388672, 'learning_rate': 0.0001962624246950012, 'epoch': 0.12}\n",
            "{'loss': 0.0732, 'grad_norm': 0.7424654364585876, 'learning_rate': 0.0001959173061326988, 'epoch': 0.12}\n",
            "{'loss': 0.08, 'grad_norm': 2.2813899517059326, 'learning_rate': 0.0001955572805786141, 'epoch': 0.12}\n",
            "{'loss': 0.0869, 'grad_norm': 3.7761106491088867, 'learning_rate': 0.00019518240398613227, 'epoch': 0.13}\n",
            "{'loss': 0.0921, 'grad_norm': 1.6270827054977417, 'learning_rate': 0.0001947927346167132, 'epoch': 0.13}\n",
            "{'loss': 0.1123, 'grad_norm': 1.8277925252914429, 'learning_rate': 0.00019438833303083678, 'epoch': 0.13}\n",
            "{'loss': 0.0988, 'grad_norm': 9.688244819641113, 'learning_rate': 0.00019396926207859084, 'epoch': 0.14}\n",
            "{'loss': 0.0689, 'grad_norm': 1.5017250776290894, 'learning_rate': 0.0001935355868899034, 'epoch': 0.14}\n",
            "{'loss': 0.2244, 'grad_norm': 18.572834014892578, 'learning_rate': 0.00019308737486442045, 'epoch': 0.15}\n",
            "{'loss': 0.2136, 'grad_norm': 5.930126667022705, 'learning_rate': 0.0001926246956610309, 'epoch': 0.15}\n",
            "{'loss': 0.1239, 'grad_norm': 10.336893081665039, 'learning_rate': 0.00019214762118704076, 'epoch': 0.15}\n",
            "{'loss': 0.1301, 'grad_norm': 9.723779678344727, 'learning_rate': 0.00019165622558699763, 'epoch': 0.16}\n",
            "{'loss': 0.1092, 'grad_norm': 7.200403690338135, 'learning_rate': 0.00019115058523116733, 'epoch': 0.16}\n",
            "{'loss': 0.108, 'grad_norm': 5.537387371063232, 'learning_rate': 0.000190630778703665, 'epoch': 0.17}\n",
            "{'loss': 0.0812, 'grad_norm': 3.510080575942993, 'learning_rate': 0.0001900968867902419, 'epoch': 0.17}\n",
            "{'loss': 0.1035, 'grad_norm': 6.8157958984375, 'learning_rate': 0.0001895489924657301, 'epoch': 0.17}\n",
            "{'loss': 0.0873, 'grad_norm': 4.338385581970215, 'learning_rate': 0.0001889871808811469, 'epoch': 0.18}\n",
            "{'loss': 0.0725, 'grad_norm': 3.5644402503967285, 'learning_rate': 0.00018841153935046098, 'epoch': 0.18}\n",
            "{'loss': 0.0822, 'grad_norm': 6.925222396850586, 'learning_rate': 0.00018782215733702286, 'epoch': 0.18}\n",
            "{'loss': 0.0906, 'grad_norm': 4.6120171546936035, 'learning_rate': 0.00018721912643966055, 'epoch': 0.19}\n",
            "{'loss': 0.0923, 'grad_norm': 7.922516822814941, 'learning_rate': 0.00018660254037844388, 'epoch': 0.19}\n",
            "{'loss': 0.1314, 'grad_norm': 0.9541751146316528, 'learning_rate': 0.00018597249498011903, 'epoch': 0.2}\n",
            "{'loss': 0.0953, 'grad_norm': 5.669104099273682, 'learning_rate': 0.00018532908816321558, 'epoch': 0.2}\n",
            "{'loss': 0.1096, 'grad_norm': 4.14001989364624, 'learning_rate': 0.00018467241992282843, 'epoch': 0.2}\n",
            "{'loss': 0.1064, 'grad_norm': 0.449192076921463, 'learning_rate': 0.00018400259231507717, 'epoch': 0.21}\n",
            "{'loss': 0.1216, 'grad_norm': 7.932538032531738, 'learning_rate': 0.0001833197094412449, 'epoch': 0.21}\n",
            "{'loss': 0.0851, 'grad_norm': 7.232353687286377, 'learning_rate': 0.0001826238774315995, 'epoch': 0.22}\n",
            "{'loss': 0.1515, 'grad_norm': 4.495628833770752, 'learning_rate': 0.0001819152044288992, 'epoch': 0.22}\n",
            "{'loss': 0.1029, 'grad_norm': 2.6662211418151855, 'learning_rate': 0.00018119380057158568, 'epoch': 0.22}\n",
            "{'loss': 0.1113, 'grad_norm': 3.1080946922302246, 'learning_rate': 0.00018045977797666684, 'epoch': 0.23}\n",
            "{'loss': 0.1344, 'grad_norm': 6.024674415588379, 'learning_rate': 0.00017971325072229226, 'epoch': 0.23}\n",
            "{'loss': 0.1023, 'grad_norm': 1.090408444404602, 'learning_rate': 0.00017895433483002354, 'epoch': 0.23}\n",
            "{'loss': 0.1134, 'grad_norm': 5.269225597381592, 'learning_rate': 0.000178183148246803, 'epoch': 0.24}\n",
            "{'loss': 0.115, 'grad_norm': 4.62173318862915, 'learning_rate': 0.00017739981082662276, 'epoch': 0.24}\n",
            "{'loss': 0.1019, 'grad_norm': 6.296285629272461, 'learning_rate': 0.0001766044443118978, 'epoch': 0.25}\n",
            "{'loss': 0.094, 'grad_norm': 1.0675321817398071, 'learning_rate': 0.0001757971723145453, 'epoch': 0.25}\n",
            "{'loss': 0.0802, 'grad_norm': 4.827779293060303, 'learning_rate': 0.00017497812029677344, 'epoch': 0.25}\n",
            "{'loss': 0.0926, 'grad_norm': 5.3671674728393555, 'learning_rate': 0.00017414741555158266, 'epoch': 0.26}\n",
            "{'loss': 0.0886, 'grad_norm': 10.417577743530273, 'learning_rate': 0.00017330518718298264, 'epoch': 0.26}\n",
            "{'loss': 0.2279, 'grad_norm': 14.650347709655762, 'learning_rate': 0.00017245156608592727, 'epoch': 0.27}\n",
            "{'loss': 0.0771, 'grad_norm': 1.9420008659362793, 'learning_rate': 0.00017158668492597186, 'epoch': 0.27}\n",
            "{'loss': 0.0979, 'grad_norm': 3.610677719116211, 'learning_rate': 0.00017071067811865476, 'epoch': 0.27}\n",
            "{'loss': 0.0978, 'grad_norm': 10.868005752563477, 'learning_rate': 0.00016982368180860728, 'epoch': 0.28}\n",
            "{'loss': 0.1081, 'grad_norm': 1.9971213340759277, 'learning_rate': 0.0001689258338483947, 'epoch': 0.28}\n",
            "{'loss': 0.1033, 'grad_norm': 4.45949125289917, 'learning_rate': 0.00016801727377709194, 'epoch': 0.28}\n",
            "{'loss': 0.101, 'grad_norm': 0.6505029201507568, 'learning_rate': 0.00016709814279859702, 'epoch': 0.29}\n",
            "{'loss': 0.1206, 'grad_norm': 5.495635032653809, 'learning_rate': 0.00016616858375968595, 'epoch': 0.29}\n",
            "{'loss': 0.0938, 'grad_norm': 6.701787948608398, 'learning_rate': 0.00016522874112781213, 'epoch': 0.3}\n",
            "{'loss': 0.1042, 'grad_norm': 6.911844730377197, 'learning_rate': 0.00016427876096865394, 'epoch': 0.3}\n",
            "{'loss': 0.0991, 'grad_norm': 8.358427047729492, 'learning_rate': 0.000163318790923414, 'epoch': 0.3}\n",
            "{'loss': 0.0949, 'grad_norm': 1.7450791597366333, 'learning_rate': 0.00016234898018587337, 'epoch': 0.31}\n",
            "{'loss': 0.1145, 'grad_norm': 0.5284179449081421, 'learning_rate': 0.00016136947947920476, 'epoch': 0.31}\n",
            "{'loss': 0.1295, 'grad_norm': 3.012030839920044, 'learning_rate': 0.00016038044103254775, 'epoch': 0.32}\n",
            "{'loss': 0.0926, 'grad_norm': 1.3671584129333496, 'learning_rate': 0.00015938201855735014, 'epoch': 0.32}\n",
            "{'loss': 0.0848, 'grad_norm': 4.271651744842529, 'learning_rate': 0.000158374367223479, 'epoch': 0.32}\n",
            "{'loss': 0.0909, 'grad_norm': 7.507917881011963, 'learning_rate': 0.0001573576436351046, 'epoch': 0.33}\n",
            "{'loss': 0.0966, 'grad_norm': 5.140277862548828, 'learning_rate': 0.0001563320058063622, 'epoch': 0.33}\n",
            "{'loss': 0.1014, 'grad_norm': 1.8214000463485718, 'learning_rate': 0.00015529761313679393, 'epoch': 0.33}\n",
            "{'loss': 0.0836, 'grad_norm': 0.6990745663642883, 'learning_rate': 0.00015425462638657595, 'epoch': 0.34}\n",
            "{'loss': 0.1372, 'grad_norm': 7.933856010437012, 'learning_rate': 0.00015320320765153367, 'epoch': 0.34}\n",
            "{'loss': 0.0932, 'grad_norm': 6.772278308868408, 'learning_rate': 0.0001521435203379498, 'epoch': 0.35}\n",
            "{'loss': 0.0893, 'grad_norm': 62.43194580078125, 'learning_rate': 0.00015107572913716858, 'epoch': 0.35}\n",
            "{'loss': 0.0894, 'grad_norm': 0.9908459782600403, 'learning_rate': 0.00015000000000000001, 'epoch': 0.35}\n",
            "{'loss': 0.1147, 'grad_norm': 2.212693929672241, 'learning_rate': 0.00014891650011092896, 'epoch': 0.36}\n",
            "{'loss': 0.1063, 'grad_norm': 0.9358528852462769, 'learning_rate': 0.00014782539786213183, 'epoch': 0.36}\n",
            "{'loss': 0.1206, 'grad_norm': 10.074800491333008, 'learning_rate': 0.0001467268628273062, 'epoch': 0.37}\n",
            "{'loss': 0.1109, 'grad_norm': 1.5701148509979248, 'learning_rate': 0.0001456210657353163, 'epoch': 0.37}\n",
            "{'loss': 0.0968, 'grad_norm': 6.4912109375, 'learning_rate': 0.00014450817844365921, 'epoch': 0.37}\n",
            "{'loss': 0.0914, 'grad_norm': 0.9574083685874939, 'learning_rate': 0.00014338837391175582, 'epoch': 0.38}\n",
            "{'loss': 0.1008, 'grad_norm': 2.4142842292785645, 'learning_rate': 0.00014226182617406996, 'epoch': 0.38}\n",
            "{'loss': 0.0878, 'grad_norm': 2.9624104499816895, 'learning_rate': 0.00014112871031306119, 'epoch': 0.39}\n",
            "{'loss': 0.0698, 'grad_norm': 1.4457677602767944, 'learning_rate': 0.00013998920243197407, 'epoch': 0.39}\n",
            "{'loss': 0.1121, 'grad_norm': 3.3913733959198, 'learning_rate': 0.00013884347962746948, 'epoch': 0.39}\n",
            "{'loss': 0.0789, 'grad_norm': 0.39910805225372314, 'learning_rate': 0.00013769171996210052, 'epoch': 0.4}\n",
            "{'loss': 0.0842, 'grad_norm': 5.814688205718994, 'learning_rate': 0.00013653410243663952, 'epoch': 0.4}\n",
            "{'loss': 0.0988, 'grad_norm': 3.4356706142425537, 'learning_rate': 0.00013537080696225814, 'epoch': 0.4}\n",
            "{'loss': 0.1197, 'grad_norm': 2.635439395904541, 'learning_rate': 0.00013420201433256689, 'epoch': 0.41}\n",
            "{'loss': 0.1107, 'grad_norm': 1.3170660734176636, 'learning_rate': 0.00013302790619551674, 'epoch': 0.41}\n",
            "{'loss': 0.1016, 'grad_norm': 1.6030782461166382, 'learning_rate': 0.00013184866502516845, 'epoch': 0.42}\n",
            "{'loss': 0.1016, 'grad_norm': 2.4215750694274902, 'learning_rate': 0.00013066447409333345, 'epoch': 0.42}\n",
            "{'loss': 0.0818, 'grad_norm': 1.237182855606079, 'learning_rate': 0.00012947551744109043, 'epoch': 0.42}\n",
            "{'loss': 0.1264, 'grad_norm': 5.340271949768066, 'learning_rate': 0.00012828197985018276, 'epoch': 0.43}\n",
            "{'loss': 0.0889, 'grad_norm': 1.808140754699707, 'learning_rate': 0.00012708404681430053, 'epoch': 0.43}\n",
            "{'loss': 0.1025, 'grad_norm': 6.241262912750244, 'learning_rate': 0.00012588190451025207, 'epoch': 0.44}\n",
            "{'loss': 0.1088, 'grad_norm': 8.300453186035156, 'learning_rate': 0.00012467573976902935, 'epoch': 0.44}\n",
            "{'loss': 0.0689, 'grad_norm': 0.5542368292808533, 'learning_rate': 0.00012346574004677154, 'epoch': 0.44}\n",
            "{'loss': 0.1312, 'grad_norm': 5.853841304779053, 'learning_rate': 0.00012225209339563145, 'epoch': 0.45}\n",
            "{'loss': 0.0937, 'grad_norm': 5.319250106811523, 'learning_rate': 0.00012103498843454959, 'epoch': 0.45}\n",
            "{'loss': 0.067, 'grad_norm': 0.420259952545166, 'learning_rate': 0.00011981461431993977, 'epoch': 0.45}\n",
            "{'loss': 0.0707, 'grad_norm': 1.95485520362854, 'learning_rate': 0.00011859116071629149, 'epoch': 0.46}\n",
            "{'loss': 0.0718, 'grad_norm': 3.6398327350616455, 'learning_rate': 0.00011736481776669306, 'epoch': 0.46}\n",
            "{'loss': 0.0859, 'grad_norm': 1.7849899530410767, 'learning_rate': 0.00011613577606328068, 'epoch': 0.47}\n",
            "{'loss': 0.0994, 'grad_norm': 3.2136390209198, 'learning_rate': 0.00011490422661761744, 'epoch': 0.47}\n",
            "{'loss': 0.1171, 'grad_norm': 1.1478065252304077, 'learning_rate': 0.00011367036083100735, 'epoch': 0.47}\n",
            "{'loss': 0.0872, 'grad_norm': 0.5315139889717102, 'learning_rate': 0.00011243437046474853, 'epoch': 0.48}\n",
            "{'loss': 0.0762, 'grad_norm': 2.9017975330352783, 'learning_rate': 0.00011119644761033078, 'epoch': 0.48}\n",
            "{'loss': 0.0856, 'grad_norm': 3.0489561557769775, 'learning_rate': 0.00010995678465958168, 'epoch': 0.49}\n",
            "{'loss': 0.0909, 'grad_norm': 3.602264642715454, 'learning_rate': 0.00010871557427476583, 'epoch': 0.49}\n",
            "{'loss': 0.1228, 'grad_norm': 0.7557403445243835, 'learning_rate': 0.00010747300935864243, 'epoch': 0.49}\n",
            "{'loss': 0.0904, 'grad_norm': 4.486807823181152, 'learning_rate': 0.00010622928302448523, 'epoch': 0.5}\n",
            "{'loss': 0.0846, 'grad_norm': 1.2507208585739136, 'learning_rate': 0.00010498458856606972, 'epoch': 0.5}\n",
            "{'loss': 0.0833, 'grad_norm': 1.4903945922851562, 'learning_rate': 0.0001037391194276326, 'epoch': 0.5}\n",
            "{'loss': 0.0889, 'grad_norm': 2.1685359477996826, 'learning_rate': 0.0001024930691738073, 'epoch': 0.51}\n",
            "{'loss': 0.1263, 'grad_norm': 2.285046339035034, 'learning_rate': 0.00010124663145954152, 'epoch': 0.51}\n",
            "{'loss': 0.0918, 'grad_norm': 5.588066101074219, 'learning_rate': 0.0001, 'epoch': 0.52}\n",
            "{'loss': 0.0931, 'grad_norm': 4.527864933013916, 'learning_rate': 9.875336854045851e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0956, 'grad_norm': 2.0201971530914307, 'learning_rate': 9.750693082619273e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0983, 'grad_norm': 5.689270496368408, 'learning_rate': 9.626088057236745e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0692, 'grad_norm': 1.062052607536316, 'learning_rate': 9.501541143393028e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0909, 'grad_norm': 1.392103910446167, 'learning_rate': 9.37707169755148e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0867, 'grad_norm': 4.376008033752441, 'learning_rate': 9.252699064135758e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0935, 'grad_norm': 3.1003427505493164, 'learning_rate': 9.128442572523417e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0587, 'grad_norm': 1.365378499031067, 'learning_rate': 9.004321534041835e-05, 'epoch': 0.55}\n",
            "{'loss': 0.12, 'grad_norm': 6.7439351081848145, 'learning_rate': 8.880355238966923e-05, 'epoch': 0.55}\n",
            "{'loss': 0.133, 'grad_norm': 4.851078987121582, 'learning_rate': 8.756562953525152e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0704, 'grad_norm': 1.2572005987167358, 'learning_rate': 8.632963916899268e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0892, 'grad_norm': 1.984858751296997, 'learning_rate': 8.509577338238255e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0991, 'grad_norm': 4.768556118011475, 'learning_rate': 8.386422393671933e-05, 'epoch': 0.57}\n",
            "{'loss': 0.094, 'grad_norm': 0.7302942872047424, 'learning_rate': 8.263518223330697e-05, 'epoch': 0.57}\n",
            "{'loss': 0.1032, 'grad_norm': 3.4238228797912598, 'learning_rate': 8.140883928370855e-05, 'epoch': 0.57}\n",
            "{'loss': 0.077, 'grad_norm': 2.5350501537323, 'learning_rate': 8.018538568006027e-05, 'epoch': 0.58}\n",
            "{'loss': 0.1115, 'grad_norm': 1.5995895862579346, 'learning_rate': 7.896501156545045e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0722, 'grad_norm': 1.8057491779327393, 'learning_rate': 7.774790660436858e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0758, 'grad_norm': 1.29696786403656, 'learning_rate': 7.653425995322851e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0783, 'grad_norm': 0.9578193426132202, 'learning_rate': 7.532426023097063e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0925, 'grad_norm': 6.757813453674316, 'learning_rate': 7.411809548974792e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0909, 'grad_norm': 5.241501808166504, 'learning_rate': 7.291595318569951e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0935, 'grad_norm': 3.5763628482818604, 'learning_rate': 7.171802014981726e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0747, 'grad_norm': 1.0774970054626465, 'learning_rate': 7.052448255890957e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0998, 'grad_norm': 5.063783645629883, 'learning_rate': 6.933552590666659e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0906, 'grad_norm': 4.413699150085449, 'learning_rate': 6.815133497483157e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0828, 'grad_norm': 3.279665231704712, 'learning_rate': 6.697209380448333e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0789, 'grad_norm': 1.172432780265808, 'learning_rate': 6.579798566743314e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0817, 'grad_norm': 1.8267154693603516, 'learning_rate': 6.462919303774186e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0924, 'grad_norm': 5.209690570831299, 'learning_rate': 6.34658975633605e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0974, 'grad_norm': 5.297896385192871, 'learning_rate': 6.230828003789949e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0783, 'grad_norm': 1.9383004903793335, 'learning_rate': 6.115652037253053e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0821, 'grad_norm': 3.1329474449157715, 'learning_rate': 6.001079756802592e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0818, 'grad_norm': 2.933224678039551, 'learning_rate': 5.887128968693887e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0892, 'grad_norm': 2.9685518741607666, 'learning_rate': 5.773817382593008e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0819, 'grad_norm': 3.4381673336029053, 'learning_rate': 5.6611626088244194e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0785, 'grad_norm': 4.18754768371582, 'learning_rate': 5.549182155634076e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0911, 'grad_norm': 3.2205405235290527, 'learning_rate': 5.43789342646837e-05, 'epoch': 0.66}\n",
            "{'loss': 0.1158, 'grad_norm': 7.515088081359863, 'learning_rate': 5.32731371726938e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0608, 'grad_norm': 2.164266347885132, 'learning_rate': 5.217460213786821e-05, 'epoch': 0.67}\n",
            "{'loss': 0.1044, 'grad_norm': 5.080366611480713, 'learning_rate': 5.108349988907111e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0899, 'grad_norm': 1.6041299104690552, 'learning_rate': 5.000000000000002e-05, 'epoch': 0.68}\n",
            "{'loss': 0.1088, 'grad_norm': 1.0822293758392334, 'learning_rate': 4.892427086283147e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0748, 'grad_norm': 2.3221137523651123, 'learning_rate': 4.78564796620502e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0741, 'grad_norm': 4.670142650604248, 'learning_rate': 4.6796792348466356e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0942, 'grad_norm': 3.396327257156372, 'learning_rate': 4.574537361342407e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0613, 'grad_norm': 1.8954575061798096, 'learning_rate': 4.470238686320606e-05, 'epoch': 0.7}\n",
            "{'loss': 0.088, 'grad_norm': 3.5747992992401123, 'learning_rate': 4.3667994193637796e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0887, 'grad_norm': 2.5734081268310547, 'learning_rate': 4.264235636489542e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0749, 'grad_norm': 3.1148130893707275, 'learning_rate': 4.1625632776521037e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0963, 'grad_norm': 3.542102336883545, 'learning_rate': 4.0617981442649855e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0898, 'grad_norm': 3.5802206993103027, 'learning_rate': 3.961955896745224e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0906, 'grad_norm': 5.7676239013671875, 'learning_rate': 3.863052052079528e-05, 'epoch': 0.72}\n",
            "{'loss': 0.1005, 'grad_norm': 1.5998588800430298, 'learning_rate': 3.7651019814126654e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0862, 'grad_norm': 2.7928390502929688, 'learning_rate': 3.668120907658603e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0797, 'grad_norm': 2.693382501602173, 'learning_rate': 3.5721239031346066e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0766, 'grad_norm': 1.3508989810943604, 'learning_rate': 3.477125887218792e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0946, 'grad_norm': 1.381934642791748, 'learning_rate': 3.383141624031408e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0987, 'grad_norm': 1.9205431938171387, 'learning_rate': 3.290185720140301e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0852, 'grad_norm': 2.7289535999298096, 'learning_rate': 3.198272622290804e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0951, 'grad_norm': 2.9233436584472656, 'learning_rate': 3.10741661516053e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0809, 'grad_norm': 1.217017412185669, 'learning_rate': 3.0176318191392726e-05, 'epoch': 0.75}\n",
            "{'loss': 0.075, 'grad_norm': 1.1775469779968262, 'learning_rate': 2.9289321881345254e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0926, 'grad_norm': 1.6857191324234009, 'learning_rate': 2.8413315074028158e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0982, 'grad_norm': 5.998437404632568, 'learning_rate': 2.7548433914072734e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0797, 'grad_norm': 1.4041903018951416, 'learning_rate': 2.669481281701739e-05, 'epoch': 0.77}\n",
            "{'loss': 0.072, 'grad_norm': 2.298590898513794, 'learning_rate': 2.5852584448417328e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0792, 'grad_norm': 3.338268995285034, 'learning_rate': 2.502187970322657e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0972, 'grad_norm': 2.53328537940979, 'learning_rate': 2.420282768545469e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0873, 'grad_norm': 2.5646567344665527, 'learning_rate': 2.339555568810221e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0978, 'grad_norm': 3.178659677505493, 'learning_rate': 2.260018917337726e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0739, 'grad_norm': 2.227125644683838, 'learning_rate': 2.181685175319702e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0725, 'grad_norm': 1.1027791500091553, 'learning_rate': 2.1045665169976468e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0858, 'grad_norm': 1.777880072593689, 'learning_rate': 2.0286749277707782e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0811, 'grad_norm': 1.2017371654510498, 'learning_rate': 1.9540222023333166e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0772, 'grad_norm': 3.621075391769409, 'learning_rate': 1.880619942841435e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0829, 'grad_norm': 4.319094181060791, 'learning_rate': 1.808479557110081e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0844, 'grad_norm': 3.434128761291504, 'learning_rate': 1.7376122568400532e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0931, 'grad_norm': 2.6018710136413574, 'learning_rate': 1.668029055875512e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0833, 'grad_norm': 2.376211166381836, 'learning_rate': 1.5997407684922862e-05, 'epoch': 0.82}\n",
            "{'loss': 0.1073, 'grad_norm': 1.2921452522277832, 'learning_rate': 1.5327580077171587e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0817, 'grad_norm': 3.6394729614257812, 'learning_rate': 1.467091183678444e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0678, 'grad_norm': 4.366776466369629, 'learning_rate': 1.402750501988097e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0972, 'grad_norm': 4.983046054840088, 'learning_rate': 1.339745962155613e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0596, 'grad_norm': 4.2902021408081055, 'learning_rate': 1.2780873560339468e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0843, 'grad_norm': 6.154365539550781, 'learning_rate': 1.2177842662977135e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0774, 'grad_norm': 2.0016565322875977, 'learning_rate': 1.1588460649539035e-05, 'epoch': 0.85}\n",
            "{'loss': 0.08, 'grad_norm': 1.4905860424041748, 'learning_rate': 1.1012819118853147e-05, 'epoch': 0.85}\n",
            "{'loss': 0.075, 'grad_norm': 3.298466920852661, 'learning_rate': 1.0451007534269907e-05, 'epoch': 0.86}\n",
            "{'loss': 0.069, 'grad_norm': 2.581984281539917, 'learning_rate': 9.903113209758096e-06, 'epoch': 0.86}\n",
            "{'loss': 0.0795, 'grad_norm': 5.453956604003906, 'learning_rate': 9.369221296335006e-06, 'epoch': 0.87}\n",
            "{'loss': 0.0963, 'grad_norm': 1.421742558479309, 'learning_rate': 8.849414768832687e-06, 'epoch': 0.87}\n",
            "{'loss': 0.089, 'grad_norm': 0.9559288024902344, 'learning_rate': 8.343774413002381e-06, 'epoch': 0.87}\n",
            "{'loss': 0.0722, 'grad_norm': 0.9498177170753479, 'learning_rate': 7.852378812959227e-06, 'epoch': 0.88}\n",
            "{'loss': 0.0954, 'grad_norm': 2.3044731616973877, 'learning_rate': 7.375304338969136e-06, 'epoch': 0.88}\n",
            "{'loss': 0.0801, 'grad_norm': 1.9373656511306763, 'learning_rate': 6.9126251355795864e-06, 'epoch': 0.89}\n",
            "{'loss': 0.1196, 'grad_norm': 6.006883144378662, 'learning_rate': 6.464413110096601e-06, 'epoch': 0.89}\n",
            "{'loss': 0.0848, 'grad_norm': 2.522700071334839, 'learning_rate': 6.030737921409169e-06, 'epoch': 0.89}\n",
            "{'loss': 0.075, 'grad_norm': 1.4553227424621582, 'learning_rate': 5.611666969163243e-06, 'epoch': 0.9}\n",
            "{'loss': 0.0839, 'grad_norm': 3.007641077041626, 'learning_rate': 5.20726538328683e-06, 'epoch': 0.9}\n",
            "{'loss': 0.0884, 'grad_norm': 1.959289789199829, 'learning_rate': 4.817596013867764e-06, 'epoch': 0.9}\n",
            "{'loss': 0.0587, 'grad_norm': 1.4340800046920776, 'learning_rate': 4.442719421385922e-06, 'epoch': 0.91}\n",
            "{'loss': 0.0744, 'grad_norm': 2.093216896057129, 'learning_rate': 4.082693867301224e-06, 'epoch': 0.91}\n",
            "{'loss': 0.0964, 'grad_norm': 1.7648965120315552, 'learning_rate': 3.7375753049987973e-06, 'epoch': 0.92}\n",
            "{'loss': 0.0922, 'grad_norm': 1.5478748083114624, 'learning_rate': 3.40741737109318e-06, 'epoch': 0.92}\n",
            "{'loss': 0.0858, 'grad_norm': 4.724285125732422, 'learning_rate': 3.092271377092215e-06, 'epoch': 0.92}\n",
            "{'loss': 0.0872, 'grad_norm': 3.2760565280914307, 'learning_rate': 2.7921863014225503e-06, 'epoch': 0.93}\n",
            "{'loss': 0.0918, 'grad_norm': 0.928345799446106, 'learning_rate': 2.5072087818176382e-06, 'epoch': 0.93}\n",
            "{'loss': 0.0893, 'grad_norm': 1.5216416120529175, 'learning_rate': 2.237383108069546e-06, 'epoch': 0.94}\n",
            "{'loss': 0.1159, 'grad_norm': 2.15663480758667, 'learning_rate': 1.9827512151456173e-06, 'epoch': 0.94}\n",
            "{'loss': 0.074, 'grad_norm': 2.1983354091644287, 'learning_rate': 1.7433526766711728e-06, 'epoch': 0.94}\n",
            "{'loss': 0.0771, 'grad_norm': 1.8015527725219727, 'learning_rate': 1.5192246987791981e-06, 'epoch': 0.95}\n",
            "{'loss': 0.0729, 'grad_norm': 1.5925661325454712, 'learning_rate': 1.3104021143278911e-06, 'epoch': 0.95}\n",
            "{'loss': 0.1039, 'grad_norm': 2.3512353897094727, 'learning_rate': 1.1169173774871478e-06, 'epoch': 0.95}\n",
            "{'loss': 0.0961, 'grad_norm': 3.9591808319091797, 'learning_rate': 9.388005586947191e-07, 'epoch': 0.96}\n",
            "{'loss': 0.0841, 'grad_norm': 1.4698559045791626, 'learning_rate': 7.760793399827937e-07, 'epoch': 0.96}\n",
            "{'loss': 0.1152, 'grad_norm': 1.5380382537841797, 'learning_rate': 6.287790106757396e-07, 'epoch': 0.97}\n",
            "{'loss': 0.0746, 'grad_norm': 3.5846102237701416, 'learning_rate': 4.969224634598591e-07, 'epoch': 0.97}\n",
            "{'loss': 0.1057, 'grad_norm': 4.010091781616211, 'learning_rate': 3.805301908254455e-07, 'epoch': 0.97}\n",
            "{'loss': 0.0909, 'grad_norm': 2.2509355545043945, 'learning_rate': 2.7962028188198706e-07, 'epoch': 0.98}\n",
            "{'loss': 0.0965, 'grad_norm': 2.4120147228240967, 'learning_rate': 1.9420841954681525e-07, 'epoch': 0.98}\n",
            "{'loss': 0.0747, 'grad_norm': 1.1912307739257812, 'learning_rate': 1.2430787810776555e-07, 'epoch': 0.99}\n",
            "{'loss': 0.0644, 'grad_norm': 1.8484299182891846, 'learning_rate': 6.992952116013918e-08, 'epoch': 0.99}\n",
            "{'loss': 0.1108, 'grad_norm': 5.447336196899414, 'learning_rate': 3.1081799918375454e-08, 'epoch': 0.99}\n",
            "{'loss': 0.0949, 'grad_norm': 2.807661771774292, 'learning_rate': 7.770751902513862e-09, 'epoch': 1.0}\n",
            "{'train_runtime': 7313.2898, 'train_samples_per_second': 1.705, 'train_steps_per_second': 0.107, 'train_loss': 0.12800882353097084, 'epoch': 1.0}\n",
            "100% 779/779 [2:01:51<00:00,  9.40s/it]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "100% 779/779 [2:01:56<00:00,  9.39s/it]\n",
            "[2025-04-28 12:02:44,987] [INFO] [axolotl.train.save_trained_model:211] [PID:33905] [RANK:0] Training completed! Saving pre-trained model to /content/mistral-output.\u001b[39m\n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mv15\u001b[0m at: \u001b[34mhttps://wandb.ai/wilson_ng-govtech/reach-fine-tuning/runs/v15\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250428_100046-v15/logs\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/outputs/mistral-qlora\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"steps\",  # eval every few steps\n",
        "    eval_steps=20,                # eval every 20 steps\n",
        "    logging_steps=5,              # log training loss every 5 steps\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,                # save model every 50 steps\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"cosine\",   # Cosine decay for LR\n",
        "    warmup_ratio=0.1,             # 10% warm-up\n",
        "    bf16=True,\n",
        "    report_to=\"wandb\",            # Track with WandB\n",
        "    run_name=\"mistral-finetune\",\n",
        "    logging_dir=\"./logs\",         # For tracking logs\n",
        ")\n",
        "\n",
        "# Step 5: Data Collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Step 6: Early Stopping Callback\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=2  # stop if eval loss doesn't improve for 2 evals\n",
        ")\n",
        "\n",
        "# Step 7: Compute Perplexity\n",
        "def compute_metrics(eval_preds):\n",
        "    loss = eval_preds[\"loss\"] if isinstance(eval_preds, dict) else eval_preds.loss\n",
        "    perplexity = math.exp(loss)\n",
        "    return {\"eval_loss\": loss, \"perplexity\": perplexity}\n",
        "\n",
        "# Step 8: Initialize the Trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping],  # Add early stopping\n",
        ")\n",
        "\n",
        "# Step 9: Train the Model\n",
        "trainer.train()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZtuI-15T45Gz"
      },
      "id": "ZtuI-15T45Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model artifact to gcs\n",
        "!gsutil -m rm -r gs://mddi-reach-conversation/mistral-output/\n",
        "!gsutil -m cp -r /content/mistral-output/ gs://mddi-reach-conversation/"
      ],
      "metadata": {
        "id": "FGpH6qYiMSWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745841860117,
          "user_tz": -480,
          "elapsed": 55356,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f3b7295b-63b4-4ff1-d3df-e1b0134a526b"
      },
      "id": "FGpH6qYiMSWH",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing gs://mddi-reach-conversation/mistral-output/README.md#1745832339847600...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/adapter_config.json#1745832339799423...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/adapter_model.safetensors#1745832364443992...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/README.md#1745832340147711...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/adapter_config.json#1745832339769123...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/adapter_model.safetensors#1745832364285822...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/optimizer.pt#1745832388044395...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/rng_state_0.pth#1745832339790699...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/rng_state_1.pth#1745832340137383...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/rng_state_2.pth#1745832340982263...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/scheduler.pt#1745832340804475...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/rng_state_3.pth#1745832341057610...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/special_tokens_map.json#1745832340049512...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/tokenizer.json#1745832341430876...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/tokenizer.model#1745832341085811...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/tokenizer_config.json#1745832339774999...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/trainer_state.json#1745832340764208...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-200/training_args.bin#1745832340751092...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/README.md#1745832340184876...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/adapter_config.json#1745832340717365...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/adapter_model.safetensors#1745832366270466...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/optimizer.pt#1745832388669757...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/rng_state_0.pth#1745832339933915...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/rng_state_1.pth#1745832340148592...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/rng_state_2.pth#1745832340010087...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/rng_state_3.pth#1745832340179272...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/scheduler.pt#1745832339991292...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/special_tokens_map.json#1745832340969132...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/tokenizer.json#1745832341567649...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/tokenizer.model#1745832342073391...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/tokenizer_config.json#1745832340092179...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/trainer_state.json#1745832341028847...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/checkpoint-295/training_args.bin#1745832339929731...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/config.json#1745832340701383...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/special_tokens_map.json#1745832339757832...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/tokenizer.json#1745832342203847...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/tokenizer.model#1745832340643811...\n",
            "Removing gs://mddi-reach-conversation/mistral-output/tokenizer_config.json#1745832340603271...\n",
            "/ [38/38 objects] 100% Done                                                     \n",
            "Operation completed over 38 objects.                                             \n",
            "Copying file:///content/mistral-output/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/README.md [Content-Type=text/markdown]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file:///content/mistral-output/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/rng_state_3.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/rng_state_2.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-200/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/rng_state_3.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/rng_state_2.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-400/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/rng_state_3.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/rng_state_2.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-779/special_tokens_map.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/adapter_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/training_args.bin [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/tokenizer.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/rng_state_0.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/trainer_state.json [Content-Type=application/json]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/rng_state_1.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/rng_state_3.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/README.md [Content-Type=text/markdown]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/rng_state_2.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/tokenizer.model [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/mistral-output/checkpoint-600/special_tokens_map.json [Content-Type=application/json]...\n",
            "/ [68/68 files][  6.6 GiB/  6.6 GiB] 100% Done  77.4 MiB/s ETA 00:00:00         \n",
            "Operation completed over 68 objects/6.6 GiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "57Vqu5KwLqDb"
      },
      "id": "57Vqu5KwLqDb"
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_test.csv\").rename({'key_point': 'stance', 'person_id': 'user'}, axis=1)\n",
        "#train_data = load_csv_from_gcs(\"mddi-reach-conversation\", \"mistral_training_data/mistral_train.csv\").rename({'key_point': 'stance', 'person_id': 'user'}, axis=1)"
      ],
      "metadata": {
        "id": "xI3yaAl7iSpq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745841864215,
          "user_tz": -480,
          "elapsed": 4106,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "xI3yaAl7iSpq",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gsutil -m cp -r gs://mddi-reach-conversation/mistral-output/ /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhLLh3gN1IZD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745292571845,
          "user_tz": -480,
          "elapsed": 88936,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "118bcba9-a056-49d4-e5b6-c7c18475abb9"
      },
      "id": "FhLLh3gN1IZD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://mddi-reach-conversation/mistral-output/README.md...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/adapter_config.json...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/adapter_model.safetensors...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \r==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/adapter_config.json...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/README.md...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/adapter_model.safetensors...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/optimizer.pt...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/rng_state_0.pth...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/rng_state_1.pth...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/rng_state_3.pth...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/scheduler.pt...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/special_tokens_map.json...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/tokenizer.json...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/tokenizer.model...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/rng_state_2.pth...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/tokenizer_config.json...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/trainer_state.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1000/training_args.bin...\n",
            "/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \r/ [0/68 files][    0.0 B/  6.5 GiB]   0% Done                                   \rCopying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/adapter_model.safetensors...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/optimizer.pt...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/adapter_config.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/rng_state_0.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/rng_state_1.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/trainer_state.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/README.md...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/scheduler.pt...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/rng_state_3.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/rng_state_2.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/tokenizer_config.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/special_tokens_map.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/tokenizer.model...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/tokenizer.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1200/training_args.bin...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/README.md...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/rng_state_1.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/training_args.bin...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/rng_state_3.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/tokenizer_config.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/scheduler.pt...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/tokenizer.model...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/optimizer.pt...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/rng_state_0.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/adapter_config.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/adapter_config.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/rng_state_2.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/rng_state_1.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/special_tokens_map.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/special_tokens_map.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/adapter_model.safetensors...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/rng_state_2.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/README.md...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/trainer_state.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/rng_state_3.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/scheduler.pt...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1400/tokenizer.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/optimizer.pt...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/adapter_model.safetensors...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/tokenizer.model...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/tokenizer.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/rng_state_0.pth...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/tokenizer_config.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/trainer_state.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/checkpoint-1457/training_args.bin...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/config.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/special_tokens_map.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/tokenizer.json...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/tokenizer.model...\n",
            "Copying gs://mddi-reach-conversation/mistral-output/tokenizer_config.json...\n",
            "|\n",
            "Operation completed over 68 objects/6.5 GiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer,  BitsAndBytesConfig\n",
        "import torch\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "# Define 4-bit quantization config (must match training time)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load base model in 4-bit\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True,\n",
        "    padding_side=\"left\",\n",
        "    #max_length=8192,padding='max_length'\n",
        "    #add_eos_token=True,\n",
        "    #add_bos_token=True\n",
        ")\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "n45Uv1cALvPA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "80e65d2c9cb9494b99b3a094b4aa4e95",
            "d49104a2791a4cf4aea35be90e351460",
            "4738795463ce41e4b4bce691ce8a625e",
            "545b6f7d2b134be28658498109ac9b3e",
            "135066807d6a4d799c9ce05b5fe7e782",
            "2a88066453984a50bb5c7c02a47301c0",
            "b2e62406e845424284e55ecc26a05452",
            "a325eca154d84e48bda67b0a1fda232b",
            "9395b0c2f4bc4f6d86d3dd473e2e6da9",
            "b5cbc6694d714d3cbcc575edc3b7fc60",
            "033ab3a881574186a34523531b17f9a5"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745841871440,
          "user_tz": -480,
          "elapsed": 7227,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4881204f-0c6f-4584-ba6c-0e471adcfdd5"
      },
      "id": "n45Uv1cALvPA",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80e65d2c9cb9494b99b3a094b4aa4e95"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load fine-tuned PEFT adapter\n",
        "model = PeftModel.from_pretrained(base_model, \"/content/mistral-output\")\n",
        "\n",
        "# Merge LoRA weights into base model\n",
        "merged_model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "cJlIZXIQX_WP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745841875364,
          "user_tz": -480,
          "elapsed": 3926,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "901d45cc-1a17-4141-b294-c7d50c8b9db0"
      },
      "id": "cJlIZXIQX_WP",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}\")"
      ],
      "metadata": {
        "id": "ZNdszShVxGU9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745841875364,
          "user_tz": -480,
          "elapsed": 9,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c314239b-c7bc-4876-9e8b-f4cdc113a1d4"
      },
      "id": "ZNdszShVxGU9",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.model.embed_tokens.weight\n",
            "base_model.model.model.layers.0.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.0.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.0.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.0.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.0.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.0.mlp.up_proj.weight\n",
            "base_model.model.model.layers.0.mlp.down_proj.weight\n",
            "base_model.model.model.layers.0.input_layernorm.weight\n",
            "base_model.model.model.layers.0.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.1.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.1.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.1.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.1.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.1.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.1.mlp.up_proj.weight\n",
            "base_model.model.model.layers.1.mlp.down_proj.weight\n",
            "base_model.model.model.layers.1.input_layernorm.weight\n",
            "base_model.model.model.layers.1.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.2.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.2.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.2.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.2.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.2.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.2.mlp.up_proj.weight\n",
            "base_model.model.model.layers.2.mlp.down_proj.weight\n",
            "base_model.model.model.layers.2.input_layernorm.weight\n",
            "base_model.model.model.layers.2.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.3.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.3.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.3.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.3.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.3.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.3.mlp.up_proj.weight\n",
            "base_model.model.model.layers.3.mlp.down_proj.weight\n",
            "base_model.model.model.layers.3.input_layernorm.weight\n",
            "base_model.model.model.layers.3.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.4.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.4.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.4.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.4.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.4.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.4.mlp.up_proj.weight\n",
            "base_model.model.model.layers.4.mlp.down_proj.weight\n",
            "base_model.model.model.layers.4.input_layernorm.weight\n",
            "base_model.model.model.layers.4.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.5.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.5.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.5.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.5.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.5.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.5.mlp.up_proj.weight\n",
            "base_model.model.model.layers.5.mlp.down_proj.weight\n",
            "base_model.model.model.layers.5.input_layernorm.weight\n",
            "base_model.model.model.layers.5.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.6.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.6.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.6.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.6.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.6.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.6.mlp.up_proj.weight\n",
            "base_model.model.model.layers.6.mlp.down_proj.weight\n",
            "base_model.model.model.layers.6.input_layernorm.weight\n",
            "base_model.model.model.layers.6.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.7.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.7.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.7.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.7.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.7.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.7.mlp.up_proj.weight\n",
            "base_model.model.model.layers.7.mlp.down_proj.weight\n",
            "base_model.model.model.layers.7.input_layernorm.weight\n",
            "base_model.model.model.layers.7.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.8.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.8.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.8.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.8.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.8.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.8.mlp.up_proj.weight\n",
            "base_model.model.model.layers.8.mlp.down_proj.weight\n",
            "base_model.model.model.layers.8.input_layernorm.weight\n",
            "base_model.model.model.layers.8.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.9.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.9.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.9.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.9.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.9.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.9.mlp.up_proj.weight\n",
            "base_model.model.model.layers.9.mlp.down_proj.weight\n",
            "base_model.model.model.layers.9.input_layernorm.weight\n",
            "base_model.model.model.layers.9.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.10.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.10.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.10.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.10.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.10.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.10.mlp.up_proj.weight\n",
            "base_model.model.model.layers.10.mlp.down_proj.weight\n",
            "base_model.model.model.layers.10.input_layernorm.weight\n",
            "base_model.model.model.layers.10.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.11.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.11.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.11.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.11.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.11.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.11.mlp.up_proj.weight\n",
            "base_model.model.model.layers.11.mlp.down_proj.weight\n",
            "base_model.model.model.layers.11.input_layernorm.weight\n",
            "base_model.model.model.layers.11.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.12.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.12.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.12.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.12.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.12.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.12.mlp.up_proj.weight\n",
            "base_model.model.model.layers.12.mlp.down_proj.weight\n",
            "base_model.model.model.layers.12.input_layernorm.weight\n",
            "base_model.model.model.layers.12.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.13.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.13.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.13.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.13.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.13.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.13.mlp.up_proj.weight\n",
            "base_model.model.model.layers.13.mlp.down_proj.weight\n",
            "base_model.model.model.layers.13.input_layernorm.weight\n",
            "base_model.model.model.layers.13.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.14.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.14.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.14.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.14.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.14.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.14.mlp.up_proj.weight\n",
            "base_model.model.model.layers.14.mlp.down_proj.weight\n",
            "base_model.model.model.layers.14.input_layernorm.weight\n",
            "base_model.model.model.layers.14.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.15.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.15.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.15.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.15.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.15.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.15.mlp.up_proj.weight\n",
            "base_model.model.model.layers.15.mlp.down_proj.weight\n",
            "base_model.model.model.layers.15.input_layernorm.weight\n",
            "base_model.model.model.layers.15.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.16.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.16.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.16.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.16.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.16.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.16.mlp.up_proj.weight\n",
            "base_model.model.model.layers.16.mlp.down_proj.weight\n",
            "base_model.model.model.layers.16.input_layernorm.weight\n",
            "base_model.model.model.layers.16.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.17.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.17.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.17.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.17.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.17.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.17.mlp.up_proj.weight\n",
            "base_model.model.model.layers.17.mlp.down_proj.weight\n",
            "base_model.model.model.layers.17.input_layernorm.weight\n",
            "base_model.model.model.layers.17.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.18.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.18.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.18.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.18.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.18.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.18.mlp.up_proj.weight\n",
            "base_model.model.model.layers.18.mlp.down_proj.weight\n",
            "base_model.model.model.layers.18.input_layernorm.weight\n",
            "base_model.model.model.layers.18.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.19.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.19.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.19.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.19.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.19.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.19.mlp.up_proj.weight\n",
            "base_model.model.model.layers.19.mlp.down_proj.weight\n",
            "base_model.model.model.layers.19.input_layernorm.weight\n",
            "base_model.model.model.layers.19.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.20.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.20.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.20.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.20.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.20.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.20.mlp.up_proj.weight\n",
            "base_model.model.model.layers.20.mlp.down_proj.weight\n",
            "base_model.model.model.layers.20.input_layernorm.weight\n",
            "base_model.model.model.layers.20.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.21.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.21.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.21.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.21.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.21.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.21.mlp.up_proj.weight\n",
            "base_model.model.model.layers.21.mlp.down_proj.weight\n",
            "base_model.model.model.layers.21.input_layernorm.weight\n",
            "base_model.model.model.layers.21.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.22.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.22.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.22.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.22.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.22.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.22.mlp.up_proj.weight\n",
            "base_model.model.model.layers.22.mlp.down_proj.weight\n",
            "base_model.model.model.layers.22.input_layernorm.weight\n",
            "base_model.model.model.layers.22.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.23.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.23.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.23.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.23.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.23.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.23.mlp.up_proj.weight\n",
            "base_model.model.model.layers.23.mlp.down_proj.weight\n",
            "base_model.model.model.layers.23.input_layernorm.weight\n",
            "base_model.model.model.layers.23.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.24.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.24.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.24.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.24.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.24.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.24.mlp.up_proj.weight\n",
            "base_model.model.model.layers.24.mlp.down_proj.weight\n",
            "base_model.model.model.layers.24.input_layernorm.weight\n",
            "base_model.model.model.layers.24.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.25.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.25.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.25.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.25.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.25.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.25.mlp.up_proj.weight\n",
            "base_model.model.model.layers.25.mlp.down_proj.weight\n",
            "base_model.model.model.layers.25.input_layernorm.weight\n",
            "base_model.model.model.layers.25.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.26.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.26.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.26.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.26.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.26.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.26.mlp.up_proj.weight\n",
            "base_model.model.model.layers.26.mlp.down_proj.weight\n",
            "base_model.model.model.layers.26.input_layernorm.weight\n",
            "base_model.model.model.layers.26.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.27.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.27.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.27.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.27.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.27.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.27.mlp.up_proj.weight\n",
            "base_model.model.model.layers.27.mlp.down_proj.weight\n",
            "base_model.model.model.layers.27.input_layernorm.weight\n",
            "base_model.model.model.layers.27.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.28.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.28.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.28.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.28.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.28.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.28.mlp.up_proj.weight\n",
            "base_model.model.model.layers.28.mlp.down_proj.weight\n",
            "base_model.model.model.layers.28.input_layernorm.weight\n",
            "base_model.model.model.layers.28.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.29.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.29.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.29.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.29.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.29.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.29.mlp.up_proj.weight\n",
            "base_model.model.model.layers.29.mlp.down_proj.weight\n",
            "base_model.model.model.layers.29.input_layernorm.weight\n",
            "base_model.model.model.layers.29.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.30.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.30.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.30.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.30.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.30.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.30.mlp.up_proj.weight\n",
            "base_model.model.model.layers.30.mlp.down_proj.weight\n",
            "base_model.model.model.layers.30.input_layernorm.weight\n",
            "base_model.model.model.layers.30.post_attention_layernorm.weight\n",
            "base_model.model.model.layers.31.self_attn.q_proj.weight\n",
            "base_model.model.model.layers.31.self_attn.k_proj.weight\n",
            "base_model.model.model.layers.31.self_attn.v_proj.weight\n",
            "base_model.model.model.layers.31.self_attn.o_proj.weight\n",
            "base_model.model.model.layers.31.mlp.gate_proj.weight\n",
            "base_model.model.model.layers.31.mlp.up_proj.weight\n",
            "base_model.model.model.layers.31.mlp.down_proj.weight\n",
            "base_model.model.model.layers.31.input_layernorm.weight\n",
            "base_model.model.model.layers.31.post_attention_layernorm.weight\n",
            "base_model.model.model.norm.weight\n",
            "base_model.model.lm_head.weight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_text = list(test_data.prompt.values)[10]\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
        "\n",
        "# Generate text\n",
        "output = merged_model.generate(inputs[\"input_ids\"], attention_mask=inputs['attention_mask'], pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "# Decode the generated text\n",
        "generated_text = tokenizer.decode(output[0])\n",
        "\n",
        "# Print the generated text\n",
        "print(generated_text.split(\"[/INST]\")[-1], list(test_data.label.values)[10])"
      ],
      "metadata": {
        "id": "POFVtmqGlsn8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745841875891,
          "user_tz": -480,
          "elapsed": 530,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f32fd0-9ae4-44de-deb2-a46d8c65c1b4"
      },
      "id": "POFVtmqGlsn8",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1</s> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from transformers import logging\n",
        "\n",
        "# Suppress the specific warning\n",
        "warnings.filterwarnings(\"ignore\", message=\"Setting `pad_token_id` to `eos_token_id`\")\n",
        "\n",
        "# Alternatively, set logging to error level to suppress other warnings\n",
        "logging.set_verbosity_error()\n"
      ],
      "metadata": {
        "id": "lSh22pTK4hHt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745832413983,
          "user_tz": -480,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "lSh22pTK4hHt",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format Test Data\n",
        "from tqdm import tqdm\n",
        "all_predictions = []\n",
        "for test_prompt in tqdm(list(test_data.prompt.values)):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(test_prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
        "\n",
        "    # Generate text\n",
        "    output = merged_model.generate(inputs[\"input_ids\"], attention_mask=inputs['attention_mask'], pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0] )\n",
        "    generated_text_cleaned = generated_text.split(\"[/INST]\")[-1]\n",
        "    if \"1\" in generated_text_cleaned:\n",
        "        prediction = 1\n",
        "    elif \"0\" in generated_text_cleaned:\n",
        "        prediction = 0\n",
        "    else:\n",
        "        prediction = -1\n",
        "    all_predictions.append(prediction)\n",
        "test_data[\"pred\"] = all_predictions\n"
      ],
      "metadata": {
        "id": "-K0mNdEoLvv3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745842732379,
          "user_tz": -480,
          "elapsed": 856491,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7ce2ba-3ff4-4fef-fd1c-f45269400d67"
      },
      "id": "-K0mNdEoLvv3",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1349/1349 [14:16<00:00,  1.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Percentage of incorrectly parsed output: {len(test_data[test_data['pred'] == -1])/len(test_data)}\")"
      ],
      "metadata": {
        "id": "Vy3QROAULxJT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745833661127,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fecf1e8-4f31-4dc0-e390-5b0bffec921f"
      },
      "id": "Vy3QROAULxJT",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of incorrectly parsed output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score,\n",
        "    auc,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "# Metrics calculation\n",
        "def compute_metrics(true_labels, prediction):\n",
        "    metrics = {}\n",
        "    metrics[\"accuracy\"] = accuracy_score(true_labels, prediction)\n",
        "    metrics[\"f1\"] = f1_score(true_labels, prediction)\n",
        "    metrics[\"precision\"] = precision_score(true_labels, prediction)\n",
        "    metrics[\"recall\"] = recall_score(true_labels, prediction)\n",
        "    metrics[\"f1_weighted\"] = f1_score(true_labels, prediction, average = \"weighted\")\n",
        "    metrics[\"recall_weighted\"] = recall_score(true_labels,prediction, average = \"weighted\")\n",
        "    metrics[\"precision_weighted\"] = precision_score(true_labels, prediction, average = \"weighted\")\n",
        "    metrics[\"f1_marco\"] = f1_score(true_labels, prediction, average = \"macro\")\n",
        "    metrics[\"precision_marco\"] = precision_score(true_labels, prediction, average = \"macro\")\n",
        "    metrics[\"recall_marco\"] = recall_score(true_labels, prediction, average = \"macro\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "0dYR7ila3UAA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745842732379,
          "user_tz": -480,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "0dYR7ila3UAA",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pred_to_evaluate = test_data[test_data[\"pred\"]!=-1]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(list(pred_to_evaluate[\"label\"].values), list(pred_to_evaluate[\"pred\"].values))\n",
        "labels = ['Negative', 'Positive']  # Change based on your label semantics\n",
        "\n",
        "# Display as heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "compute_metrics(list(pred_to_evaluate[\"label\"].values), list(pred_to_evaluate[\"pred\"].values))\n"
      ],
      "metadata": {
        "id": "OOzcfKEFLzNs",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745842732665,
          "user_tz": -480,
          "elapsed": 289,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "0191c7c3-f960-4b4c-e07a-7afb5f8d3e91"
      },
      "id": "OOzcfKEFLzNs",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5271779597915115,\n",
              " 'f1': 0.6631299734748011,\n",
              " 'precision': 0.514827018121911,\n",
              " 'recall': 0.9314456035767511,\n",
              " 'f1_weighted': 0.4350157332871093,\n",
              " 'recall_weighted': 0.5271779597915115,\n",
              " 'precision_weighted': 0.5791668072844811,\n",
              " 'f1_marco': 0.4351854611443918,\n",
              " 'precision_marco': 0.5791189354175447,\n",
              " 'recall_marco': 0.527478754169328}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Model Evaluation"
      ],
      "metadata": {
        "id": "3dEzmby-WwTA"
      },
      "id": "3dEzmby-WwTA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Model evaluation\n",
        "# Load base model in 4-bit\n",
        "from tqdm import tqdm\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "all_base_predictions = []\n",
        "for test_prompt in tqdm(list(test_data.prompt.values)):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate text\n",
        "    output = base_model.generate(inputs['input_ids'])\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0])\n",
        "    generated_text_cleaned = generated_text.split(\"[/INST]\")[-1]\n",
        "    if \"1\" in generated_text_cleaned:\n",
        "        prediction = 1\n",
        "    elif \"0\" in generated_text_cleaned:\n",
        "        prediction = 0\n",
        "    else:\n",
        "        prediction = -1\n",
        "    all_base_predictions.append(prediction)\n",
        "test_data[\"base_pred\"] = all_base_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "36b4a790a8354069bc6622aefcbd28fb",
            "6434354d675f40c49656ad2da8eae25a",
            "28d344b637af42579c06afec6f266d31",
            "5e7bbd4c27ec45f69baa5011d3a81db0",
            "3c27425ef2d9440c9652c923839a3ebf",
            "4e6be87b166f4e748409a0aafd05eaa1",
            "f2fc9b233ffb4530b8086c481fb3fbaa",
            "2c01dbe9d5764dd3a640de6739b90d82",
            "2668fa1b3e65432e8a70c8fbacaa5c6d",
            "12eae6d4ce264d6da4b94af8a978cfe8",
            "2eaab8dde79f4496944d424c2a79b87d"
          ]
        },
        "id": "81ftDHr52R_8",
        "outputId": "7de57dbb-4fb5-4bf4-9b97-7496dc50a2f3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745744012283,
          "user_tz": -480,
          "elapsed": 1405139,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "81ftDHr52R_8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36b4a790a8354069bc6622aefcbd28fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1349/1349 [23:06<00:00,  1.03s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pred_to_evaluate = test_data[test_data[\"base_pred\"]!=-1]\n",
        "\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(list(pred_to_evaluate[\"label\"].values), list(pred_to_evaluate[\"base_pred\"].values))\n",
        "labels = ['Negative', 'Positive']  # Change based on your label semantics\n",
        "\n",
        "# Display as heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "compute_metrics(pred_to_evaluate[\"label\"], pred_to_evaluate[\"base_pred\"])\n"
      ],
      "metadata": {
        "id": "2Y7fTtED2YAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745744456160,
          "user_tz": -480,
          "elapsed": 222,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "554a7fb0-440c-4efd-afaf-79b3828bd3e9"
      },
      "id": "2Y7fTtED2YAc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5552260934025204,\n",
              " 'f1': 0.6005326231691078,\n",
              " 'precision': 0.5460048426150121,\n",
              " 'recall': 0.6671597633136095,\n",
              " 'f1_weighted': 0.5495438363247711,\n",
              " 'recall_weighted': 0.5552260934025204,\n",
              " 'precision_weighted': 0.5578708116016146,\n",
              " 'f1_marco': 0.5494301911832161,\n",
              " 'precision_marco': 0.5578972587836055,\n",
              " 'recall_marco': 0.5549766127117824}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_base_predictions = []\n",
        "for train_prompt in tqdm(list(train_data.prompt.values)):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(train_prompt.split(\"[/INST]\")[0], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate text\n",
        "    output = base_model.generate(inputs['input_ids'], pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0])\n",
        "    generated_text_cleaned = generated_text.split(\"[/INST]\")[-1]\n",
        "    if \"1\" in generated_text_cleaned:\n",
        "        prediction = 1\n",
        "    elif \"0\" in generated_text_cleaned:\n",
        "        prediction = 0\n",
        "    else:\n",
        "        prediction = -1\n",
        "    all_base_predictions.append(prediction)\n",
        "train_data[\"base_pred\"] = all_base_predictions"
      ],
      "metadata": {
        "id": "rQEwjT4wuqSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745748534524,
          "user_tz": -480,
          "elapsed": 3506534,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "fad4c99c-f716-4d22-f622-38b39d3d773e"
      },
      "id": "rQEwjT4wuqSz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2440/2440 [58:26<00:00,  1.44s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred_to_evaluate = train_data[train_data[\"base_pred\"]!=-1]\n",
        "print(len(train_data), len(pred_to_evaluate))\n",
        "compute_metrics(pred_to_evaluate[\"label\"], pred_to_evaluate[\"base_pred\"])"
      ],
      "metadata": {
        "id": "FsYFiFPAPluc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745748534524,
          "user_tz": -480,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0d044299-083f-447e-87e4-b18ac0b14ab6"
      },
      "id": "FsYFiFPAPluc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2440 2440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.06885245901639345,\n",
              " 'f1': 0.12883435582822086,\n",
              " 'precision': 0.06885245901639345,\n",
              " 'recall': 1.0,\n",
              " 'f1_weighted': 0.008870562204566026,\n",
              " 'recall_weighted': 0.06885245901639345,\n",
              " 'precision_weighted': 0.004740661112604139,\n",
              " 'f1_marco': 0.06441717791411043,\n",
              " 'precision_marco': 0.03442622950819672,\n",
              " 'recall_marco': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "reach_classification_mistral.ipynb",
      "gpuType": "A100",
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36b4a790a8354069bc6622aefcbd28fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6434354d675f40c49656ad2da8eae25a",
              "IPY_MODEL_28d344b637af42579c06afec6f266d31",
              "IPY_MODEL_5e7bbd4c27ec45f69baa5011d3a81db0"
            ],
            "layout": "IPY_MODEL_3c27425ef2d9440c9652c923839a3ebf"
          }
        },
        "6434354d675f40c49656ad2da8eae25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6be87b166f4e748409a0aafd05eaa1",
            "placeholder": "​",
            "style": "IPY_MODEL_f2fc9b233ffb4530b8086c481fb3fbaa",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "28d344b637af42579c06afec6f266d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c01dbe9d5764dd3a640de6739b90d82",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2668fa1b3e65432e8a70c8fbacaa5c6d",
            "value": 3
          }
        },
        "5e7bbd4c27ec45f69baa5011d3a81db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12eae6d4ce264d6da4b94af8a978cfe8",
            "placeholder": "​",
            "style": "IPY_MODEL_2eaab8dde79f4496944d424c2a79b87d",
            "value": " 3/3 [00:17&lt;00:00,  5.92s/it]"
          }
        },
        "3c27425ef2d9440c9652c923839a3ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6be87b166f4e748409a0aafd05eaa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fc9b233ffb4530b8086c481fb3fbaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c01dbe9d5764dd3a640de6739b90d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2668fa1b3e65432e8a70c8fbacaa5c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12eae6d4ce264d6da4b94af8a978cfe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eaab8dde79f4496944d424c2a79b87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10aa1e394e664ebfb26e1dd249eb6c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_e561b146a4b04a6a8632757b7951c608"
          }
        },
        "86358fd54f724bb886fbbd80e04bfcb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e43f9e59364847bbbc20d3f9af1550",
            "placeholder": "​",
            "style": "IPY_MODEL_0822820fb77d456c96978828c9f2d8d6",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "61f74e459d444e8da5703a555d447c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6b0cacfc393c421d95eec5905908b5b7",
            "placeholder": "​",
            "style": "IPY_MODEL_d4d20b4d8d4147839263187732ab7355",
            "value": ""
          }
        },
        "b6c8e2a6c8874f3b8b0d3c0f4667cb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_58c2e9445e7c470f9c258a7121417a3f",
            "style": "IPY_MODEL_32369ea1f8af4d108fbd79bd7acd229e",
            "value": true
          }
        },
        "2a95eeb444c34fdfb6883444a2f5db49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c38fbe45e2fe4a2bbbb55e4733358c91",
            "style": "IPY_MODEL_2529865dfa3142ceb6fc8dad3be579ee",
            "tooltip": ""
          }
        },
        "8012e553c2ac4c55997085b2ec6f8986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5fcb45521134a559ed1e0e5ca959516",
            "placeholder": "​",
            "style": "IPY_MODEL_13b6663f5c314d85a0cf6772d03c517e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e561b146a4b04a6a8632757b7951c608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "24e43f9e59364847bbbc20d3f9af1550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0822820fb77d456c96978828c9f2d8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b0cacfc393c421d95eec5905908b5b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d20b4d8d4147839263187732ab7355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58c2e9445e7c470f9c258a7121417a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32369ea1f8af4d108fbd79bd7acd229e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c38fbe45e2fe4a2bbbb55e4733358c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2529865dfa3142ceb6fc8dad3be579ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d5fcb45521134a559ed1e0e5ca959516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b6663f5c314d85a0cf6772d03c517e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed01d668f6ba459d9e6bfc0bd3412141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9463a8b6044694aefa9872efdc4d8a",
            "placeholder": "​",
            "style": "IPY_MODEL_adfc6c613d034c0db8a419aa0480d3a4",
            "value": "Connecting..."
          }
        },
        "7c9463a8b6044694aefa9872efdc4d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adfc6c613d034c0db8a419aa0480d3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e65d2c9cb9494b99b3a094b4aa4e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d49104a2791a4cf4aea35be90e351460",
              "IPY_MODEL_4738795463ce41e4b4bce691ce8a625e",
              "IPY_MODEL_545b6f7d2b134be28658498109ac9b3e"
            ],
            "layout": "IPY_MODEL_135066807d6a4d799c9ce05b5fe7e782"
          }
        },
        "d49104a2791a4cf4aea35be90e351460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a88066453984a50bb5c7c02a47301c0",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e62406e845424284e55ecc26a05452",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4738795463ce41e4b4bce691ce8a625e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a325eca154d84e48bda67b0a1fda232b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9395b0c2f4bc4f6d86d3dd473e2e6da9",
            "value": 3
          }
        },
        "545b6f7d2b134be28658498109ac9b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5cbc6694d714d3cbcc575edc3b7fc60",
            "placeholder": "​",
            "style": "IPY_MODEL_033ab3a881574186a34523531b17f9a5",
            "value": " 3/3 [00:05&lt;00:00,  1.85s/it]"
          }
        },
        "135066807d6a4d799c9ce05b5fe7e782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a88066453984a50bb5c7c02a47301c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e62406e845424284e55ecc26a05452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a325eca154d84e48bda67b0a1fda232b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9395b0c2f4bc4f6d86d3dd473e2e6da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5cbc6694d714d3cbcc575edc3b7fc60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033ab3a881574186a34523531b17f9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}